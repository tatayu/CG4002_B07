{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dance move: 0, Name: dummy_dance_1\n",
      "Dance move: 1, Name: dummy_dance_2\n",
      "Dance move: 2, Name: dummy_dance_3\n",
      "Dance move: 3, Name: dummy_dance_4\n",
      "Dance move: 4, Name: dummy_dance_5\n",
      "Dance move: 5, Name: dummy_dance_6\n",
      "Dance move: 6, Name: dummy_dance_7\n",
      "Dance move: 7, Name: dummy_dance_8\n",
      "Dance move: 8, Name: move_left\n",
      "Dance move: 9, Name: move_right\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split, KFold, TimeSeriesSplit, cross_val_score\n",
    "\n",
    "import brevitas.nn as nn\n",
    "\n",
    "from config import *\n",
    "from classic_models import *\n",
    "from data_preprocessing import *\n",
    "from feature_extraction import *\n",
    "from helpers import *\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_x</th>\n",
       "      <th>mean_y</th>\n",
       "      <th>mean_z</th>\n",
       "      <th>max_x</th>\n",
       "      <th>max_y</th>\n",
       "      <th>max_z</th>\n",
       "      <th>min_x</th>\n",
       "      <th>min_y</th>\n",
       "      <th>min_z</th>\n",
       "      <th>median_x</th>\n",
       "      <th>...</th>\n",
       "      <th>iqr_x</th>\n",
       "      <th>iqr_y</th>\n",
       "      <th>iqr_z</th>\n",
       "      <th>zero_crossing_counts_x</th>\n",
       "      <th>zero_crossing_counts_y</th>\n",
       "      <th>zero_crossing_counts_z</th>\n",
       "      <th>dominant_frequency_x</th>\n",
       "      <th>dominant_frequency_y</th>\n",
       "      <th>dominant_frequency_z</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.3208</td>\n",
       "      <td>19.61</td>\n",
       "      <td>-4.04</td>\n",
       "      <td>14.470</td>\n",
       "      <td>-0.1728</td>\n",
       "      <td>7.356010</td>\n",
       "      <td>13.0675</td>\n",
       "      <td>-0.555269</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.61</td>\n",
       "      <td>-19.61</td>\n",
       "      <td>-4.205</td>\n",
       "      <td>0.2321</td>\n",
       "      <td>11.014407</td>\n",
       "      <td>13.9650</td>\n",
       "      <td>0.362901</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.4090</td>\n",
       "      <td>19.61</td>\n",
       "      <td>-1.76</td>\n",
       "      <td>13.725</td>\n",
       "      <td>0.1785</td>\n",
       "      <td>6.944948</td>\n",
       "      <td>12.7025</td>\n",
       "      <td>-0.511257</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.61</td>\n",
       "      <td>-19.61</td>\n",
       "      <td>-4.205</td>\n",
       "      <td>-0.1642</td>\n",
       "      <td>10.652340</td>\n",
       "      <td>14.3025</td>\n",
       "      <td>0.273621</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0170</td>\n",
       "      <td>19.61</td>\n",
       "      <td>-1.76</td>\n",
       "      <td>13.065</td>\n",
       "      <td>-0.3281</td>\n",
       "      <td>6.670013</td>\n",
       "      <td>11.3150</td>\n",
       "      <td>-0.482849</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.61</td>\n",
       "      <td>-19.61</td>\n",
       "      <td>-3.730</td>\n",
       "      <td>0.4712</td>\n",
       "      <td>10.484271</td>\n",
       "      <td>14.0375</td>\n",
       "      <td>0.245018</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.1898</td>\n",
       "      <td>19.61</td>\n",
       "      <td>-1.76</td>\n",
       "      <td>12.985</td>\n",
       "      <td>-0.1299</td>\n",
       "      <td>7.002910</td>\n",
       "      <td>14.2475</td>\n",
       "      <td>-0.335542</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.61</td>\n",
       "      <td>-19.61</td>\n",
       "      <td>-3.680</td>\n",
       "      <td>0.3690</td>\n",
       "      <td>11.250628</td>\n",
       "      <td>14.5200</td>\n",
       "      <td>0.251294</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.9784</td>\n",
       "      <td>19.61</td>\n",
       "      <td>-1.76</td>\n",
       "      <td>12.555</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>6.741029</td>\n",
       "      <td>12.9700</td>\n",
       "      <td>-0.347759</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.61</td>\n",
       "      <td>-19.61</td>\n",
       "      <td>-3.730</td>\n",
       "      <td>-0.7864</td>\n",
       "      <td>11.196545</td>\n",
       "      <td>14.5200</td>\n",
       "      <td>0.365375</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_x  mean_y  mean_z   max_x   max_y     max_z    min_x     min_y  \\\n",
       "0  12.3208   19.61   -4.04  14.470 -0.1728  7.356010  13.0675 -0.555269   \n",
       "1  12.4090   19.61   -1.76  13.725  0.1785  6.944948  12.7025 -0.511257   \n",
       "2  12.0170   19.61   -1.76  13.065 -0.3281  6.670013  11.3150 -0.482849   \n",
       "3  11.1898   19.61   -1.76  12.985 -0.1299  7.002910  14.2475 -0.335542   \n",
       "4  10.9784   19.61   -1.76  12.555  0.6584  6.741029  12.9700 -0.347759   \n",
       "\n",
       "   min_z  median_x  ...  iqr_x  iqr_y  iqr_z  zero_crossing_counts_x  \\\n",
       "0    8.0       0.0  ...  19.61 -19.61 -4.205                  0.2321   \n",
       "1    6.0       0.0  ...  19.61 -19.61 -4.205                 -0.1642   \n",
       "2    6.0       0.0  ...  19.61 -19.61 -3.730                  0.4712   \n",
       "3    6.0       0.0  ...  19.61 -19.61 -3.680                  0.3690   \n",
       "4    5.0       0.0  ...  19.61 -19.61 -3.730                 -0.7864   \n",
       "\n",
       "   zero_crossing_counts_y  zero_crossing_counts_z  dominant_frequency_x  \\\n",
       "0               11.014407                 13.9650              0.362901   \n",
       "1               10.652340                 14.3025              0.273621   \n",
       "2               10.484271                 14.0375              0.245018   \n",
       "3               11.250628                 14.5200              0.251294   \n",
       "4               11.196545                 14.5200              0.365375   \n",
       "\n",
       "   dominant_frequency_y  dominant_frequency_z  tag  \n",
       "0                  28.0                  0.28  1.0  \n",
       "1                  28.0                  0.28  1.0  \n",
       "2                  27.0                  0.28  1.0  \n",
       "3                  28.0                  0.28  1.0  \n",
       "4                  27.0                  0.28  1.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('out.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        df = pd.read_csv('out.csv')\n",
    "        df['tag'] = df['tag'].apply(lambda x: x-1)\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            df = df.to_numpy()\n",
    "\n",
    "        self.X = df[:,:-1]\n",
    "        self.y = df[:,-1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get item by index\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        # returns length of data\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1345 449\n"
     ]
    }
   ],
   "source": [
    "dataset = FeatureDataset()\n",
    "\n",
    "train_size = int(len(dataset) * 0.75)\n",
    "test_size = len(dataset) - train_size\n",
    "train_data, test_data = torch.utils.data.random_split(dataset, (train_size, test_size))\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = 64, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = 64, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x24363803948>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.input_fc = nn.QuantLinear(input_size, 256, bias=True, weight_bit_width=4)\n",
    "        self.hidden_fc = nn.QuantLinear(256, 256, bias=True, weight_bit_width=4)\n",
    "        self.hidden_fc_2 = nn.QuantLinear(256, 128, bias=True, weight_bit_width=4)\n",
    "        self.output_fc = nn.QuantLinear(128, output_size, bias=False, weight_bit_width=4)\n",
    "        \n",
    "        self.relu = nn.QuantReLU(bit_width=2, max_val=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_1 = self.input_fc(x.float())\n",
    "        h_1 = torch.nn.functional.relu(x_1)\n",
    "        x_2 = self.hidden_fc(h_1)\n",
    "        x_3 = self.hidden_fc_2(x_2)\n",
    "        h_2 = torch.nn.functional.relu(x_3)\n",
    "        y_pred = self.output_fc(h_2)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 10\n"
     ]
    }
   ],
   "source": [
    "model = SimpleMLP(df.shape[1]-1, len(dances))\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr = 0.001)\n",
    "learning_rate = 3e-5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
    "\n",
    "print(df.shape[1]-1, len(dances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 0.13351\n",
      "Epoch: 20, Loss: 0.13356\n",
      "Epoch: 30, Loss: 0.03532\n",
      "Epoch: 40, Loss: 0.00651\n",
      "Epoch: 50, Loss: 0.24381\n",
      "Epoch: 60, Loss: 0.10216\n",
      "Epoch: 70, Loss: 0.01696\n",
      "Epoch: 80, Loss: 5.08520\n",
      "Epoch: 90, Loss: 0.00380\n",
      "Epoch: 100, Loss: 0.15512\n",
      "Epoch: 110, Loss: 0.00037\n",
      "Epoch: 120, Loss: 0.44478\n",
      "Epoch: 130, Loss: 0.04596\n",
      "Epoch: 140, Loss: 0.00338\n",
      "Epoch: 150, Loss: 0.10570\n",
      "Epoch: 160, Loss: 0.08229\n",
      "Epoch: 170, Loss: 0.02329\n",
      "Epoch: 180, Loss: 0.00117\n",
      "Epoch: 190, Loss: 0.00073\n",
      "Epoch: 200, Loss: 0.02591\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 200\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.float(), y.long()\n",
    "        outputs = model(x)\n",
    "\n",
    "        loss = criterion(outputs, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(\"Epoch: {}, Loss: {:.5f}\".format(epoch + 1, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleMLP(\n",
       "  (input_fc): QuantLinear(\n",
       "    in_features=30, out_features=256, bias=True\n",
       "    (input_quant): IdentityQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): IdentityQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "        )\n",
       "        (scaling_impl): StatsFromParameterScaling(\n",
       "          (parameter_list_stats): _ParameterListStats(\n",
       "            (first_tracked_param): _ViewParameterWrapper()\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsMax()\n",
       "            )\n",
       "          )\n",
       "          (stats_scaling_impl): _StatsScaling(\n",
       "            (affine_rescaling): Identity()\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): Identity()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (restrict_scaling_pre): Identity()\n",
       "          )\n",
       "        )\n",
       "        (int_scaling_impl): IntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (hidden_fc): QuantLinear(\n",
       "    in_features=256, out_features=256, bias=True\n",
       "    (input_quant): IdentityQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): IdentityQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "        )\n",
       "        (scaling_impl): StatsFromParameterScaling(\n",
       "          (parameter_list_stats): _ParameterListStats(\n",
       "            (first_tracked_param): _ViewParameterWrapper()\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsMax()\n",
       "            )\n",
       "          )\n",
       "          (stats_scaling_impl): _StatsScaling(\n",
       "            (affine_rescaling): Identity()\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): Identity()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (restrict_scaling_pre): Identity()\n",
       "          )\n",
       "        )\n",
       "        (int_scaling_impl): IntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (hidden_fc_2): QuantLinear(\n",
       "    in_features=256, out_features=128, bias=True\n",
       "    (input_quant): IdentityQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): IdentityQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "        )\n",
       "        (scaling_impl): StatsFromParameterScaling(\n",
       "          (parameter_list_stats): _ParameterListStats(\n",
       "            (first_tracked_param): _ViewParameterWrapper()\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsMax()\n",
       "            )\n",
       "          )\n",
       "          (stats_scaling_impl): _StatsScaling(\n",
       "            (affine_rescaling): Identity()\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): Identity()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (restrict_scaling_pre): Identity()\n",
       "          )\n",
       "        )\n",
       "        (int_scaling_impl): IntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (output_fc): QuantLinear(\n",
       "    in_features=128, out_features=10, bias=False\n",
       "    (input_quant): IdentityQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): IdentityQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "        )\n",
       "        (scaling_impl): StatsFromParameterScaling(\n",
       "          (parameter_list_stats): _ParameterListStats(\n",
       "            (first_tracked_param): _ViewParameterWrapper()\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsMax()\n",
       "            )\n",
       "          )\n",
       "          (stats_scaling_impl): _StatsScaling(\n",
       "            (affine_rescaling): Identity()\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): Identity()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (restrict_scaling_pre): Identity()\n",
       "          )\n",
       "        )\n",
       "        (int_scaling_impl): IntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (relu): QuantReLU(\n",
       "    (input_quant): IdentityQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): ReLU()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClamp()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "          )\n",
       "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
       "            (stats_input_view_shape_impl): OverTensorView()\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsPercentile()\n",
       "            )\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): Identity()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (restrict_inplace_preprocess): Identity()\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "estimator should be an estimator implementing 'fit' method, SimpleMLP(\n  (input_fc): QuantLinear(\n    in_features=30, out_features=256, bias=True\n    (input_quant): IdentityQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n    )\n    (output_quant): IdentityQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n    )\n    (weight_quant): WeightQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n      (tensor_quant): RescalingIntQuant(\n        (int_quant): IntQuant(\n          (float_to_int_impl): RoundSte()\n          (tensor_clamp_impl): TensorClampSte()\n          (delay_wrapper): DelayWrapper(\n            (delay_impl): _NoDelay()\n          )\n        )\n        (scaling_impl): StatsFromParameterScaling(\n          (parameter_list_stats): _ParameterListStats(\n            (first_tracked_param): _ViewParameterWrapper()\n            (stats): _Stats(\n              (stats_impl): AbsMax()\n            )\n          )\n          (stats_scaling_impl): _StatsScaling(\n            (affine_rescaling): Identity()\n            (restrict_clamp_scaling): _RestrictClampValue(\n              (clamp_min_ste): Identity()\n              (restrict_value_impl): FloatRestrictValue()\n            )\n            (restrict_scaling_pre): Identity()\n          )\n        )\n        (int_scaling_impl): IntScaling()\n        (zero_point_impl): ZeroZeroPoint(\n          (zero_point): StatelessBuffer()\n        )\n        (msb_clamp_bit_width_impl): BitWidthConst(\n          (bit_width): StatelessBuffer()\n        )\n      )\n    )\n    (bias_quant): BiasQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n    )\n  )\n  (hidden_fc): QuantLinear(\n    in_features=256, out_features=256, bias=True\n    (input_quant): IdentityQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n    )\n    (output_quant): IdentityQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n    )\n    (weight_quant): WeightQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n      (tensor_quant): RescalingIntQuant(\n        (int_quant): IntQuant(\n          (float_to_int_impl): RoundSte()\n          (tensor_clamp_impl): TensorClampSte()\n          (delay_wrapper): DelayWrapper(\n            (delay_impl): _NoDelay()\n          )\n        )\n        (scaling_impl): StatsFromParameterScaling(\n          (parameter_list_stats): _ParameterListStats(\n            (first_tracked_param): _ViewParameterWrapper()\n            (stats): _Stats(\n              (stats_impl): AbsMax()\n            )\n          )\n          (stats_scaling_impl): _StatsScaling(\n            (affine_rescaling): Identity()\n            (restrict_clamp_scaling): _RestrictClampValue(\n              (clamp_min_ste): Identity()\n              (restrict_value_impl): FloatRestrictValue()\n            )\n            (restrict_scaling_pre): Identity()\n          )\n        )\n        (int_scaling_impl): IntScaling()\n        (zero_point_impl): ZeroZeroPoint(\n          (zero_point): StatelessBuffer()\n        )\n        (msb_clamp_bit_width_impl): BitWidthConst(\n          (bit_width): StatelessBuffer()\n        )\n      )\n    )\n    (bias_quant): BiasQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n    )\n  )\n  (hidden_fc_2): QuantLinear(\n    in_features=256, out_features=128, bias=True\n    (input_quant): IdentityQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n    )\n    (output_quant): IdentityQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n    )\n    (weight_quant): WeightQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n      (tensor_quant): RescalingIntQuant(\n        (int_quant): IntQuant(\n          (float_to_int_impl): RoundSte()\n          (tensor_clamp_impl): TensorClampSte()\n          (delay_wrapper): DelayWrapper(\n            (delay_impl): _NoDelay()\n          )\n        )\n        (scaling_impl): StatsFromParameterScaling(\n          (parameter_list_stats): _ParameterListStats(\n            (first_tracked_param): _ViewParameterWrapper()\n            (stats): _Stats(\n              (stats_impl): AbsMax()\n            )\n          )\n          (stats_scaling_impl): _StatsScaling(\n            (affine_rescaling): Identity()\n            (restrict_clamp_scaling): _RestrictClampValue(\n              (clamp_min_ste): Identity()\n              (restrict_value_impl): FloatRestrictValue()\n            )\n            (restrict_scaling_pre): Identity()\n          )\n        )\n        (int_scaling_impl): IntScaling()\n        (zero_point_impl): ZeroZeroPoint(\n          (zero_point): StatelessBuffer()\n        )\n        (msb_clamp_bit_width_impl): BitWidthConst(\n          (bit_width): StatelessBuffer()\n        )\n      )\n    )\n    (bias_quant): BiasQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n    )\n  )\n  (output_fc): QuantLinear(\n    in_features=128, out_features=10, bias=False\n    (input_quant): IdentityQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n    )\n    (output_quant): IdentityQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n    )\n    (weight_quant): WeightQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n      (tensor_quant): RescalingIntQuant(\n        (int_quant): IntQuant(\n          (float_to_int_impl): RoundSte()\n          (tensor_clamp_impl): TensorClampSte()\n          (delay_wrapper): DelayWrapper(\n            (delay_impl): _NoDelay()\n          )\n        )\n        (scaling_impl): StatsFromParameterScaling(\n          (parameter_list_stats): _ParameterListStats(\n            (first_tracked_param): _ViewParameterWrapper()\n            (stats): _Stats(\n              (stats_impl): AbsMax()\n            )\n          )\n          (stats_scaling_impl): _StatsScaling(\n            (affine_rescaling): Identity()\n            (restrict_clamp_scaling): _RestrictClampValue(\n              (clamp_min_ste): Identity()\n              (restrict_value_impl): FloatRestrictValue()\n            )\n            (restrict_scaling_pre): Identity()\n          )\n        )\n        (int_scaling_impl): IntScaling()\n        (zero_point_impl): ZeroZeroPoint(\n          (zero_point): StatelessBuffer()\n        )\n        (msb_clamp_bit_width_impl): BitWidthConst(\n          (bit_width): StatelessBuffer()\n        )\n      )\n    )\n    (bias_quant): BiasQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n    )\n  )\n  (relu): QuantReLU(\n    (input_quant): IdentityQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n    )\n    (act_quant): ActQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n        (activation_impl): ReLU()\n        (tensor_quant): RescalingIntQuant(\n          (int_quant): IntQuant(\n            (float_to_int_impl): RoundSte()\n            (tensor_clamp_impl): TensorClamp()\n            (delay_wrapper): DelayWrapper(\n              (delay_impl): _NoDelay()\n            )\n          )\n          (scaling_impl): ParameterFromRuntimeStatsScaling(\n            (stats_input_view_shape_impl): OverTensorView()\n            (stats): _Stats(\n              (stats_impl): AbsPercentile()\n            )\n            (restrict_clamp_scaling): _RestrictClampValue(\n              (clamp_min_ste): Identity()\n              (restrict_value_impl): FloatRestrictValue()\n            )\n            (restrict_inplace_preprocess): Identity()\n          )\n          (int_scaling_impl): IntScaling()\n          (zero_point_impl): ZeroZeroPoint(\n            (zero_point): StatelessBuffer()\n          )\n          (msb_clamp_bit_width_impl): BitWidthConst(\n            (bit_width): StatelessBuffer()\n          )\n        )\n      )\n    )\n  )\n) was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-88aad1d498b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtscv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimeSeriesSplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtscv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    381\u001b[0m     \"\"\"\n\u001b[0;32m    382\u001b[0m     \u001b[1;31m# To ensure multimetric format is not supported\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[1;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m         raise TypeError(\"estimator should be an estimator implementing \"\n\u001b[1;32m--> 401\u001b[1;33m                         \"'fit' method, %r was passed\" % estimator)\n\u001b[0m\u001b[0;32m    402\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mget_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: estimator should be an estimator implementing 'fit' method, SimpleMLP(\n  (input_fc): QuantLinear(\n    in_features=30, out_features=256, bias=True\n    (input_quant): IdentityQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n    )\n    (output_quant): IdentityQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n    )\n    (weight_quant): WeightQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n      (tensor_quant): RescalingIntQuant(\n        (int_quant): IntQuant(\n          (float_to_int_impl): RoundSte()\n          (tensor_clamp_impl): TensorClampSte()\n          (delay_wrapper): DelayWrapper(\n            (delay_impl): _NoDelay()\n          )\n        )\n        (scaling_impl): StatsFromParameterScaling(\n          (parameter_list_stats): _ParameterListStats(\n            (first_tracked_param): _ViewParameterWrapper()\n            (stats): _Stats(\n              (stats_impl): AbsMax()\n            )\n          )\n          (stats_scaling_impl): _StatsScaling(\n            (affine_rescaling): Identity()\n            (restrict_clamp_scaling): _RestrictClampValue(\n              (clamp_min_ste): Identity()\n              (restrict_value_impl): FloatRestrictValue()\n            )\n            (restrict_scaling_pre): Identity()\n          )\n        )\n        (int_scaling_impl): IntScaling()\n        (zero_point_impl): ZeroZeroPoint(\n          (zero_point): StatelessBuffer()\n        )\n        (msb_clamp_bit_width_impl): BitWidthConst(\n          (bit_width): StatelessBuffer()\n        )\n      )\n    )\n    (bias_quant): BiasQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n    )\n  )\n  (hidden_fc): QuantLinear(\n    in_features=256, out_features=256, bias=True\n    (input_quant): IdentityQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n    )\n    (output_quant): IdentityQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n    )\n    (weight_quant): WeightQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n      (tensor_quant): RescalingIntQuant(\n        (int_quant): IntQuant(\n          (float_to_int_impl): RoundSte()\n          (tensor_clamp_impl): TensorClampSte()\n          (delay_wrapper): DelayWrapper(\n            (delay_impl): _NoDelay()\n          )\n        )\n        (scaling_impl): StatsFromParameterScaling(\n          (parameter_list_stats): _ParameterListStats(\n            (first_tracked_param): _ViewParameterWrapper()\n            (stats): _Stats(\n              (stats_impl): AbsMax()\n            )\n          )\n          (stats_scaling_impl): _StatsScaling(\n            (affine_rescaling): Identity()\n            (restrict_clamp_scaling): _RestrictClampValue(\n              (clamp_min_ste): Identity()\n              (restrict_value_impl): FloatRestrictValue()\n            )\n            (restrict_scaling_pre): Identity()\n          )\n        )\n        (int_scaling_impl): IntScaling()\n        (zero_point_impl): ZeroZeroPoint(\n          (zero_point): StatelessBuffer()\n        )\n        (msb_clamp_bit_width_impl): BitWidthConst(\n          (bit_width): StatelessBuffer()\n        )\n      )\n    )\n    (bias_quant): BiasQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n    )\n  )\n  (hidden_fc_2): QuantLinear(\n    in_features=256, out_features=128, bias=True\n    (input_quant): IdentityQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n    )\n    (output_quant): IdentityQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n    )\n    (weight_quant): WeightQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n      (tensor_quant): RescalingIntQuant(\n        (int_quant): IntQuant(\n          (float_to_int_impl): RoundSte()\n          (tensor_clamp_impl): TensorClampSte()\n          (delay_wrapper): DelayWrapper(\n            (delay_impl): _NoDelay()\n          )\n        )\n        (scaling_impl): StatsFromParameterScaling(\n          (parameter_list_stats): _ParameterListStats(\n            (first_tracked_param): _ViewParameterWrapper()\n            (stats): _Stats(\n              (stats_impl): AbsMax()\n            )\n          )\n          (stats_scaling_impl): _StatsScaling(\n            (affine_rescaling): Identity()\n            (restrict_clamp_scaling): _RestrictClampValue(\n              (clamp_min_ste): Identity()\n              (restrict_value_impl): FloatRestrictValue()\n            )\n            (restrict_scaling_pre): Identity()\n          )\n        )\n        (int_scaling_impl): IntScaling()\n        (zero_point_impl): ZeroZeroPoint(\n          (zero_point): StatelessBuffer()\n        )\n        (msb_clamp_bit_width_impl): BitWidthConst(\n          (bit_width): StatelessBuffer()\n        )\n      )\n    )\n    (bias_quant): BiasQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n    )\n  )\n  (output_fc): QuantLinear(\n    in_features=128, out_features=10, bias=False\n    (input_quant): IdentityQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n    )\n    (output_quant): IdentityQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n    )\n    (weight_quant): WeightQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n      (tensor_quant): RescalingIntQuant(\n        (int_quant): IntQuant(\n          (float_to_int_impl): RoundSte()\n          (tensor_clamp_impl): TensorClampSte()\n          (delay_wrapper): DelayWrapper(\n            (delay_impl): _NoDelay()\n          )\n        )\n        (scaling_impl): StatsFromParameterScaling(\n          (parameter_list_stats): _ParameterListStats(\n            (first_tracked_param): _ViewParameterWrapper()\n            (stats): _Stats(\n              (stats_impl): AbsMax()\n            )\n          )\n          (stats_scaling_impl): _StatsScaling(\n            (affine_rescaling): Identity()\n            (restrict_clamp_scaling): _RestrictClampValue(\n              (clamp_min_ste): Identity()\n              (restrict_value_impl): FloatRestrictValue()\n            )\n            (restrict_scaling_pre): Identity()\n          )\n        )\n        (int_scaling_impl): IntScaling()\n        (zero_point_impl): ZeroZeroPoint(\n          (zero_point): StatelessBuffer()\n        )\n        (msb_clamp_bit_width_impl): BitWidthConst(\n          (bit_width): StatelessBuffer()\n        )\n      )\n    )\n    (bias_quant): BiasQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n    )\n  )\n  (relu): QuantReLU(\n    (input_quant): IdentityQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n    )\n    (act_quant): ActQuantProxyFromInjector(\n      (_zero_hw_sentinel): StatelessBuffer()\n      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n        (activation_impl): ReLU()\n        (tensor_quant): RescalingIntQuant(\n          (int_quant): IntQuant(\n            (float_to_int_impl): RoundSte()\n            (tensor_clamp_impl): TensorClamp()\n            (delay_wrapper): DelayWrapper(\n              (delay_impl): _NoDelay()\n            )\n          )\n          (scaling_impl): ParameterFromRuntimeStatsScaling(\n            (stats_input_view_shape_impl): OverTensorView()\n            (stats): _Stats(\n              (stats_impl): AbsPercentile()\n            )\n            (restrict_clamp_scaling): _RestrictClampValue(\n              (clamp_min_ste): Identity()\n              (restrict_value_impl): FloatRestrictValue()\n            )\n            (restrict_inplace_preprocess): Identity()\n          )\n          (int_scaling_impl): IntScaling()\n          (zero_point_impl): ZeroZeroPoint(\n            (zero_point): StatelessBuffer()\n          )\n          (msb_clamp_bit_width_impl): BitWidthConst(\n            (bit_width): StatelessBuffer()\n          )\n        )\n      )\n    )\n  )\n) was passed"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit()\n",
    "print(np.array(np.mean(cross_val_score(model, dataset.X, dataset.y, cv=tscv))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred, y_prob  = [], [], []\n",
    "\n",
    "tscv = TimeSeriesSplit()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "    # for x, y in test_loader:\n",
    "        y = \n",
    "        y = list(y.numpy())\n",
    "        y_true += y\n",
    "\n",
    "        x = x.float()\n",
    "        outputs = model(x)\n",
    "\n",
    "        # predicted label\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted = list(predicted.cpu().numpy())\n",
    "        y_pred += predicted\n",
    "\n",
    "        # probability for each label\n",
    "        prob = list(outputs.cpu().numpy())\n",
    "        y_prob += prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9665924276169265\n"
     ]
    }
   ],
   "source": [
    "# calculating overall accuracy\n",
    "num_correct = 0\n",
    "\n",
    "for i in range(len(y_true)):\n",
    "    if y_true[i] == y_pred[i]:\n",
    "        num_correct += 1\n",
    "\n",
    "print(\"Accuracy: \", num_correct/len(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class TwoLayerMLP(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_hidden, d_out):\n",
    "        super(TwoLayerMLP, self).__init__()\n",
    "        self.d_in = d_in\n",
    "\n",
    "        self.linear1 = nn.QuantLinear(d_in, d_hidden, bias=True, weight_bit_width=4)\n",
    "        self.linear2 = nn.QuantLinear(d_hidden, d_out, bias=True, weight_bit_width=4)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X.view(-1, self.d_in)\n",
    "        X = self.linear1(X.float())\n",
    "        X = self.linear2(X)\n",
    "        return torch.nn.functional.log_softmax(X, dim=1)\n",
    "    \n",
    "    def load(self, model_path):\n",
    "        self.load_state_dict(torch.load(model_path))\n",
    "        \n",
    "        self.eval()\n",
    "    def predict(self, X):\n",
    "        outputs = self(X.float())\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.input_fc = nn.QuantLinear(input_size, 256, bias=True, weight_bit_width=4)\n",
    "        self.hidden_fc = nn.QuantLinear(256, 256, bias=True, weight_bit_width=4)\n",
    "        self.hidden_fc_2 = nn.QuantLinear(256, 128, bias=True, weight_bit_width=4)\n",
    "        self.output_fc = nn.QuantLinear(128, output_size, bias=False, weight_bit_width=4)\n",
    "        \n",
    "        self.relu = nn.QuantReLU(bit_width=2, max_val=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_1 = self.input_fc(x.float())\n",
    "        h_1 = torch.nn.functional.relu(x_1)\n",
    "        x_2 = self.hidden_fc(h_1)\n",
    "        x_3 = self.hidden_fc_2(x_2)\n",
    "        h_2 = torch.nn.functional.relu(x_3)\n",
    "        y_pred = self.output_fc(h_2)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_model(model, criterion, optimizer, dataloaders, num_epochs=25,\n",
    "        scheduler=None, log_interval=None):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # Store losses and accuracies accross epochs\n",
    "    losses, accuracies = dict(train=[], val=[]), dict(train=[], val=[])\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if log_interval is not None and epoch % log_interval == 0:\n",
    "            print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "            print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            nsamples = 0\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                nsamples += inputs.shape[0]\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels.long())\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if scheduler is not None and phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            #nsamples = dataloaders[phase].dataset.data.shape[0]\n",
    "            epoch_loss = running_loss / nsamples\n",
    "            epoch_acc = running_corrects.double() / nsamples\n",
    "\n",
    "            losses[phase].append(epoch_loss)\n",
    "            accuracies[phase].append(epoch_acc)\n",
    "            if log_interval is not None and epoch % log_interval == 0:\n",
    "                print('{} Loss: {:.4f} Acc: {:.2f}%'.format(\n",
    "                    phase, epoch_loss, 100 * epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        if log_interval is not None and epoch % log_interval == 0:\n",
    "            print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.2f}%'.format(100 * best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model, losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network, epochs, save_Model = False):\n",
    "    total_acc = 0\n",
    "    kfold = KFold(n_splits=5)\n",
    "    for fold, (train_index, test_index) in enumerate(kfold.split(x_train, y_train)):\n",
    "        ### Dividing data into folds\n",
    "        x_train_fold = x_train[train_index]\n",
    "        x_test_fold = x_train[test_index]\n",
    "        y_train_fold = y_train[train_index]\n",
    "        y_test_fold = y_train[test_index]\n",
    "\n",
    "        train = torch.utils.data.TensorDataset(x_train_fold, y_train_fold)\n",
    "        test = torch.utils.data.TensorDataset(x_test_fold, y_test_fold)\n",
    "        train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "        test_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            print('\\nEpoch {} / {} \\nFold number {} / {}'.format(epoch + 1, epochs, fold + 1 , kfold.get_n_splits()))\n",
    "            correct = 0\n",
    "            network.train()\n",
    "            for batch_index, (x_batch, y_batch) in enumerate(train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                out = network(x_batch)\n",
    "                loss = loss_f(out, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                pred = torch.max(out.data, dim=1)[1]\n",
    "                correct += (pred == y_batch).sum()\n",
    "                if (batch_index + 1) % 32 == 0:\n",
    "                    print('[{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy:{:.3f}%'.format(\n",
    "                        (batch_index + 1)*len(x_batch), len(train_loader.dataset),\n",
    "                        100.*batch_index / len(train_loader), loss.data, float(correct*100) / float(batch_size*(batch_index+1))))\n",
    "        total_acc += float(correct*100) / float(batch_size*(batch_index+1))\n",
    "    total_acc = (total_acc / kfold.get_n_splits())\n",
    "    print('\\n\\nTotal accuracy cross validation: {:.3f}%'.format(total_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "torch.Size([50, 30])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n",
      "Total number of parameters = 2060\n",
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 2.1363 Acc: 27.14%\n",
      "val Loss: 1.3091 Acc: 53.01%\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.1823 Acc: 62.08%\n",
      "val Loss: 0.9475 Acc: 77.51%\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 0.8990 Acc: 80.59%\n",
      "val Loss: 0.7804 Acc: 79.29%\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 0.7422 Acc: 85.28%\n",
      "val Loss: 0.6002 Acc: 90.65%\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 0.6220 Acc: 90.11%\n",
      "val Loss: 0.5368 Acc: 90.87%\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 0.5559 Acc: 90.26%\n",
      "val Loss: 0.4805 Acc: 90.65%\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 0.5134 Acc: 90.26%\n",
      "val Loss: 0.4420 Acc: 91.76%\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 0.4712 Acc: 91.23%\n",
      "val Loss: 0.4121 Acc: 91.98%\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 0.4407 Acc: 91.15%\n",
      "val Loss: 0.3934 Acc: 92.65%\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 0.4178 Acc: 90.56%\n",
      "val Loss: 0.3674 Acc: 92.43%\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 0.3956 Acc: 90.78%\n",
      "val Loss: 0.3538 Acc: 93.10%\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 0.3838 Acc: 91.23%\n",
      "val Loss: 0.3374 Acc: 91.98%\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 0.3743 Acc: 91.30%\n",
      "val Loss: 0.3454 Acc: 91.09%\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 0.3592 Acc: 89.96%\n",
      "val Loss: 0.3195 Acc: 91.76%\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 0.3467 Acc: 91.45%\n",
      "val Loss: 0.3075 Acc: 93.10%\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 0.3386 Acc: 92.04%\n",
      "val Loss: 0.3017 Acc: 92.87%\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 0.3321 Acc: 92.12%\n",
      "val Loss: 0.2922 Acc: 92.87%\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 0.3257 Acc: 91.52%\n",
      "val Loss: 0.2916 Acc: 92.87%\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 0.3178 Acc: 92.42%\n",
      "val Loss: 0.2838 Acc: 93.32%\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 0.3116 Acc: 92.12%\n",
      "val Loss: 0.2850 Acc: 93.54%\n",
      "\n",
      "Training complete in 0m 2s\n",
      "Best val Acc: 93.54%\n",
      "False\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de5xVdb3/8dcHGO4glxlQuYhXBiVRGy9FJfw0RbOMk5XoCW9Fmlae6pSWibfULlon85IaWuZR8nijUpG8ZqUymBcQuUgiIyhjmKCoCHx+f3z2bjbDntlrZvZl2Pv9fDzWY++91nft/WE7ftba3/VZ36+5OyIiUr66lDoAEREpLCV6EZEyp0QvIlLmlOhFRMqcEr2ISJnrVuoAsqmurvZRo0aVOgwRkW3GvHnzXnf3mmzbOmWiHzVqFPX19aUOQ0Rkm2Fmy1vapq4bEZEyp0QvIlLmlOhFRMqcEr2ISJlTohcRKXNK9CIiZU6JXkSkzJVNot+4ES65BO6/v9SRiIh0LmWT6Lt2hZ/8BO68s9SRiIh0LmWT6M2gthYWLix1JCIinUvZJHqIRP/CC6WOQkSkcymrRD9mDLz2GrzxRqkjERHpPMoq0dfWxqPO6kVEmijRi4iUubJK9KNGQffuSvQiIpnKKtF36wZ77KFELyKSqawSPajEUkSkubJM9MuWwXvvlToSEZHOoewS/ZgxsGkTvPhiqSMREekcyi7Rpytv1H0jIhJyJnozG2FmD5nZQjNbYGZfz9LGzOznZrbUzJ41s/0ytp1gZktSywn5/gc0t8ce8agLsiIioVuCNhuBb7r7U2bWD5hnZnPc/fmMNkcAu6eWA4GrgQPNbBAwHagDPLXvLHcv2L2rffvCiBFK9CIiaTnP6N19lbs/lXq+DlgIDGvW7GjgNx4eBwaY2Q7A4cAcd1+TSu5zgEl5/RdkMWaMEr2ISFqb+ujNbBSwL/BEs03DgBUZrxtS61pan+29p5lZvZnVNzY2tiWsraQHN3Pv0NuIiJSFxInezPoCtwNnuvva5puz7OKtrN96pfu17l7n7nU1NTVJw8qqthbeegteeaVDbyMiUhYSJXozqyKS/M3ufkeWJg3AiIzXw4GVrawvKI15IyLSJEnVjQG/Aha6++UtNJsFTE1V3xwEvOnuq4DZwGFmNtDMBgKHpdYV1Jgx8agSSxGRZFU344EvAM+Z2dOpdd8FRgK4+zXAPcCRwFJgPXBSatsaM7sQmJva7wJ3X5O/8LMbOhS2205n9CIikCDRu/tjZO9rz2zjwOktbJsBzGhXdO2UnlZQiV5EpAzvjE1TiaWISCjbRF9bCytXwptvljoSEZHSKutED7BoUWnjEBEptbJP9Oq+EZFKV7aJfpddoKpKJZYiImWb6KuqYLfddEYvIlK2iR5UYikiAhWQ6JcuhfffL3UkIiKlU9aJfswY2LhR0wqKSGUr60SvyhsRkTJP9KNHx6MSvYhUsrJO9P37w7BhKrEUkcpW1okeVHkjIlIxiV7TCopIpaqIRL92Lbz6aqkjEREpjbJP9JptSkQqXdknepVYikilyznDlJnNAI4CVrv72Czb/xs4PuP9xgA1qWkEXwLWAZuAje5el6/Ak9pxR+jXT4leRCpXkjP6G4FJLW109x+7+z7uvg9wNvBIs3lhJ6a2Fz3JQ9O0guq6EZFKlTPRu/ujQNIJvacAt3QoogJQiaWIVLK89dGbWW/izP/2jNUO3G9m88xsWo79p5lZvZnVNzY25issIBJ9QwOsW5fXtxUR2Sbk82LsJ4G/NOu2Ge/u+wFHAKeb2cda2tndr3X3Onevq6mpyWNYmlZQRCpbPhP9sTTrtnH3lanH1cCdwAF5/LzE0iWW6r4RkUqUl0RvZtsBBwN3Z6zrY2b90s+Bw4D5+fi8ttp1V+jaVYleRCpTkvLKW4AJQLWZNQDTgSoAd78m1WwycL+7v52x61DgTjNLf87/uvt9+Qs9ue7dI9kr0YtIJcqZ6N19SoI2NxJlmJnrlgHj2htYvqnEUkQqVdnfGZs2ZgwsWRIzTomIVJKKSfS1tTF37D/+UepIRESKq6ISPaj7RkQqT8Ulel2QFZFKUzGJfsAA2H57JXoRqTwVk+hBY96ISGWquES/cKGmFRSRylJRiX7MGPjXv2D16lJHIiJSPBWV6HVBVkQqUUUmepVYikglqahEP3w49O6tM3oRqSwVlei7dFHljYhUnopK9KBELyKVpyIT/fLl8PbbuduKiJSDikv06dmmFi8ubRwiIsVScYleJZYiUmkqLtHvtltclFWJpYhUiopL9D17ws4764xeRCpHzkRvZjPMbLWZZZ3Y28wmmNmbZvZ0ajk3Y9skM1tkZkvN7Kx8Bt4RY8Yo0YtI5UhyRn8jMClHmz+7+z6p5QIAM+sKXAkcAewJTDGzPTsSbL7U1sbF2E2bSh2JiEjh5Uz07v4osKYd730AsNTdl7n7BuBW4Oh2vE/e1dbCe+/BSy+VOhIRkcLLVx/9h8zsGTO718z2Sq0bBqzIaNOQWpeVmU0zs3ozq29sbMxTWNmlSyzVfSMilSAfif4pYCd3HwdcAdyVWm9Z2rY4Ery7X+vude5eV1NTk4ewWjZ6dDwq0YtIJehwonf3te7+Vur5PUCVmVUTZ/AjMpoOB1Z29PPyYfBgqKlRiaWIVIYOJ3oz297MLPX8gNR7/hOYC+xuZjubWXfgWGBWRz8vXzTmjYhUim65GpjZLcAEoNrMGoDpQBWAu18DHAOcZmYbgXeAY93dgY1mdgYwG+gKzHD3BQX5V7TDmDFw++2ljkJEpPByJnp3n5Jj+y+AX7Sw7R7gnvaFVli1tfDPf8Lrr0N1damjEREpnIq7MzZNs02JSKWo+ESvfnoRKXcVm+h32inGvVGiF5FyV7GJvkuXqKdX142IlLuKTfSgEksRqQwVnejHjInxbt55p9SRiIgUTkUn+tpacIclS0odiYhI4VR8ogf104tIeavoRL/HHmCmfnoRKW8Vneh79YJRo5ToRaS8VXSih+i+UdeNiJQzJfpaWLQINm8udSQiIoWhRF8L774LL79c6khERAqj4hO9phUUkXJXXol+5ky47LI27aISSxEpd+WV6O+/H6ZPhzffTLxLdTUMGqQzehEpX+WV6E8/Hd5+G37zm8S7mEX3jRK9iJSr8kr0++0HBx4IV10VYxskpBJLESlnORO9mc0ws9VmNr+F7ceb2bOp5a9mNi5j20tm9pyZPW1m9fkMvEVf+Uqcnj/0UOJdamuhsTGmFhQRKTdJzuhvBCa1sv0fwMHuvjdwIXBts+0T3X0fd69rX4ht9LnPwYQJsGlT4l3SF2QXLSpMSCIipZRkcvBHzWxUK9v/mvHycWB4x8PqgJ4923Q2D1uWWH74wwWISUSkhPLdR38KcG/GawfuN7N5ZjattR3NbJqZ1ZtZfWNjY8cjWbsWnnwyUdNRo6B7d/XTi0h5ynlGn5SZTSQS/UcyVo9395VmNgSYY2YvuPuj2fZ392tJdfvU1dUlv5LakpNOgr/+NW55rapqtWnXrjGSpSpvRKQc5eWM3sz2Bq4Hjnb3f1/SdPeVqcfVwJ3AAfn4vEROPhlefRXuvDNRc5VYiki56nCiN7ORwB3AF9x9ccb6PmbWL/0cOAzIWrlTEJMmRZ/MVVclal5bC8uWxbg3IiLlJEl55S3A34DRZtZgZqeY2almdmqqybnAYOCqZmWUQ4HHzOwZ4Engj+5+XwH+Ddl17QqnnQaPPAILFuRsXlsbI1guXVqE2EREiihJ1c2UHNu/CHwxy/plwLit9yiik0+Gc8+Fe++FvfZqtWm6xPKFF2Ds2CLEJiJSJHm7GNspVVfHKfrw3BWfo0fH44IFcMwxBY5LRKSIymsIhGzSST7HDVR9+sToCTNmwHvvFSEuEZEiKf9ED3D++ZHFc4x/c+GFUY15zTVFiktEpAgqI9EPHw7z5sFjj7Xa7NBDYeJE+MEPYN26IsUmIlJglZHop0yBAQPgyitbbWYGl1wSA5z99KdFik1EpMAqI9H37h13yt5+e9xE1YoDD4TJk+EnP4HXXy9SfCIiBVQZiR7g1FNh40a4/vqcTS+6KOYvueSSIsQlIlJglZPo99gjrrIed1zOpnvuCVOnRk/PihVFiE1EpIAqJ9EDfPnLsMsuiZqed14U6Zx/fmFDEhEptMpK9ACPPhpZPIeddooRFG64QYOdici2rfIS/Z//HKfpixfnbPrd78Z13HPOKUJcIiIFUnmJ/otfjPHpr746Z9MhQ+Cb34xinblzixCbiEgBVF6iHzo0BrO54YYorcnhG9+AwYPj7F5EZFtUeYke4CtfgTffhFtuydm0f3/43vfgT3+CBx4oQmwiInlWmYl+/Hg48sgYsz6B006DESPg7LNzDpcjItLpVGaiN4M//jHulk2gZ88o1Jk7N/HMhCIinUZlJvq099+HJ59M1HTq1Jic5Jxz4gZbEZFtRaJEb2YzzGy1mWWd89XCz81sqZk9a2b7ZWw7wcyWpJYT8hV4Xnz/+/DRj8Lq1TmbdusWo1ouXAg33VSE2ERE8iTpGf2NwKRWth8B7J5apgFXA5jZIGA6cCBwADDdzAa2N9i8mzoVNmyI2UYSmDwZ9t8fpk/XJOIisu1IlOjd/VFgTStNjgZ+4+FxYICZ7QAcDsxx9zXu/gYwh9YPGMW1554wYUKMgZNjBipoGsZ4xQpNTiIi24589dEPAzKH/2pIrWtp/VbMbJqZ1ZtZfWNjY57CSuD002H5crjnnkTNDzkkJijR5CQisq3IV6K3LOu8lfVbr3S/1t3r3L2upqYmT2ElcPTRsOOOcPfdiXe5+OIYq/7yywsYl4hInuQr0TcAIzJeDwdWtrK+86iqgr/8Ba69NvEu++8Pn/lMTE5SzB8fIiLtka9EPwuYmqq+OQh4091XAbOBw8xsYOoi7GGpdZ3LqFHQpQts3px4l4sugvXr4+xeRKQzS1peeQvwN2C0mTWY2SlmdqqZnZpqcg+wDFgKXAd8BcDd1wAXAnNTywWpdZ3Pb38Lo0fDO+8kal5bCyeeCFddBS+/XNjQREQ6wrwT3tNfV1fn9fX1xf3Qhx+GiRPhl7+EadMS7fLyyzFx1XHHJa7QFBEpCDOb5+512bZV9p2xmQ4+GD70ITjzTHj88US7jBwZRTu//jU8/3yB4xMRaScl+jQzuOuuqMD5xCcSTyt19tnQp0/cZCsi0hkp0WcaMgRmz4YePeCJJxLtUl0N3/oW3HFH4mFzRESKSn302axbB/36tan5rrvCBz6gMetFpDTUR99W6SQ/ezZ88pPw3ns5m3/ve/Dgg3D//UWIT0SkDZToW/P66/CHP8AXvpCzxv7UU+Os/vjjdWFWRDoXJfrWHH983P56221RjdNKN1ePHnDffTGc8aGHwtKlRYxTRKQVSvS5fPObMUP4FVfAj37UatPddos++vffj8HPli8vUowiIq1Qok/ixz+GKVNgyZKck8buuWf0069dG8l+Zeca2UdEKpASfRJdusRdUdddF/X2Ofrr990X7r0XXnstunE08JmIlJISfVJVVZHkly6FffbJWTR/0EFxHfcf/4DDDoM33ihSnCIizSjRt1XfvvDWW3H37OLFrTY9+GC4805YsACOOEITlYhIaSjRt9X220d9PcDhh8Orr7bafNIk+N3voL4+SvLXry9CjCIiGZTo22P33WPqwdWr41R97dpWm3/603DTTfDoozHBeI77r0RE8kqJvr323x9uvx369496yhymTIHrr4+KnM9/PtEuIiJ5oUTfEZMmxTj2gwfDhg05q3FOPjnK8e++G6ZOhU2bihOmiFS2bqUOYJtnFn0xRx4Z1TiXXdZq8zPOgLffhrPOgt69o2Kziw63IlJASvT50L07jB0Ll18Ow4fDf/1Xq82/851I9hdeGMn+5z+P44WISCEkSvRmNgn4H6ArcL27X9ps+0+BiamXvYEh7j4gtW0T8Fxq28vu/ql8BN6pmMFPfwqvvBJDJuyxR5RftuL886MC57LLItlfeqmSvYgURs5Eb2ZdgSuBjwMNwFwzm+Xu/x6j0d3/K6P9V4F9M97iHXffJ38hd1JdusBvfhN3SE2ZAn/7G+y1V4vNzWJkhfXrYwidPn3g3HOLGK+IVIwkvcMHAEvdfZm7bwBuBY5upf0U4JZ8BLfN6d07rrTuuWeiK61m8ItfwAknwPTpObv3RUTaJUnXzTBgRcbrBuDAbA3NbCdgZ+DBjNU9zawe2Ahc6u53tbDvNGAawMiRIxOE1UkNHx5n8+l+mE2boGvXFpt36RJll+vXx5SEmzfHo7pxRCRfkiT6bCmnpSEcjwX+z90zT2dHuvtKM9sFeNDMnnP3F7d6Q/drgWshphJMEFfnZRajXH7ta5HBr7++1czdrRvcfHPs8u1vwzPPRDVOr15FjFlEylaSrpsGYETG6+FAS4PvHkuzbht3X5l6XAY8zJb99+XLDAYOhBkz4kJtDlVVMHNmVOL87//C+PEaz15E8iNJop8L7G5mO5tZdyKZz2reyMxGAwOBv2WsG2hmPVLPq4HxQOVMtHfeefCZz8B//zf88Y85m3fpAuecA7NmwYsvQl0dPPRQ4cMUkfKWM9G7+0bgDGA2sBD4nbsvMLMLzCyzVHIKcKv7FjNzjAHqzewZ4CGij75yEn16HPt99olKnAULEu121FEwdy7U1MDHPw4/+1nO+U5ERFpk3gkzSF1dndfX15c6jPxpaIAJEyJjH3VU4t3Wro2KnLvuivnJf/lL9duLSHZmNs/d67Jt0833xTB8OCxc2KYkDzFe2u23x81VN90EH/kIvPxygWIUkbKlRF8sVVXxeN11cNppiftiunSJG6l+//uY3OqDH4xx1EREklKiL7YVK+CaaxJV4mQ66qiYvbC6Ouah/fnP1W8vIsko0RdbGytxMo0eDU88EcPofP3rcOKJ8M47BYlSRMqIEn2xtbMSJ61//5iH9vzzY2idj35U/fYi0jol+lLo0yfGxOnXDx58MHf7ZtL99rNmwZIlUW//yCMFiFNEyoISfakMHx5n81/9arvf4pOfjH77QYPgkEPUby8i2SnRl9KAAfH42GMxklk7snTzfvvDD495aZXwRSRNib4zmDMnxihuYyVO2nbbRb/9T34Czz4byX7s2Kjk1MVaEVGi7wymT2+qxPnFL9qVnbt0icmtli+HG2+Msv1p02DkSPj+92HVqvyHLSLbBiX6ziBdiTN+fPTZjxwZ4x+0Q48eMWzC3/8eA6J9+MPwgx/ATjvB1Knw1FN5jl1EOj0l+s6iT58onXn44eiv798/1l98cXTtbN7cprczi+F17r4bFi+GU0+FO+6IO2sPPjjGz0kwCZaIlAENataZvfUW7L47vPpqXHU9/fQ4XU8fBNroX/+CX/0qqnNefhl22SXmRjnppHa/pYh0EhrUbFvVty+89BL89rcxicnXvgbDhsG997br7QYMiH78F1+E226D7beHM8+EESPgG9+IjxKR8qNE39n16AHHHx/z0M6dC8ccA/vtF9seeSTKbTZubNNbdusWb/OXvzSVZl5xBey6a4x/f/nl8PzzKtEUKRfqutmWfe5zcWo+YkSMiPnFL8ZsJe3Q0ABXXx1998+npoYZORKOOAImTYobsvr1y2PsIpJXrXXdKNFvyzZuhD/8IUoyH3ggzv6//W244IIOve3y5XDffbH86U9xqaCqKsbDnzQpkv/Ysa3Ody4iRaZEXwmefx6uugrGjYMvfSmy849+FFNT7b57u992w4bo4rnvvrg08NxzsX7YsKakf+ihcdOWiJROhxO9mU0C/gfoClzv7pc2234i8GPgldSqX7j79altJwDnpNZf5O6/zvV5SvR5cP/9kYU3b476/BNPhM9+tsMZuaEBZs+OpD9nTpT7d+0a9frpbp5x4+LWABEpng4lejPrCiwGPg40AHOBKZmTfKcSfZ27n9Fs30FAPVAHODAP+KC7v9HaZyrR58nKlVGxc+ONMZVhr16waFH06efB++/D449H0r/vvrhJC2Do0BiGYdKkuLhbXZ2XjxORVnS0vPIAYKm7L3P3DcCtwNEJP/twYI67r0kl9znApIT7SkftuGP02S9YEOU1Z5/dlOTPOgvOOSfGOW6nqqoYD//ii+OO25Ur45gycWJcOjjuOBgyBA48MEZ5+NvfdJOWSCkkSfTDgBUZrxtS65r7jJk9a2b/Z2bpU8ak+2Jm08ys3szqGxsbE4QliZnBAQfEoDcQdZMvvgiXXAJ77BFXWa+7Dt58s0Mfs8MOcT/XLbfA6tVxtj99enTtXHRRdO/U1MDnPw833BAHBhEpvCSJPlttRfP+nt8Do9x9b+BPQLofPsm+sdL9Wnevc/e6mnaWCEpCZlGWuWIF/PCHsGZNjIB20UWx/d1346prG4ddyNS1a9OZ/F//Co2NMHMmfPrT8Oc/w8knxwXdcePiR8eDD8J77+Xp3yciW0jSR/8h4Dx3Pzz1+mwAd7+khfZdgTXuvp2ZTQEmuPuXU9t+CTzs7re09pnqoy8y97gZa+jQGP3sT3+KzvWamuiH+X//L5bddstLTaV7HEfSJZyPPRb9/X36xFl/XV3TMmKEyjhFkujoxdhuxMXYQ4iqmrnAce6+IKPNDu6+KvV8MvAddz8odTF2HpC6lZOniIuxa1r7TCX6EmtsjInLH3ooTrUbGmJ9fX2MirZ8ebzeaae8fNy6dfFR990X/fjz5zfd7FtTs2Xir6uLSw8isqV8lFceCfyMKK+c4e4/MLMLgHp3n2VmlwCfAjYCa4DT3P2F1L4nA99NvdUP3P2GXJ+nRN+JuMPSpTGq5kknxfgJX/1q3KS1885NZ/sTJ0YnfR68+25MoFJf37QsWNDUk7TDDlsm/g9+MH6MiFQy3TAl+bV4cRTTP/hgHAD+9a/Ivq+8Ev0ss2fHIGx77w09e+blI9evh6ef3jL5v/BC03g8I0ZEwh83Lgb6HD06rjP37ZuXjxfp9JTopXA2bYJnnokSmqOOinU77xxDYXbrBnvtFRn4E5+A//iPvH70unVRuz9vXiT+uXPjx0fmn/SwYU2Jf/RoqK2Nx5EjdVOXlBcleimul16K7Ju5HHMMXHNNHBg+8hEYMyYOAOnT8F698vLR774byX7RoqblhRfiMbN6tGfPGBki8yCQXjScg2yLlOiltNwjA/fqBf/8J/znf8Yp+Ouvx/auXeFnP4MzzohuoDlzYNSoWKqr81bps3r1lgeA9EHgH//Y8kauIUOi22ePPeJgkH6+6655Ox6J5F1rib5bsYORCmTWlCEHD44xE9yjjj99xl+X+vt89tkYfjmtd++o7rnyyrjgu2JFlOaMGhXrhwxJdCAwiwu2Q4fCxz625bYNG+L+sUWL4vJDernnnpjcK/M9Ro7cMvmnDwajRkVPlUhnpD9NKY101hw5EiZPblp/wAHR5//SS1sugwbF9kcfjV8Eab16RcK/7bYYO3npUli2LJ7vsEOig0D37tGTNGbM1tvWro1RItLJP/385pu37AqqqoqpGUeOjB8hNTXxmF4yXw8eHO1FikWJXjqXnj2jWmfvvbNvnzw5zvrTB4Dly+Nx8ODYPnNmjOEDcXD4wAci6V98cUyMu3lzm67C9u/fdCkhk3vcbpB5EFi8OAqPli2LXqnWRpQYMKDlg8CAAS0vPXokDl3k39RHL+XljTeiDnP+/Lj9dv786Jd55ZXoWzn9dPj975sOAGPHxkFl3Li8h7JhQ1ySeP31WBobm5639DrXMBA9e0bCHzgw+4GgujpuKNtxx/hBs+OOccexlD/10UvlGDgw+vInTmxa597UhTN+fJxqz58fQz1s2BBdP+mZ0c85B1ataurQ33776JPZf/+t3yuH7t0j2Sa9jyx9zfqNN+KadGtLuk36V0V6fbbpg/v3b0r6zQ8Cmc97904Wp2x7lOil/GUm5uOOiwVigJ2lS5uqfyCy5mOPRYlOOmsefHDcGAZx5r9mTdOBYOjQKBc95ZTYPndu9L/suGObbxZLX7Pu1at9wzy4R7JftSpua1i5csvnK1fGAHMrV2b/5bDddnFcq6mJZciQlh8HD9bF522J/lNJ5aqq2voK7MyZ8bh5c5w2Z5bdQMzStWwZvPZaLM88Exn2lFPiceJEePvtaFtdDcOHx3SO3/hGbP/tbyOLDx8eS1v7VTZvjmki162LK8Vr10bdZ3U11rCCgU88wcCxY9lzwm4tZmL3+KdlOxC89lr8Sli0KI53r7++5Q1omQYN2vogMHhwTCLfv3/Tku11z54arK6YlOhFsunSJbJW+iJvWnpM/5bcfXcMArdiRTw2NEQfDkSX0dSpW7YfMCDGcj7zzEje3/1uJO90Il+3LiaJmTwZnnwyxn5u7tZbY5D/JUviQARNpURjx0Z3VG1t/ILp1g0zY9CgSNRjx7b+z9m0KX7ANDbGj5zMx8znzz8fj2vWJBvdulu37AeCvn1j6dNn6yXb+sx1vXvHLRmyNSV6kXwxg0MOaXl7v36RjNMHgPQyenRsX7EizvgzT38HDmwqtRkxAs49d8vs2K8f7JcaHHb8+JjqK30Rev78KEdN3w12ww3wrW/FsBTpC9Fjx0bXUwvlPF27NnXl7Lln7q/AHd55p+nHRuYxq6XX6XWNjfFj6e23m5YNGxJ+9yk9e259MOjdO/uBI9u2vn23/GrTj9t6OayqbkQqxV/+El1T6Yqk9LWJNWvigPLrX8esMOl6z3SGP+KIaJf6RVDMPpf3398y8be0vPXWlq/Xr2+5bXrbO+8kj6NHj62Tf/qx+fP0waP5Y/N1+e6+UtWNiMQZ//jx8Tw9JsQLL0SSh5hA/p574tQ6fSF6u+3iCi/EtYa77tqy+H/33eGqq2L7vfdG2969m5ZBg5qug6xdG6fGbchwVVVNpaP5tnnz1geE9OWPzJ6zlh5XrYp7J9Kv169v2+ebbX0wGDYsBn/NNyV6kUqUOSZE2qWXxuIe2auxMTJY2mc+E6WomTcBpMtSIW5Ke+yxLT9nv/1iiAuIeQvmzWvKcL17w4QJ8Lvfxfbjj4+rxJk3Buy7b9N1h8cea7qRYMCAOAh1oE+lS5emawL5sIrMz18AAAfbSURBVHHj1r8aWnpsaVuhSlyV6EVkS2aRRJsP4/nZzzYl3WzuuCPuEFu/vmnJLDE988y4JpG5fdddm7Zv2hS/MtI3BrzxRgxtnf7MT30q1mU65RS4/vp4fsghcVHBrGmZPDnmQ3733aYxlDK3f+5zMGVKfN6XvhQHjsy+mMMOg4MOilgfeWTrfpqMg023btm/ts5AiV5E8iPdp9+SzDGKsrn11i1fu0cnfdrvf7/13WTpsqF0V9O6dbFfekmXum7eHAeZzG3ucX0ivf/zz8fV33T/zDvvRDI/6KAYauPII7eO+Zpr4MtfjmE5jj46DmzucdDavBmuuCL2+/Of4dhjY13mMnMmHHoozJoVB5y//z1GysuzRInezCYB/0NMJXi9u1/abPs3gC8SUwk2Aie7+/LUtk3Ac6mmL7v7p/IUu4iUM7Om0lRour6QTbdu8MADLW/v3TsqklpSXR3zVWbauLHpJoKddopRUzM76deta4qpVy/46Efjl0OXLvHLIl2im37/I4+MdZlL+rbpXXaB004r2M+BJJODdyUmB/840EBMDj7F3Z/PaDMReMLd15vZacAEd/98attb7t6mXjBV3YiItE1rVTdJhvE7AFjq7svcfQNwK3B0ZgN3f8jd09ecHweGdyRgERHJnySJfhiwIuN1Q2pdS04B7s143dPM6s3scTP7dDtiFBGRDkjSR5+t4DVrf4+Z/SdQBxycsXqku680s12AB83sOXd/Mcu+04BpACNHjkwQloiIJJHkjL4BGJHxejiwsnkjMzsU+B7wKXf/99h47r4y9bgMeBjYN9uHuPu17l7n7nU1rV25FxGRNkmS6OcCu5vZzmbWHTgWmJXZwMz2BX5JJPnVGesHmlmP1PNqYDzwPCIiUjQ5u27cfaOZnQHMJsorZ7j7AjO7AKh391nAj4G+wG0WtzanyyjHAL80s83EQeXSzGodEREpPA1qJiJSBjpaXikiItuwTnlGb2aNwPJ27l4NvJ6zVekovo5RfB2j+DqmM8e3k7tnrWTplIm+I8ysvqWfL52B4usYxdcxiq9jOnt8LVHXjYhImVOiFxEpc+WY6K8tdQA5KL6OUXwdo/g6prPHl1XZ9dGLiMiWyvGMXkREMijRi4iUuW020ZvZJDNbZGZLzeysLNt7mNnM1PYnzGxUEWMbYWYPmdlCM1tgZl/P0maCmb1pZk+nlnOLFV/q818ys+dSn73VbcgWfp76/p41s/2KGNvojO/laTNba2ZnNmtT1O/PzGaY2Wozm5+xbpCZzTGzJanHgS3se0KqzRIzO6GI8f3YzF5I/fe708wGtLBvq38LBYzvPDN7JeO/YZa5+nL/v17A+GZmxPaSmT3dwr4F//46zN23uYUYc+dFYBegO/AMsGezNl8Brkk9PxaYWcT4dgD2Sz3vR8zQ1Ty+CcAfSvgdvgRUt7L9SGJeAQMOImYQK9V/61eJm0FK9v0BHwP2A+ZnrPsRcFbq+VnAD7PsNwhYlnocmHo+sEjxHQZ0Sz3/Ybb4kvwtFDC+84BvJfjv3+r/64WKr9n2y4BzS/X9dXTZVs/oc856lXr969Tz/wMOsdSIa4Xm7qvc/anU83XAQlqfrKUzOhr4jYfHgQFmtkMJ4jgEeNFTcxCXirs/Cqxptjrzb+zXQLaJdQ4H5rj7Gnd/A5gDTCpGfO5+v7unZs0u7cxvLXx/SST5f73DWosvlTc+B9yS788tlm010SeZ9erfbVJ/7G8Cg4sSXYZUl9G+wBNZNn/IzJ4xs3vNbK+iBhaTx9xvZvNSk74019aZxQrlWFr+H6yU3x/AUHdfBXFwB4ZkadNZvseT2XLmt0y5/hYK6YxU19KMFrq+OsP391HgNXdf0sL2Un5/iWyriT7JrFeJZ8YqFDPrC9wOnOnua5ttforojhgHXAHcVczYgPHuvh9wBHC6mX2s2fbO8P11Bz4F3JZlc6m/v6Q6w/f4PWAjcHMLTXL9LRTK1cCuwD7AKqJ7pLmSf3/AFFo/my/V95fYtprok8x69e82ZtYN2I72/XRsFzOrIpL8ze5+R/Pt7r7W3d9KPb8HqLKYnKUovGnmr9XAncRP5EyJZhYrsCOAp9z9teYbSv39pbyW7s5KPa7O0qak32Pq4u9RwPGe6lBuLsHfQkG4+2vuvsndNwPXtfC5pf7+ugH/AcxsqU2pvr+22FYTfc5Zr1Kv0xUOxwAPtvSHnm+pPr1fAQvd/fIW2myfvmZgZgcQ/y3+WaT4+phZv/Rz4qLd/GbNZgFTU9U3BwFvprspiqjFM6lSfn8ZMv/GTgDuztJmNnCYxWxrA4nvenYxgjOzScB3iJnf1rfQJsnfQqHiy7zmM7mFz03y/3ohHQq84O4N2TaW8vtrk1JfDW7vQlSFLCauyH8vte4C4o8aoCfxk38p8CSwSxFj+wjx8/JZ4OnUciRwKnBqqs0ZwAKiiuBx4MNFjG+X1Oc+k4oh/f1lxmfAlanv9zmgrsj/fXsTiXu7jHUl+/6IA84q4H3iLPMU4prPA8CS1OOgVNs64PqMfU9O/R0uBU4qYnxLif7t9N9gugptR+Ce1v4WihTfTam/rWeJ5L1D8/hSr7f6f70Y8aXW35j+m8toW/Tvr6OLhkAQESlz22rXjYiIJKRELyJS5pToRUTKnBK9iEiZU6IXESlzSvQiImVOiV5EpMz9f9Rody9KiQmkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "D_in = df.shape[1]-1\n",
    "D_out = len(dances)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = 64, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = 64, shuffle = False)\n",
    "\n",
    "dataloaders = dict(train=train_loader, val=test_loader)\n",
    "\n",
    "model = TwoLayerMLP(D_in, 50, D_out)\n",
    "print(next(model.parameters()).is_cuda)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "\n",
    "# Explore the model\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "\n",
    "print(\"Total number of parameters =\", np.sum([np.prod(parameter.shape) for parameter in model.parameters()]))\n",
    "\n",
    "model, losses, accuracies = train_val_model(model, criterion, optimizer, dataloaders,\n",
    "                       num_epochs=20, log_interval=1)\n",
    "\n",
    "print(next(model.parameters()).is_cuda)\n",
    "\n",
    "_ = plt.plot(losses['train'], '-b', losses['val'], '--r')\n",
    "# torch.save(model.state_dict(), 'models/mod-%s.pth' % model.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerMLP(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_hidden, d_out):\n",
    "        super(TwoLayerMLP, self).__init__()\n",
    "        self.d_in = d_in\n",
    "\n",
    "        self.linear1 = nn.QuantLinear(d_in, d_hidden, bias=True, weight_bit_width=4)\n",
    "        self.linear2 = nn.QuantLinear(d_hidden, d_out, bias=True, weight_bit_width=4)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X.view(-1, self.d_in)\n",
    "        X = self.linear1(X.float())\n",
    "        X = self.linear2(X)\n",
    "        return torch.nn.functional.log_softmax(X, dim=1)\n",
    "    \n",
    "    def load(self, model_path):\n",
    "        self.load_state_dict(torch.load(model_path))\n",
    "        \n",
    "        self.eval()\n",
    "    def predict(self, X):\n",
    "        outputs = self(X.float())\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "torch.Size([50, 30])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n",
      "Total number of parameters = 2060\n",
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 2.0427 Acc: 32.34%\n",
      "val Loss: 2.1297 Acc: 29.84%\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.2935 Acc: 56.28%\n",
      "val Loss: 0.9693 Acc: 68.60%\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 0.8991 Acc: 71.97%\n",
      "val Loss: 0.8223 Acc: 74.39%\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 0.7732 Acc: 78.22%\n",
      "val Loss: 0.7176 Acc: 81.07%\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 0.6688 Acc: 84.76%\n",
      "val Loss: 0.6243 Acc: 87.97%\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 0.5844 Acc: 88.77%\n",
      "val Loss: 0.5678 Acc: 89.31%\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 0.5454 Acc: 88.55%\n",
      "val Loss: 0.5210 Acc: 91.31%\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 0.4920 Acc: 90.33%\n",
      "val Loss: 0.4831 Acc: 91.76%\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 0.4654 Acc: 91.08%\n",
      "val Loss: 0.4583 Acc: 91.76%\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 0.4384 Acc: 90.78%\n",
      "val Loss: 0.4289 Acc: 92.87%\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 0.4133 Acc: 91.60%\n",
      "val Loss: 0.4136 Acc: 91.76%\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 0.3958 Acc: 91.38%\n",
      "val Loss: 0.4257 Acc: 88.64%\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 0.3882 Acc: 91.00%\n",
      "val Loss: 0.3756 Acc: 90.87%\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 0.3684 Acc: 91.75%\n",
      "val Loss: 0.3935 Acc: 90.42%\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 0.3599 Acc: 92.12%\n",
      "val Loss: 0.3539 Acc: 91.54%\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 0.3496 Acc: 91.23%\n",
      "val Loss: 0.3510 Acc: 89.98%\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 0.3374 Acc: 91.75%\n",
      "val Loss: 0.3425 Acc: 90.65%\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 0.3282 Acc: 92.34%\n",
      "val Loss: 0.3524 Acc: 90.42%\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 0.3249 Acc: 92.19%\n",
      "val Loss: 0.3257 Acc: 90.87%\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 0.3193 Acc: 92.27%\n",
      "val Loss: 0.3284 Acc: 91.54%\n",
      "\n",
      "Training complete in 0m 2s\n",
      "Best val Acc: 92.87%\n",
      "False\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "D_in = df.shape[1]-1\n",
    "D_out = len(dances)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = 64, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = 64, shuffle = False)\n",
    "\n",
    "dataloaders = dict(train=train_loader, val=test_loader)\n",
    "\n",
    "model = TwoLayerMLP(D_in, 50, D_out)\n",
    "print(next(model.parameters()).is_cuda)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "\n",
    "# Explore the model\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "\n",
    "print(\"Total number of parameters =\", np.sum([np.prod(parameter.shape) for parameter in model.parameters()]))\n",
    "\n",
    "model, losses, accuracies = train_val_model(model, criterion, optimizer, dataloaders,\n",
    "                       num_epochs=20, log_interval=1)\n",
    "\n",
    "print(next(model.parameters()).is_cuda)\n",
    "\n",
    "_ = plt.plot(losses['train'], '-b', losses['val'], '--r')\n",
    "# torch.save(model.state_dict(), 'models/mod-%s.pth' % model.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.2336 Acc: 92.86%\n",
      "val Loss: 0.2092 Acc: 94.43%\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.2107 Acc: 93.61%\n",
      "val Loss: 0.1968 Acc: 94.43%\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.1908 Acc: 94.20%\n",
      "val Loss: 0.1870 Acc: 93.76%\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.1844 Acc: 94.65%\n",
      "val Loss: 0.1709 Acc: 94.43%\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.1868 Acc: 93.98%\n",
      "val Loss: 0.1697 Acc: 95.10%\n",
      "\n",
      "Training complete in 0m 1s\n",
      "Best val Acc: 95.10%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "\n",
    "model, losses, accuracies = train_val_model(model, criterion, optimizer, dataloaders,\n",
    "                       num_epochs=10, log_interval=2)\n",
    "\n",
    "_ = plt.plot(losses['train'], '-b', losses['val'], '--r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'MLP_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 173, 3: 8, 2: 180, 1: 179}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 0.32037037037037036,\n",
       " 3: 0.014814814814814815,\n",
       " 2: 0.3333333333333333,\n",
       " 1: 0.3314814814814815}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model = TwoLayerMLP(D_in, 50, D_out)\n",
    "mlp_model.load('MLP_Model')\n",
    "# mlp_model.eval()\n",
    "\n",
    "to_predict = 3\n",
    "\n",
    "output = mlp_model.predict(torch.from_numpy(np.array(df[df['tag'] < to_predict+1])[:,:-1]))\n",
    "proba_dict = {}\n",
    "\n",
    "for x in output:\n",
    "    x = int(x)\n",
    "    if x not in proba_dict:\n",
    "        proba_dict[x] = 1\n",
    "    else:\n",
    "        proba_dict[x] += 1\n",
    "print(proba_dict)\n",
    "for k in proba_dict.keys():\n",
    "    proba_dict[k] /= len(output)\n",
    "    \n",
    "proba_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 3])\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import torch\n",
    "\n",
    "X = numpy.random.uniform(-10, 10, 70).reshape(1, 7, -1)\n",
    "# Y = np.random.randint(0, 9, 10).reshape(1, 1, -1)\n",
    "\n",
    "class Simple1DCNN(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Simple1DCNN, self).__init__()\n",
    "        self.layer1 = torch.nn.Conv1d(in_channels=7, out_channels=20, kernel_size=5, stride=2)\n",
    "        self.act1 = torch.nn.ReLU()\n",
    "        self.layer2 = torch.nn.Conv1d(in_channels=20, out_channels=10, kernel_size=1)\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.layer2(x)\n",
    "\n",
    "        log_probs = torch.nn.functional.log_softmax(x, dim=1)\n",
    "\n",
    "        return log_probs\n",
    "\n",
    "model = Simple1DCNN().double()\n",
    "print(model(torch.tensor(X)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "train_data_normalized = scaler.fit_transform(train_data .reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('train', <torch.utils.data.dataloader.DataLoader object at 0x000002CF11546608>), ('val', <torch.utils.data.dataloader.DataLoader object at 0x000002CF17867188>)])\n",
      "torch.Size([400, 30])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400])\n",
      "torch.Size([400])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n",
      "Total number of parameters = 53810\n",
      "960 241\n",
      "\n",
      "Epoch 1 / 150 \n",
      "Fold number 1 / 5\n",
      "tensor([[ 0.2939],\n",
      "        [-0.2470],\n",
      "        [ 0.1055],\n",
      "        [-0.0956],\n",
      "        [ 0.1541],\n",
      "        [-0.0700],\n",
      "        [ 0.1111],\n",
      "        [-0.0792],\n",
      "        [-0.2696],\n",
      "        [-0.2655]], grad_fn=<ViewBackward>) tensor([5., 0., 5., 8., 7., 4., 4., 2., 5., 7.], dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Target 5 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-976fe87b7986>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m             \u001b[0msingle_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m             \u001b[0msingle_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2262\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[0;32m   2263\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2264\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2265\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2266\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Target 5 is out of bounds."
     ]
    }
   ],
   "source": [
    "class LSTM(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layer_size=100):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_layer_size)\n",
    "\n",
    "        self.linear = torch.nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n",
    "                            torch.zeros(1,1,self.hidden_layer_size))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1).float(), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "D_in = df.shape[1]-1\n",
    "D_out = len(dances)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = 64, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = 64, shuffle = False)\n",
    "\n",
    "dataloaders = dict(train=train_loader, val=test_loader)\n",
    "\n",
    "print(dataloaders.items())\n",
    "model = LSTM(D_in, D_out)\n",
    "loss_function = torch.nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 150\n",
    "\n",
    "# Explore the model\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "\n",
    "print(\"Total number of parameters =\", np.sum([np.prod(parameter.shape) for parameter in model.parameters()]))\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.X, dataset.y, test_size=0.33, random_state=42)\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(X_train, y_train)):\n",
    "    ### Dividing data into folds\n",
    "    x_train_fold = X_train[train_index]\n",
    "    x_test_fold = X_train[test_index]\n",
    "    y_train_fold = y_train[train_index]\n",
    "    y_test_fold = y_train[test_index]\n",
    "    \n",
    "    print(len(train_index), len(test_index))\n",
    "\n",
    "    train = torch.utils.data.TensorDataset(torch.tensor(x_train_fold), torch.tensor(y_train_fold))\n",
    "    test = torch.utils.data.TensorDataset(torch.tensor(x_test_fold), torch.tensor(y_test_fold))\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size = 10, shuffle = False)\n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size = 10, shuffle = False)\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        print('\\nEpoch {} / {} \\nFold number {} / {}'.format(i + 1, epochs, fold + 1 , kfold.get_n_splits()))\n",
    "        correct = 0\n",
    "        model.train()\n",
    "        for batch_index, (x_batch, y_batch) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                            torch.zeros(1, 1, model.hidden_layer_size))\n",
    "            y_pred = model(x_batch)\n",
    "            \n",
    "            y_pred = y_pred.reshape(len(y_pred), 1)\n",
    "            \n",
    "            print(y_pred, y_batch)\n",
    "\n",
    "            single_loss = loss_function(y_pred, y_batch.long())\n",
    "            single_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data_normalized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-196-069e340b33c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfut_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtest_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data_normalized\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtrain_window\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data_normalized' is not defined"
     ]
    }
   ],
   "source": [
    "fut_pred = 12\n",
    "\n",
    "test_inputs = train_data_normalized[-train_window:].tolist()\n",
    "print(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in = df.shape[1]-1\n",
    "D_out = len(dances)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = 64, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = 64, shuffle = False)\n",
    "\n",
    "dataloaders = dict(train=train_loader, val=test_loader)\n",
    "\n",
    "model = TwoLayerMLP(D_in, 50, D_out)\n",
    "print(next(model.parameters()).is_cuda)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "\n",
    "# Explore the model\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "\n",
    "print(\"Total number of parameters =\", np.sum([np.prod(parameter.shape) for parameter in model.parameters()]))\n",
    "\n",
    "model, losses, accuracies = train_val_model(model, criterion, optimizer, dataloaders,\n",
    "                       num_epochs=20, log_interval=1)\n",
    "\n",
    "print(next(model.parameters()).is_cuda)\n",
    "\n",
    "_ = plt.plot(losses['train'], '-b', losses['val'], '--r')\n",
    "# torch.save(model.state_dict(), 'models/mod-%s.pth' % model.__class__.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiDirectional_LSTM(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.input_fc = nn.QuantLinear(input_size, 256, bias=True)\n",
    "        self.hidden_fc = nn.QuantLinear(256, 128, bias=True)\n",
    "        self.output_fc = nn.QuantLinear(128, output_size, bias=True)\n",
    "        self.lstm = eval('nn.' + rnn_type)(\n",
    "            self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, bidirectional=True\n",
    "        )        \n",
    "        self.relu = nn.QuantReLU()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # This is what we'll initialise our hidden state as\n",
    "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_1 = self.input_fc(x)\n",
    "        h_1 = torch.nn.functional.relu(self.input_fc(x))\n",
    "        x_2 = self.hidden_fc(h_1)\n",
    "        h_2 = torch.nn.functional.relu(x_2)\n",
    "        # Forward pass through LSTM layer\n",
    "        # shape of lstm_out: [batch_size, input_size ,hidden_dim]\n",
    "        # shape of self.hidden: (a, b), where a and b both\n",
    "        # have shape (batch_size, num_layers, hidden_dim).\n",
    "        lstm_out, self.hidden = self.lstm(h_2)\n",
    "\n",
    "        # Can pass on the entirety of lstm_out to the next layer if it is a seq2seq prediction\n",
    "        y_pred = self.output_fc(lstm_out)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kfold = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train_index, test_index in kfold.split(X_train, y_train):  \n",
    "#     x_train_fold = X_train[train_index] \n",
    "#     y_train_fold = y_train[train_index] \n",
    "#     x_test_fold = X_train[test_index] \n",
    "#     y_test_fold = y_train[test_index] \n",
    "\n",
    "#     print(x_train_fold.shape, y_train_fold.shape) \n",
    "#     print(x_test_fold.shape, y_test_fold.shape) \n",
    "#     break "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
