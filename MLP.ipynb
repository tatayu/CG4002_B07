{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dab1_guiyong.json', 'dab1_john.json', 'dab1_kelvin.json', 'dab1_xiaoxue.json', 'dab2_guiyong.json', 'dab2_john.json', 'dab2_kelvin.json', 'dab2_xiaoxue.json', 'dab2_yujie.json', 'elbowkick1_guiyong.json', 'elbowkick1_john.json', 'elbowkick1_kelvin.json', 'elbowkick1_xiaoxue.json', 'elbowkick2_guiyong.json', 'elbowkick2_john.json', 'elbowkick2_kelvin.json', 'elbowkick2_xiaoxue.json', 'elbowkick2_yujie.json', 'gun1_guiyong.json', 'gun1_john.json', 'gun1_kelvin.json', 'gun1_xiaoxue.json', 'gun2_guiyong.json', 'gun2_john.json', 'gun2_kelvin.json', 'gun2_xiaoxue.json', 'gun2_yujie.json', 'hair1_guiyong.json', 'hair1_john.json', 'hair1_kelvin.json', 'hair1_xiaoxue.json', 'hair2_guiyong.json', 'hair2_john.json', 'hair2_kelvin.json', 'hair2_xiaoxue.json', 'hair2_yujie.json', 'listen1_guiyong.json', 'listen1_john.json', 'listen1_kelvin.json', 'listen1_xiaoxue.json', 'listen2_guiyong.json', 'listen2_john.json', 'listen2_kelvin.json', 'listen2_xiaoxue.json', 'listen2_yujie.json', 'pointhigh1_guiyong.json', 'pointhigh1_john.json', 'pointhigh1_kelvin.json', 'pointhigh1_xiaoxue.json', 'pointhigh2_guiyong.json', 'pointhigh2_john.json', 'pointhigh2_kelvin.json', 'pointhigh2_xiaoxue.json', 'pointhigh2_yujie.json', 'sidepump1_guiyong.json', 'sidepump1_john.json', 'sidepump1_kelvin.json', 'sidepump1_xiaoxue.json', 'sidepump2_guiyong.json', 'sidepump2_john.json', 'sidepump2_kelvin.json', 'sidepump2_xiaoxue.json', 'sidepump2_yujie.json', 'wipetable1_guiyong.json', 'wipetable1_john.json', 'wipetable1_kelvin.json', 'wipetable1_xiaoxue.json', 'wipetable2_guiyong.json', 'wipetable2_john.json', 'wipetable2_kelvin.json', 'wipetable2_xiaoxue.json', 'wipetable2_yujie.json']\n",
      "{0: 'dab1_guiyong', 1: 'dab1_john', 2: 'dab1_kelvin', 3: 'dab1_xiaoxue', 4: 'dab2_guiyong', 5: 'dab2_john', 6: 'dab2_kelvin', 7: 'dab2_xiaoxue', 8: 'dab2_yujie', 9: 'elbowkick1_guiyong', 10: 'elbowkick1_john', 11: 'elbowkick1_kelvin', 12: 'elbowkick1_xiaoxue', 13: 'elbowkick2_guiyong', 14: 'elbowkick2_john', 15: 'elbowkick2_kelvin', 16: 'elbowkick2_xiaoxue', 17: 'elbowkick2_yujie', 18: 'gun1_guiyong', 19: 'gun1_john', 20: 'gun1_kelvin', 21: 'gun1_xiaoxue', 22: 'gun2_guiyong', 23: 'gun2_john', 24: 'gun2_kelvin', 25: 'gun2_xiaoxue', 26: 'gun2_yujie', 27: 'hair1_guiyong', 28: 'hair1_john', 29: 'hair1_kelvin', 30: 'hair1_xiaoxue', 31: 'hair2_guiyong', 32: 'hair2_john', 33: 'hair2_kelvin', 34: 'hair2_xiaoxue', 35: 'hair2_yujie', 36: 'listen1_guiyong', 37: 'listen1_john', 38: 'listen1_kelvin', 39: 'listen1_xiaoxue', 40: 'listen2_guiyong', 41: 'listen2_john', 42: 'listen2_kelvin', 43: 'listen2_xiaoxue', 44: 'listen2_yujie', 45: 'pointhigh1_guiyong', 46: 'pointhigh1_john', 47: 'pointhigh1_kelvin', 48: 'pointhigh1_xiaoxue', 49: 'pointhigh2_guiyong', 50: 'pointhigh2_john', 51: 'pointhigh2_kelvin', 52: 'pointhigh2_xiaoxue', 53: 'pointhigh2_yujie', 54: 'sidepump1_guiyong', 55: 'sidepump1_john', 56: 'sidepump1_kelvin', 57: 'sidepump1_xiaoxue', 58: 'sidepump2_guiyong', 59: 'sidepump2_john', 60: 'sidepump2_kelvin', 61: 'sidepump2_xiaoxue', 62: 'sidepump2_yujie', 63: 'wipetable1_guiyong', 64: 'wipetable1_john', 65: 'wipetable1_kelvin', 66: 'wipetable1_xiaoxue', 67: 'wipetable2_guiyong', 68: 'wipetable2_john', 69: 'wipetable2_kelvin', 70: 'wipetable2_xiaoxue', 71: 'wipetable2_yujie'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, TimeSeriesSplit, cross_val_score\n",
    "\n",
    "import brevitas.nn as nn\n",
    "\n",
    "from config import *\n",
    "from classic_models import *\n",
    "from data_preprocessing import *\n",
    "from feature_extraction import *\n",
    "from helpers import *\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tslearn.preprocessing import TimeSeriesScalerMinMax\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_accel1</th>\n",
       "      <th>mean_accel2</th>\n",
       "      <th>mean_accel3</th>\n",
       "      <th>mean_gyro1</th>\n",
       "      <th>mean_gyro2</th>\n",
       "      <th>mean_gyro3</th>\n",
       "      <th>max_accel1</th>\n",
       "      <th>max_accel2</th>\n",
       "      <th>max_accel3</th>\n",
       "      <th>max_gyro1</th>\n",
       "      <th>...</th>\n",
       "      <th>var_coeff_gyro1</th>\n",
       "      <th>var_coeff_gyro2</th>\n",
       "      <th>var_coeff_gyro3</th>\n",
       "      <th>kurtosis_accel1</th>\n",
       "      <th>kurtosis_accel2</th>\n",
       "      <th>kurtosis_accel3</th>\n",
       "      <th>kurtosis_gyro1</th>\n",
       "      <th>kurtosis_gyro2</th>\n",
       "      <th>kurtosis_gyro3</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.608140</td>\n",
       "      <td>0.840685</td>\n",
       "      <td>0.399280</td>\n",
       "      <td>0.587075</td>\n",
       "      <td>-0.004089</td>\n",
       "      <td>0.149590</td>\n",
       "      <td>0.310510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543558</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.160816</td>\n",
       "      <td>0.223313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.184615</td>\n",
       "      <td>0.317834</td>\n",
       "      <td>-0.788047</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.605134</td>\n",
       "      <td>0.845661</td>\n",
       "      <td>0.399280</td>\n",
       "      <td>0.587075</td>\n",
       "      <td>0.003562</td>\n",
       "      <td>0.147052</td>\n",
       "      <td>0.308160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543558</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.158658</td>\n",
       "      <td>0.206135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.215385</td>\n",
       "      <td>0.309391</td>\n",
       "      <td>-0.621000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.630307</td>\n",
       "      <td>0.857108</td>\n",
       "      <td>0.399280</td>\n",
       "      <td>0.622943</td>\n",
       "      <td>0.006429</td>\n",
       "      <td>0.156956</td>\n",
       "      <td>0.320767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.539877</td>\n",
       "      <td>-0.001944</td>\n",
       "      <td>0.158728</td>\n",
       "      <td>0.206135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>0.312124</td>\n",
       "      <td>-0.658889</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.656246</td>\n",
       "      <td>0.857108</td>\n",
       "      <td>0.399280</td>\n",
       "      <td>0.716536</td>\n",
       "      <td>0.004895</td>\n",
       "      <td>0.148565</td>\n",
       "      <td>0.280961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522699</td>\n",
       "      <td>0.002964</td>\n",
       "      <td>0.154838</td>\n",
       "      <td>0.182822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.184615</td>\n",
       "      <td>0.302822</td>\n",
       "      <td>-0.493985</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.661091</td>\n",
       "      <td>0.857108</td>\n",
       "      <td>0.426051</td>\n",
       "      <td>0.716536</td>\n",
       "      <td>-0.001454</td>\n",
       "      <td>0.144479</td>\n",
       "      <td>0.280717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522699</td>\n",
       "      <td>0.003218</td>\n",
       "      <td>0.134400</td>\n",
       "      <td>0.174233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.215385</td>\n",
       "      <td>0.255009</td>\n",
       "      <td>-0.171893</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_accel1  mean_accel2  mean_accel3  mean_gyro1  mean_gyro2  mean_gyro3  \\\n",
       "0     0.608140     0.840685     0.399280    0.587075   -0.004089    0.149590   \n",
       "1     0.605134     0.845661     0.399280    0.587075    0.003562    0.147052   \n",
       "2     0.630307     0.857108     0.399280    0.622943    0.006429    0.156956   \n",
       "3     0.656246     0.857108     0.399280    0.716536    0.004895    0.148565   \n",
       "4     0.661091     0.857108     0.426051    0.716536   -0.001454    0.144479   \n",
       "\n",
       "   max_accel1  max_accel2  max_accel3  max_gyro1  ...  var_coeff_gyro1  \\\n",
       "0    0.310510         0.0         3.0        0.0  ...         0.543558   \n",
       "1    0.308160         0.0         3.0        0.0  ...         0.543558   \n",
       "2    0.320767         0.0         4.0        0.0  ...         0.539877   \n",
       "3    0.280961         0.0         4.0        0.0  ...         0.522699   \n",
       "4    0.280717         0.0         4.0        0.0  ...         0.522699   \n",
       "\n",
       "   var_coeff_gyro2  var_coeff_gyro3  kurtosis_accel1  kurtosis_accel2  \\\n",
       "0         0.001482         0.160816         0.223313              0.0   \n",
       "1         0.000170         0.158658         0.206135              0.0   \n",
       "2        -0.001944         0.158728         0.206135              0.0   \n",
       "3         0.002964         0.154838         0.182822              0.0   \n",
       "4         0.003218         0.134400         0.174233              0.0   \n",
       "\n",
       "   kurtosis_accel3  kurtosis_gyro1  kurtosis_gyro2  kurtosis_gyro3  tag  \n",
       "0              3.0        0.184615        0.317834       -0.788047  0.0  \n",
       "1              3.0        0.215385        0.309391       -0.621000  0.0  \n",
       "2              2.0        0.246154        0.312124       -0.658889  0.0  \n",
       "3              3.0        0.184615        0.302822       -0.493985  0.0  \n",
       "4              4.0        0.215385        0.255009       -0.171893  0.0  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "df_train = pd.read_csv('out_11_train.csv')\n",
    "# df_train = df_train.iloc[:, list(range(21)) + [-1]]\n",
    "df_test = pd.read_csv('out_11_test.csv')\n",
    "# df_test = df_test.iloc[:, list(range(21)) + [-1]]\n",
    "df_train['tag'] = df_train['tag'].apply(lambda x: x-1)\n",
    "df_test['tag'] = df_test['tag'].apply(lambda x: x-1)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 60\n"
     ]
    }
   ],
   "source": [
    "print(window_size, overlap)\n",
    "window_size = 80\n",
    "overlap = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            df_np = df.to_numpy()\n",
    "        self.X = df_np[:,:-1]\n",
    "        self.y = df_np[:,-1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get item by index\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        # returns length of data\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 8\n"
     ]
    }
   ],
   "source": [
    "dataset = FeatureDataset(df_train)\n",
    "D_in = 72 # df.shape[1]-1\n",
    "D_out = 8 # len(dances)\n",
    "print(D_in, D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_hidden, d_out):\n",
    "        super(MLP, self).__init__()\n",
    "        self.d_in = d_in\n",
    "\n",
    "        self.linear1 = nn.QuantLinear(d_in, d_hidden, bias=True)\n",
    "        self.linear2 = nn.QuantLinear(d_hidden, d_hidden//4, bias=True)\n",
    "        self.linear3 = nn.QuantLinear(d_hidden//4, d_hidden//4, bias=True)\n",
    "        self.linear4 = nn.QuantLinear(d_hidden//4, d_hidden//8, bias=True)\n",
    "        self.linear5 = nn.QuantLinear(d_hidden//8, d_out, bias=False)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = X.view(-1, self.d_in)\n",
    "        X = self.relu(self.linear1(X.float()))\n",
    "        X = self.relu(self.linear2(X))\n",
    "        X = self.relu(self.linear3(X))\n",
    "        X = self.relu(self.linear4(X))\n",
    "        X = self.linear5(X)\n",
    "        return torch.nn.functional.log_softmax(X, dim=1)\n",
    "    \n",
    "    def load(self, model_path):\n",
    "        self.load_state_dict(torch.load(model_path))\n",
    "        self.eval()\n",
    "\n",
    "    def predict(self, X):\n",
    "        outputs = self(X.float())\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_model(model, criterion, optimizer, X, y, num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # Store losses and accuracies accross epochs\n",
    "    losses, accuracies = dict(train=[], val=[]), dict(train=[], val=[])\n",
    "\n",
    "    # tscv = TimeSeriesSplit(n_splits=15, max_train_size=3000)\n",
    "    kf = KFold(n_splits=16)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    confusion_matrix = torch.zeros(8, 8)\n",
    "\n",
    "    for i in range(1,num_epochs+1):\n",
    "        print('Epoch {}/{}'.format(i, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "        \n",
    "        # for fold, (train_index, test_index) in enumerate(tscv.split(X_train, y_train)):\n",
    "        for fold, (train_index, test_index) in enumerate(kf.split(X_train)):\n",
    "#             if len(train_index) > 500:\n",
    "#                 train_index = train_index[len(train_index)-500:]\n",
    "            ### Dividing data into folds\n",
    "            # print(train_index, test_index, len(X_train))\n",
    "            x_train_fold = X_train[train_index]\n",
    "            x_test_fold = X_train[test_index]\n",
    "            y_train_fold = y_train[train_index]\n",
    "            y_test_fold = y_train[test_index]\n",
    "\n",
    "            print('Train Index Length:', len(train_index), end='\\t\\t')\n",
    "            print('Test Index Length:', len(test_index), end='\\n\\n')\n",
    "\n",
    "            train = torch.utils.data.TensorDataset(torch.tensor(x_train_fold), torch.tensor(y_train_fold))\n",
    "            test = torch.utils.data.TensorDataset(torch.tensor(x_test_fold), torch.tensor(y_test_fold))\n",
    "            train_loader = torch.utils.data.DataLoader(train, batch_size = 20, shuffle = False)\n",
    "            test_loader = torch.utils.data.DataLoader(test, batch_size = 20, shuffle = False)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            for batch_index, (x_batch, y_batch) in enumerate(train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                y_pred = model(x_batch)\n",
    "                _, preds = torch.max(y_pred, 1)\n",
    "                for t, p in zip(y_batch.view(-1), preds.view(-1)):\n",
    "                        confusion_matrix[t.long(), p.long()] += 1\n",
    "                # print(y_pred.shape, y_batch.view(-1, 1).shape)\n",
    "                single_loss = criterion(y_pred, y_batch.long())\n",
    "                single_loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += single_loss.item() * x_batch.size(0)\n",
    "                running_corrects += torch.sum(preds == y_batch.data)\n",
    "            print('Fold No. {}/{}\\tEpoch {}/{}\\t'.format(fold + 1 , kf.get_n_splits(X_train), i, num_epochs), end='')\n",
    "            print(f'loss: {single_loss.item():10.8f}')\n",
    "            \n",
    "            nsamples = len(train_index)\n",
    "            epoch_loss = running_loss / nsamples\n",
    "            epoch_acc = running_corrects.double() / nsamples\n",
    "\n",
    "            losses[phase].append(epoch_loss)\n",
    "            accuracies[phase].append(epoch_acc)\n",
    "            print('{} Loss: {:.4f} Acc: {:.2f}%'.format(\n",
    "                    phase, epoch_loss, 100 * epoch_acc)\n",
    "            )\n",
    "            print()\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.2f}%'.format(100 * best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    print(confusion_matrix.diag()/confusion_matrix.sum(1))\n",
    "    return model, losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([70, 72])\n",
      "torch.Size([70])\n",
      "torch.Size([17, 70])\n",
      "torch.Size([17])\n",
      "torch.Size([17, 17])\n",
      "torch.Size([17])\n",
      "torch.Size([8, 17])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 8])\n",
      "Total number of parameters = 6831\n"
     ]
    }
   ],
   "source": [
    "model = MLP(D_in, 70, D_out)\n",
    "# model = MultiHead4MLP(D_in, D_out)\n",
    "# Explore the model\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "\n",
    "print(\"Total number of parameters =\", np.sum([np.prod(parameter.shape) for parameter in model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "----------\n",
      "Train Index Length: 3248\t\tTest Index Length: 217\n",
      "\n",
      "Fold No. 1/16\tEpoch 1/1\tloss: 0.77968353\n",
      "val Loss: 1.1288 Acc: 58.41%\n",
      "\n",
      "Train Index Length: 3248\t\tTest Index Length: 217\n",
      "\n",
      "Fold No. 2/16\tEpoch 1/1\tloss: 0.74764937\n",
      "val Loss: 1.1060 Acc: 59.14%\n",
      "\n",
      "Train Index Length: 3248\t\tTest Index Length: 217\n",
      "\n",
      "Fold No. 3/16\tEpoch 1/1\tloss: 0.72412056\n",
      "val Loss: 1.0835 Acc: 60.25%\n",
      "\n",
      "Train Index Length: 3248\t\tTest Index Length: 217\n",
      "\n",
      "Fold No. 4/16\tEpoch 1/1\tloss: 0.69885594\n",
      "val Loss: 1.0652 Acc: 61.45%\n",
      "\n",
      "Train Index Length: 3248\t\tTest Index Length: 217\n",
      "\n",
      "Fold No. 5/16\tEpoch 1/1\tloss: 0.67614692\n",
      "val Loss: 1.0442 Acc: 62.47%\n",
      "\n",
      "Train Index Length: 3248\t\tTest Index Length: 217\n",
      "\n",
      "Fold No. 6/16\tEpoch 1/1\tloss: 0.66291463\n",
      "val Loss: 1.0241 Acc: 62.47%\n",
      "\n",
      "Train Index Length: 3248\t\tTest Index Length: 217\n",
      "\n",
      "Fold No. 7/16\tEpoch 1/1\tloss: 0.63531554\n",
      "val Loss: 1.0007 Acc: 63.98%\n",
      "\n",
      "Train Index Length: 3248\t\tTest Index Length: 217\n",
      "\n",
      "Fold No. 8/16\tEpoch 1/1\tloss: 0.62092489\n",
      "val Loss: 0.9860 Acc: 64.01%\n",
      "\n",
      "Train Index Length: 3248\t\tTest Index Length: 217\n",
      "\n",
      "Fold No. 9/16\tEpoch 1/1\tloss: 0.60637498\n",
      "val Loss: 0.9710 Acc: 64.50%\n",
      "\n",
      "Train Index Length: 3249\t\tTest Index Length: 216\n",
      "\n",
      "Fold No. 10/16\tEpoch 1/1\tloss: 0.64275420\n",
      "val Loss: 0.9511 Acc: 65.07%\n",
      "\n",
      "Train Index Length: 3249\t\tTest Index Length: 216\n",
      "\n",
      "Fold No. 11/16\tEpoch 1/1\tloss: 0.62524992\n",
      "val Loss: 0.9415 Acc: 65.44%\n",
      "\n",
      "Train Index Length: 3249\t\tTest Index Length: 216\n",
      "\n",
      "Fold No. 12/16\tEpoch 1/1\tloss: 0.61225504\n",
      "val Loss: 0.9276 Acc: 66.33%\n",
      "\n",
      "Train Index Length: 3249\t\tTest Index Length: 216\n",
      "\n",
      "Fold No. 13/16\tEpoch 1/1\tloss: 0.59793162\n",
      "val Loss: 0.9092 Acc: 66.76%\n",
      "\n",
      "Train Index Length: 3249\t\tTest Index Length: 216\n",
      "\n",
      "Fold No. 14/16\tEpoch 1/1\tloss: 0.58495635\n",
      "val Loss: 0.9036 Acc: 67.10%\n",
      "\n",
      "Train Index Length: 3249\t\tTest Index Length: 216\n",
      "\n",
      "Fold No. 15/16\tEpoch 1/1\tloss: 0.56806397\n",
      "val Loss: 0.8883 Acc: 67.04%\n",
      "\n",
      "Train Index Length: 3249\t\tTest Index Length: 216\n",
      "\n",
      "Fold No. 16/16\tEpoch 1/1\tloss: 0.95876002\n",
      "val Loss: 0.8734 Acc: 68.14%\n",
      "\n",
      "Training complete in 0m 28s\n",
      "Best val Acc: 68.14%\n",
      "tensor([0.2807, 0.6438, 0.6489, 0.7355, 0.3814, 0.7323, 0.8047, 0.8293])\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.4)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "model, losses, accuracies = train_val_model(model, criterion, optimizer, dataset.X, dataset.y, num_epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.plot(losses['train'], '-b', losses['val'], '--r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'MLP_Model_moves_{D_out}_windowsize{window_size}_overlap{overlap}_epoch{NUM_EPOCHS}'\n",
    "torch.save(model.state_dict(), name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "linear1.weight \t\t torch.Size([70, 72])\n",
      "linear1.bias \t\t torch.Size([70])\n",
      "linear2.weight \t\t torch.Size([17, 70])\n",
      "linear2.bias \t\t torch.Size([17])\n",
      "linear3.weight \t\t torch.Size([17, 17])\n",
      "linear3.bias \t\t torch.Size([17])\n",
      "linear4.weight \t\t torch.Size([8, 17])\n",
      "linear4.bias \t\t torch.Size([8])\n",
      "linear5.weight \t\t torch.Size([8, 8])\n",
      "Optimizer's state_dict:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'momentum_buffer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-6b663fd4d333>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvar_name\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'state'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlp_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'momentum_buffer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;31m# print(var_name, \"\\t\", np.array(optimizer.state_dict()[var_name][i]['momentum_buffer']))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'momentum_buffer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'momentum_buffer'"
     ]
    }
   ],
   "source": [
    "mlp_model = MLP(D_in, 70, D_out)\n",
    "mlp_model.load(name)\n",
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in mlp_model.state_dict():\n",
    "    print(param_tensor, \"\\t\\t\", mlp_model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "\n",
    "with open('weights.txt', 'w') as outfile:\n",
    "    for var_name in optimizer.state_dict():\n",
    "        if var_name == 'state':\n",
    "            for i in range(len(mlp_model.state_dict())):\n",
    "                print(var_name, \"\\t\", optimizer.state_dict()[var_name][i]['momentum_buffer'].shape)\n",
    "                # print(var_name, \"\\t\", np.array(optimizer.state_dict()[var_name][i]['momentum_buffer']))\n",
    "                y = np.array(optimizer.state_dict()[var_name][i]['momentum_buffer'])\n",
    "                for x in y:\n",
    "                    x = str(x)\n",
    "                    x = x.replace('[','{').replace(']','}').replace(' ', ', ').replace('{,', '{').replace(', ,', ',').replace('\\n,', ',\\n')\n",
    "                    outfile.write(x)\n",
    "                # np.savetxt(outfile, np.array(optimizer.state_dict()[var_name][i]['momentum_buffer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.35181644359464626, 5: 0.3193116634799235, 6: 0.1988527724665392, 7: 0.07839388145315487, 3: 0.021032504780114723, 4: 0.019120458891013385, 1: 0.009560229445506692, 2: 0.0019120458891013384}\n",
      "{1: 0.6408094435075885, 2: 0.1551433389544688, 4: 0.09274873524451939, 7: 0.05564924114671164, 3: 0.026981450252951095, 0: 0.013490725126475547, 5: 0.011804384485666104, 6: 0.003372681281618887}\n",
      "{2: 0.58578856152513, 1: 0.25476603119584057, 4: 0.08665511265164645, 3: 0.025996533795493933, 7: 0.024263431542461005, 0: 0.010398613518197574, 5: 0.008665511265164644, 6: 0.0034662045060658577}\n",
      "{3: 0.6339754816112084, 4: 0.14886164623467601, 5: 0.138353765323993, 2: 0.043782837127845885, 0: 0.017513134851138354, 1: 0.008756567425569177, 7: 0.008756567425569177}\n",
      "{3: 0.3651877133105802, 4: 0.3430034129692833, 1: 0.13993174061433447, 0: 0.04607508532423208, 2: 0.040955631399317405, 6: 0.034129692832764506, 7: 0.017064846416382253, 5: 0.013651877133105802}\n",
      "{5: 0.7077702702702703, 0: 0.1266891891891892, 7: 0.08108108108108109, 4: 0.033783783783783786, 6: 0.02702702702702703, 3: 0.016891891891891893, 1: 0.006756756756756757}\n",
      "{6: 0.7895595432300163, 0: 0.11908646003262642, 7: 0.05057096247960848, 4: 0.01631321370309951, 5: 0.011419249592169658, 1: 0.009787928221859706, 3: 0.0016313213703099511, 2: 0.0016313213703099511}\n",
      "{7: 0.8929824561403509, 0: 0.05087719298245614, 5: 0.04035087719298246, 6: 0.012280701754385965, 1: 0.0035087719298245615}\n"
     ]
    }
   ],
   "source": [
    "mlp_model = MLP(D_in, 70, D_out)\n",
    "mlp_model.load(name)\n",
    "mlp_model.eval()\n",
    "\n",
    "for to_predict in range(D_out):\n",
    "    df_target = df_test[df_test['tag'] == to_predict]\n",
    "    df_target = torch.from_numpy(np.array(df_target)[:,:-1])\n",
    "\n",
    "#     df_random = df_test\n",
    "\n",
    "#     df_filtered = torch.from_numpy(np.array(pd.merge(df_target, df_random))[:,:-1])\n",
    "    output = mlp_model.predict(df_target)\n",
    "    proba_dict = {}\n",
    "\n",
    "    for x in output:\n",
    "        x = int(x)\n",
    "        if x not in proba_dict:\n",
    "            proba_dict[x] = 1\n",
    "        else:\n",
    "            proba_dict[x] += 1\n",
    "    for k in proba_dict.keys():\n",
    "        proba_dict[k] /= len(output)\n",
    "\n",
    "    print(dict(sorted(proba_dict.items(), key=lambda item: -item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(df, window_size):\n",
    "    full_features = np.array([])\n",
    "    axis = ['accel1', 'accel2', 'accel3', 'gyro1', 'gyro2', 'gyro3']\n",
    "    titles = np.ravel(np.array([i+'_'+j for i in feature_list for j in axis]))\n",
    "\n",
    "    # print(\"Begin Feature Extraction\")\n",
    "    windows = set_sliding_windows(df, 60, window_size)\n",
    "    # windows = set_windows(df, window_size)\n",
    "\n",
    "    for window in windows:\n",
    "        for _,ax in enumerate(window.T):\n",
    "                full_features = np.append(full_features, add_mean(ax))\n",
    "                full_features = np.append(full_features, add_max(ax))\n",
    "                full_features = np.append(full_features, add_min(ax))\n",
    "                full_features = np.append(full_features, add_median(ax))\n",
    "                full_features = np.append(full_features, add_gradient(ax))\n",
    "                full_features = np.append(full_features, add_std(ax))\n",
    "                full_features = np.append(full_features, add_iqr(ax))\n",
    "                # full_features = np.append(full_features, add_skew(ax))\n",
    "                full_features = np.append(full_features, add_zero_crossing_count(ax))\n",
    "                # full_features = np.append(full_features, add_cwt(ax))\n",
    "                full_features = np.append(full_features, add_no_peaks(ax))\n",
    "                full_features = np.append(full_features, add_recurring_dp(ax))\n",
    "                # full_features = np.append(full_features, add_ratio_v_tsl(ax))\n",
    "                # full_features = np.append(full_features, add_sum_recurring_dp(ax))\n",
    "                full_features = np.append(full_features, add_var_coeff(ax))\n",
    "                full_features = np.append(full_features, add_kurtosis(ax)) \n",
    "\n",
    "    full_features = full_features.reshape(\n",
    "        -1,\n",
    "        len(feature_list) * 6,\n",
    "    )   \n",
    "    full_features_df = pd.DataFrame(full_features)\n",
    "    full_features_df.columns = titles\n",
    "    return full_features_df\n",
    "\n",
    "def feature_extraction(data):\n",
    "    data = pd.DataFrame.from_dict(data)\n",
    "    if 'dance' in data:\n",
    "        del data['dance']\n",
    "\n",
    "    df = data.apply(pd.to_numeric).interpolate(method='polynomial', order=2)\n",
    "    col = df.columns\n",
    "    # X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0)\n",
    "    # df_scaled = df.apply(lambda x: (x - mean(x)) / std(x))\n",
    "    df_scaled = df.apply(lambda x: (x - min(x)) / (max(x) - min(x)))\n",
    "    # min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    # df_scaled = min_max_scaler.fit_transform(df)\n",
    "    df = pd.DataFrame(df_scaled, columns=col)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # print(df.shape)\n",
    "    features = feature_extract(df, window_size=65).reset_index(drop=True)\n",
    "    # print(features.shape)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase: 0\n",
      "dab\n",
      "{3: 0.8, 5: 0.1, 4: 0.05, 0: 0.05}\n",
      "{3: 0.7, 4: 0.2, 5: 0.1}\n",
      "{5: 0.65, 0: 0.2, 3: 0.1, 7: 0.05}\n",
      "{5: 1.0}\n",
      "{0: 0.45, 6: 0.3, 5: 0.2, 4: 0.05}\n",
      "{3: 0.7, 4: 0.3}\n",
      "{3: 0.55, 5: 0.35, 0: 0.1}\n",
      "{0: 0.4, 5: 0.25, 3: 0.25, 4: 0.1}\n",
      "elbowkick\n",
      "{0: 0.75, 5: 0.1, 6: 0.1, 7: 0.05}\n",
      "{0: 0.65, 1: 0.15, 7: 0.15, 5: 0.05}\n",
      "{4: 0.55, 3: 0.2, 0: 0.2, 5: 0.05}\n",
      "{3: 0.4, 1: 0.3, 4: 0.25, 2: 0.05}\n",
      "{4: 0.3, 5: 0.25, 1: 0.25, 3: 0.15, 2: 0.05}\n",
      "{4: 0.3, 5: 0.25, 1: 0.25, 3: 0.15, 2: 0.05}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-7e8b903f58c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m                     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[0mdf_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmlp_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[0mproba_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-7a63362d675d>\u001b[0m in \u001b[0;36mfeature_extraction\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;31m# print(df.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_extract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m65\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[1;31m# print(features.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-7a63362d675d>\u001b[0m in \u001b[0;36mfeature_extract\u001b[1;34m(df, window_size)\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[1;31m# full_features = np.append(full_features, add_ratio_v_tsl(ax))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[1;31m# full_features = np.append(full_features, add_sum_recurring_dp(ax))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[0mfull_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_var_coeff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m                 \u001b[0mfull_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_kurtosis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mappend\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(arr, values, axis)\u001b[0m\n\u001b[0;32m   4669\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4670\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4671\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "dances = ['dab', 'elbowkick', 'gun', 'hair', 'listen', 'pointhigh', 'sidepump', 'wipetable']\n",
    "# dances = ['gun', 'hair', 'sidepump']\n",
    "# dances = ['elbowkick', 'pointhigh', 'wipetable']\n",
    "persons = ['kelvin', 'guiyong', 'xiaoxue', 'john']\n",
    "beetles = ['1', '2']\n",
    "\n",
    "test_range = 12\n",
    "leap = 160\n",
    "truth, total, skipped = 0,0,0\n",
    "for i in range(0,0+test_range):\n",
    "    print(\"Phase:\", i)\n",
    "    start, end = i * leap, i * leap + leap\n",
    "    for d in dances:\n",
    "        print(d)\n",
    "        df_full = pd.DataFrame()\n",
    "        collection = [np.array([]) for x in range(16)]\n",
    "        j = 0\n",
    "        for p in persons:\n",
    "            for b in beetles:\n",
    "                move_json = 'collected_data/' + d + b + '_' + p + '.json'\n",
    "                with open(move_json) as f:\n",
    "                    x = json.load(f)\n",
    "                x = pd.DataFrame.from_dict(x)[start:end]\n",
    "                df_target = torch.from_numpy(np.array(feature_extraction(x)))\n",
    "                output = mlp_model.predict(df_target)\n",
    "                proba_dict = {}\n",
    "\n",
    "                for x in output:\n",
    "                    x = int(x)\n",
    "                    if x not in proba_dict:\n",
    "                        proba_dict[x] = 1\n",
    "                    else:\n",
    "                        proba_dict[x] += 1\n",
    "                for k in proba_dict.keys():\n",
    "                    proba_dict[k] /= len(output)\n",
    "\n",
    "                print(dict(sorted(proba_dict.items(), key=lambda item: -item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"collected_data/dab2_guiyong.json\") as f:\n",
    "    x = json.load(f)\n",
    "x = pd.DataFrame.from_dict(x)[120:240]\n",
    "feature_extraction(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_accel1</th>\n",
       "      <th>mean_accel2</th>\n",
       "      <th>mean_accel3</th>\n",
       "      <th>mean_gyro1</th>\n",
       "      <th>mean_gyro2</th>\n",
       "      <th>mean_gyro3</th>\n",
       "      <th>max_accel1</th>\n",
       "      <th>max_accel2</th>\n",
       "      <th>max_accel3</th>\n",
       "      <th>max_gyro1</th>\n",
       "      <th>...</th>\n",
       "      <th>var_coeff_gyro1</th>\n",
       "      <th>var_coeff_gyro2</th>\n",
       "      <th>var_coeff_gyro3</th>\n",
       "      <th>kurtosis_accel1</th>\n",
       "      <th>kurtosis_accel2</th>\n",
       "      <th>kurtosis_accel3</th>\n",
       "      <th>kurtosis_gyro1</th>\n",
       "      <th>kurtosis_gyro2</th>\n",
       "      <th>kurtosis_gyro3</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.619921</td>\n",
       "      <td>0.852686</td>\n",
       "      <td>0.415965</td>\n",
       "      <td>0.644185</td>\n",
       "      <td>0.004212</td>\n",
       "      <td>0.120937</td>\n",
       "      <td>0.139660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513191</td>\n",
       "      <td>0.009334</td>\n",
       "      <td>0.136847</td>\n",
       "      <td>0.188756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.275968</td>\n",
       "      <td>-0.960621</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.624279</td>\n",
       "      <td>0.852686</td>\n",
       "      <td>0.416880</td>\n",
       "      <td>0.644185</td>\n",
       "      <td>-0.001367</td>\n",
       "      <td>0.116153</td>\n",
       "      <td>0.135386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516332</td>\n",
       "      <td>0.009095</td>\n",
       "      <td>0.137426</td>\n",
       "      <td>0.223304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.267198</td>\n",
       "      <td>-1.087590</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.628567</td>\n",
       "      <td>0.852686</td>\n",
       "      <td>0.416880</td>\n",
       "      <td>0.647176</td>\n",
       "      <td>0.004263</td>\n",
       "      <td>0.117444</td>\n",
       "      <td>0.141651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.531407</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>0.131167</td>\n",
       "      <td>0.201319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.250598</td>\n",
       "      <td>-0.998598</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.635413</td>\n",
       "      <td>0.852686</td>\n",
       "      <td>0.416880</td>\n",
       "      <td>0.654197</td>\n",
       "      <td>0.003841</td>\n",
       "      <td>0.122414</td>\n",
       "      <td>0.153426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534548</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>0.127450</td>\n",
       "      <td>0.185302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.240380</td>\n",
       "      <td>-0.874532</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.642668</td>\n",
       "      <td>0.852686</td>\n",
       "      <td>0.416880</td>\n",
       "      <td>0.666117</td>\n",
       "      <td>0.003439</td>\n",
       "      <td>0.128431</td>\n",
       "      <td>0.157654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534548</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.126936</td>\n",
       "      <td>0.185302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.238541</td>\n",
       "      <td>-0.847370</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.638731</td>\n",
       "      <td>0.855403</td>\n",
       "      <td>0.433303</td>\n",
       "      <td>0.633242</td>\n",
       "      <td>-0.001171</td>\n",
       "      <td>0.120727</td>\n",
       "      <td>0.165690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562814</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.107036</td>\n",
       "      <td>0.145729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.188983</td>\n",
       "      <td>-0.345404</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.634350</td>\n",
       "      <td>0.855403</td>\n",
       "      <td>0.433303</td>\n",
       "      <td>0.633242</td>\n",
       "      <td>-0.003033</td>\n",
       "      <td>0.125137</td>\n",
       "      <td>0.181677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562814</td>\n",
       "      <td>0.002387</td>\n",
       "      <td>0.096728</td>\n",
       "      <td>0.145729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.168880</td>\n",
       "      <td>-0.719264</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.626859</td>\n",
       "      <td>0.855403</td>\n",
       "      <td>0.417308</td>\n",
       "      <td>0.632799</td>\n",
       "      <td>-0.004421</td>\n",
       "      <td>0.131631</td>\n",
       "      <td>0.203022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562814</td>\n",
       "      <td>-0.000402</td>\n",
       "      <td>0.093748</td>\n",
       "      <td>0.145729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.163197</td>\n",
       "      <td>-0.898353</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.617916</td>\n",
       "      <td>0.855403</td>\n",
       "      <td>0.417308</td>\n",
       "      <td>0.614850</td>\n",
       "      <td>-0.004626</td>\n",
       "      <td>0.136993</td>\n",
       "      <td>0.216331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562814</td>\n",
       "      <td>-0.003920</td>\n",
       "      <td>0.100980</td>\n",
       "      <td>0.145729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.177072</td>\n",
       "      <td>-0.475365</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.610069</td>\n",
       "      <td>0.855403</td>\n",
       "      <td>0.417308</td>\n",
       "      <td>0.586920</td>\n",
       "      <td>-0.003406</td>\n",
       "      <td>0.138429</td>\n",
       "      <td>0.222711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559045</td>\n",
       "      <td>-0.005942</td>\n",
       "      <td>0.112796</td>\n",
       "      <td>0.158291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.201060</td>\n",
       "      <td>-0.351155</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_accel1  mean_accel2  mean_accel3  mean_gyro1  mean_gyro2  mean_gyro3  \\\n",
       "0      0.619921     0.852686     0.415965    0.644185    0.004212    0.120937   \n",
       "1      0.624279     0.852686     0.416880    0.644185   -0.001367    0.116153   \n",
       "2      0.628567     0.852686     0.416880    0.647176    0.004263    0.117444   \n",
       "3      0.635413     0.852686     0.416880    0.654197    0.003841    0.122414   \n",
       "4      0.642668     0.852686     0.416880    0.666117    0.003439    0.128431   \n",
       "..          ...          ...          ...         ...         ...         ...   \n",
       "67     0.638731     0.855403     0.433303    0.633242   -0.001171    0.120727   \n",
       "68     0.634350     0.855403     0.433303    0.633242   -0.003033    0.125137   \n",
       "69     0.626859     0.855403     0.417308    0.632799   -0.004421    0.131631   \n",
       "70     0.617916     0.855403     0.417308    0.614850   -0.004626    0.136993   \n",
       "71     0.610069     0.855403     0.417308    0.586920   -0.003406    0.138429   \n",
       "\n",
       "    max_accel1  max_accel2  max_accel3  max_gyro1  ...  var_coeff_gyro1  \\\n",
       "0     0.139660         0.0         3.0       0.00  ...         0.513191   \n",
       "1     0.135386         0.0         3.0       0.00  ...         0.516332   \n",
       "2     0.141651         0.0         3.0       0.00  ...         0.531407   \n",
       "3     0.153426         0.0         3.0       0.00  ...         0.534548   \n",
       "4     0.157654         0.0         2.0       0.00  ...         0.534548   \n",
       "..         ...         ...         ...        ...  ...              ...   \n",
       "67    0.165690         0.0         2.0       0.00  ...         0.562814   \n",
       "68    0.181677         0.0         2.0       0.00  ...         0.562814   \n",
       "69    0.203022         0.0         2.0       0.00  ...         0.562814   \n",
       "70    0.216331         0.0         2.0       0.00  ...         0.562814   \n",
       "71    0.222711         0.0         1.0       0.04  ...         0.559045   \n",
       "\n",
       "    var_coeff_gyro2  var_coeff_gyro3  kurtosis_accel1  kurtosis_accel2  \\\n",
       "0          0.009334         0.136847         0.188756              0.0   \n",
       "1          0.009095         0.137426         0.223304              0.0   \n",
       "2          0.003719         0.131167         0.201319              0.0   \n",
       "3          0.002198         0.127450         0.185302              0.0   \n",
       "4          0.000113         0.126936         0.185302              0.0   \n",
       "..              ...              ...              ...              ...   \n",
       "67         0.004372         0.107036         0.145729              0.0   \n",
       "68         0.002387         0.096728         0.145729              0.0   \n",
       "69        -0.000402         0.093748         0.145729              0.0   \n",
       "70        -0.003920         0.100980         0.145729              0.0   \n",
       "71        -0.005942         0.112796         0.158291              0.0   \n",
       "\n",
       "    kurtosis_accel3  kurtosis_gyro1  kurtosis_gyro2  kurtosis_gyro3  tag  \n",
       "0               1.0            0.14        0.275968       -0.960621  0.0  \n",
       "1               1.0            0.14        0.267198       -1.087590  0.0  \n",
       "2               2.0            0.18        0.250598       -0.998598  0.0  \n",
       "3               2.0            0.18        0.240380       -0.874532  0.0  \n",
       "4               2.0            0.18        0.238541       -0.847370  0.0  \n",
       "..              ...             ...             ...             ...  ...  \n",
       "67              2.0            0.08        0.188983       -0.345404  0.0  \n",
       "68              2.0            0.12        0.168880       -0.719264  0.0  \n",
       "69              2.0            0.12        0.163197       -0.898353  0.0  \n",
       "70              2.0            0.12        0.177072       -0.475365  0.0  \n",
       "71              2.0            0.12        0.201060       -0.351155  0.0  \n",
       "\n",
       "[72 rows x 73 columns]"
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.df.head(72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hierarchical = df.copy()\n",
    "df_hierarchical['tag'] = df_hierarchical['tag'].apply(lambda x: 0 if x <= 7 else 1)\n",
    "\n",
    "msk = np.random.rand(len(df_hierarchical)) < 0.8\n",
    "df_train = df_hierarchical[msk]\n",
    "df_test = df_hierarchical[~msk]\n",
    "\n",
    "dataset = FeatureDataset(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hierarchical = MLP(D_in, 50, 2)\n",
    "optimizer = torch.optim.SGD(model_hierarchical.parameters(), lr=0.01, momentum=0.5)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "model, losses, accuracies = train_val_model(model_hierarchical, criterion, optimizer, dataset.X, dataset.y, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'MLP_Model_Hierarchical_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(losses['train'], '-b', losses['val'], '--r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = MLP(D_in, 50, 2)\n",
    "mlp_model.load('MLP_Model_Hierarchical_1')\n",
    "mlp_model.eval()\n",
    "\n",
    "for to_predict in range(2):\n",
    "    df_target = df_test[df_test['tag'] == to_predict]\n",
    "\n",
    "    df_random = df_test\n",
    "\n",
    "    df_filtered = torch.from_numpy(np.array(pd.merge(df_target, df_random))[:,:-1])\n",
    "    output = mlp_model.predict(df_filtered)\n",
    "    # print(output)\n",
    "    proba_dict = {}\n",
    "\n",
    "    for x in output:\n",
    "        x = int(x)\n",
    "        if x not in proba_dict:\n",
    "            proba_dict[x] = 1\n",
    "        else:\n",
    "            proba_dict[x] += 1\n",
    "    for k in proba_dict.keys():\n",
    "        proba_dict[k] /= len(output)\n",
    "    print(dict(sorted(proba_dict.items(), key=lambda item: -item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hierarchical_2 = df.copy()\n",
    "df_hierarchical_2 = df_hierarchical_2[df_hierarchical_2['tag'] >= 8]\n",
    "df_hierarchical_2 = df_hierarchical_2.apply(lambda x: x-8)\n",
    "msk = np.random.rand(len(df_hierarchical_2)) < 0.8\n",
    "df_train = df_hierarchical_2[msk]\n",
    "df_test = df_hierarchical_2[~msk]\n",
    "\n",
    "dataset = FeatureDataset(df_train)\n",
    "\n",
    "model_hierarchical_2 = MLP(D_in, 50, 2)\n",
    "# optimizer = torch.optim.Adam(model_hierarchical_2.parameters(), lr=1e-4)\n",
    "optimizer = torch.optim.SGD(model_hierarchical_2.parameters(), lr=0.01, momentum=0.5)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model, losses, accuracies = train_val_model(model_hierarchical_2, criterion, optimizer, dataset.X, dataset.y, num_epochs=20)\n",
    "\n",
    "torch.save(model.state_dict(), 'MLP_Model_Hierarchical_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(losses['train'], '-b', losses['val'], '--r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = MLP(D_in, 50, 2)\n",
    "mlp_model.load('MLP_Model_Hierarchical_2')\n",
    "mlp_model.eval()\n",
    "\n",
    "for to_predict in range(2):\n",
    "    df_target = df_test[df_test['tag'] == to_predict]\n",
    "\n",
    "    df_random = df_test\n",
    "\n",
    "    df_filtered = torch.from_numpy(np.array(pd.merge(df_target, df_random))[:,:-1])\n",
    "    output = mlp_model.predict(df_filtered)\n",
    "    # print(output)\n",
    "    proba_dict = {}\n",
    "\n",
    "    for x in output:\n",
    "        x = int(x) + 8\n",
    "        if x not in proba_dict:\n",
    "            proba_dict[x] = 1\n",
    "        else:\n",
    "            proba_dict[x] += 1\n",
    "    for k in proba_dict.keys():\n",
    "        proba_dict[k] /= len(output)\n",
    "\n",
    "    print(dict(sorted(proba_dict.items(), key=lambda item: -item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hierarchical_3 = df.copy()\n",
    "df_hierarchical_3 = df_hierarchical_3[df_hierarchical_3['tag'] < 8]\n",
    "msk = np.random.rand(len(df_hierarchical_3)) < 0.8\n",
    "df_train = df_hierarchical_3[msk]\n",
    "df_test = df_hierarchical_3[~msk]\n",
    "\n",
    "dataset = FeatureDataset(df_train)\n",
    "\n",
    "model_hierarchical_3 = MLP(D_in, 50, 8)\n",
    "# optimizer = torch.optim.Adam(model_hierarchical_2.parameters(), lr=1e-4)\n",
    "optimizer = torch.optim.SGD(model_hierarchical_3.parameters(), lr=0.01, momentum=0.5)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "model, losses, accuracies = train_val_model(model_hierarchical_3, criterion, optimizer, dataset.X, dataset.y, num_epochs=30)\n",
    "\n",
    "torch.save(model.state_dict(), 'MLP_Model_Hierarchical_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(losses['train'], '-b', losses['val'], '--r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = MLP(D_in, 50, 8)\n",
    "mlp_model.load('MLP_Model_Hierarchical_3')\n",
    "mlp_model.eval()\n",
    "\n",
    "for to_predict in range(8):\n",
    "    df_target = df_test[df_test['tag'] == to_predict]\n",
    "\n",
    "    df_random = df_test\n",
    "\n",
    "    df_filtered = torch.from_numpy(np.array(pd.merge(df_target, df_random))[:,:-1])\n",
    "    output = mlp_model.predict(df_filtered)\n",
    "    # print(output)\n",
    "    proba_dict = {}\n",
    "\n",
    "    for x in output:\n",
    "        x = int(x)\n",
    "        if x not in proba_dict:\n",
    "            proba_dict[x] = 1\n",
    "        else:\n",
    "            proba_dict[x] += 1\n",
    "    for k in proba_dict.keys():\n",
    "        proba_dict[k] /= len(output)\n",
    "\n",
    "    print(dict(sorted(proba_dict.items(), key=lambda item: -item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 4)]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "lst = [1,1,1,1,2,3]\n",
    "print(statistics._counts(lst))\n",
    "print(max([p[0] for p in statistics._counts(lst)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidating Data\n",
      "(4352, 7) (4338, 7)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "# X, y = make_classification(n_samples=100, random_state=1)\n",
    "train, test = consolidate_data()\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(train)[:,:-1], np.array(train)[:,-1], random_state=1)\n",
    "# print(X_train.shape, y_train.shape)\n",
    "clf = MLPClassifier(solver='adam', alpha=1e-5, random_state=1, max_iter=2000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6167279411764706"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(490, 6)\n",
      "{1: 0.6, 7: 0.16938775510204082, 5: 0.07959183673469387, 6: 0.07755102040816327, 4: 0.036734693877551024, 8: 0.014285714285714285, 2: 0.012244897959183673, 3: 0.01020408163265306}\n",
      "(554, 6)\n",
      "{2: 0.33393501805054154, 5: 0.24548736462093862, 3: 0.16787003610108303, 1: 0.07581227436823104, 7: 0.06498194945848375, 6: 0.05595667870036101, 4: 0.039711191335740074, 8: 0.016245487364620937}\n",
      "(538, 6)\n",
      "{3: 0.2899628252788104, 5: 0.25650557620817843, 4: 0.12825278810408922, 2: 0.09851301115241635, 6: 0.07434944237918216, 7: 0.05947955390334572, 1: 0.048327137546468404, 8: 0.04460966542750929}\n",
      "(536, 6)\n",
      "{4: 0.34328358208955223, 3: 0.1623134328358209, 5: 0.14925373134328357, 2: 0.125, 1: 0.11194029850746269, 6: 0.08768656716417911, 7: 0.011194029850746268, 8: 0.009328358208955223}\n",
      "(546, 6)\n",
      "{5: 0.38644688644688646, 2: 0.152014652014652, 4: 0.10989010989010989, 1: 0.1043956043956044, 6: 0.1043956043956044, 7: 0.06227106227106227, 3: 0.04395604395604396, 8: 0.03663003663003663}\n",
      "(555, 6)\n",
      "{6: 0.572972972972973, 7: 0.12072072072072072, 1: 0.1063063063063063, 8: 0.055855855855855854, 4: 0.05405405405405406, 5: 0.032432432432432434, 2: 0.032432432432432434, 3: 0.025225225225225224}\n",
      "(573, 6)\n",
      "{7: 0.7958115183246073, 1: 0.05410122164048865, 8: 0.0506108202443281, 5: 0.04886561954624782, 2: 0.019197207678883072, 6: 0.012216404886561954, 3: 0.010471204188481676, 4: 0.008726003490401396}\n",
      "(546, 6)\n",
      "{8: 0.8992673992673993, 2: 0.05311355311355311, 7: 0.02564102564102564, 1: 0.01098901098901099, 5: 0.009157509157509158, 3: 0.0018315018315018315}\n"
     ]
    }
   ],
   "source": [
    "test = np.array(test)\n",
    "for to_predict in range(8):\n",
    "    df_target = test[test[:,-1] == to_predict+1][:,:-1]\n",
    "    print(df_target.shape)\n",
    "    output = clf.predict(df_target)\n",
    "    # print(output)\n",
    "    proba_dict = {}\n",
    "\n",
    "    for x in output:\n",
    "        x = int(x)\n",
    "        if x not in proba_dict:\n",
    "            proba_dict[x] = 1\n",
    "        else:\n",
    "            proba_dict[x] += 1\n",
    "    for k in proba_dict.keys():\n",
    "        proba_dict[k] /= len(output)\n",
    "\n",
    "    print(dict(sorted(proba_dict.items(), key=lambda item: -item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 6 is different from 72)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-131-930d625d1bae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mdf_filtered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_random\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mdf_filtered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_filtered\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_filtered\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;31m# print(output)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mproba_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    969\u001b[0m         \"\"\"\n\u001b[0;32m    970\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 971\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    973\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    683\u001b[0m                                          layer_units[i + 1])))\n\u001b[0;32m    684\u001b[0m         \u001b[1;31m# forward propagate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_forward_pass\u001b[1;34m(self, activations)\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_layers_\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m             activations[i + 1] = safe_sparse_dot(activations[i],\n\u001b[1;32m--> 104\u001b[1;33m                                                  self.coefs_[i])\n\u001b[0m\u001b[0;32m    105\u001b[0m             \u001b[0mactivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercepts_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    149\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 6 is different from 72)"
     ]
    }
   ],
   "source": [
    "# mlp_model = MLP(D_in, 50, 8)\n",
    "# mlp_model.load('MLP_Model_Hierarchical_3')\n",
    "# mlp_model.eval()\n",
    "\n",
    "for to_predict in range(8):\n",
    "    df_target = df_test[df_test['tag'] == to_predict]\n",
    "\n",
    "    df_random = df_test\n",
    "\n",
    "    df_filtered = torch.from_numpy(np.array(pd.merge(df_target, df_random))[:,:-1])\n",
    "    df_filtered = df_filtered\n",
    "    output = clf.predict(df_filtered)\n",
    "    # print(output)\n",
    "    proba_dict = {}\n",
    "\n",
    "    for x in output:\n",
    "        x = int(x)\n",
    "        if x not in proba_dict:\n",
    "            proba_dict[x] = 1\n",
    "        else:\n",
    "            proba_dict[x] += 1\n",
    "    for k in proba_dict.keys():\n",
    "        proba_dict[k] /= len(output)\n",
    "\n",
    "    print(dict(sorted(proba_dict.items(), key=lambda item: -item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase: 0\n",
      "dab\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{3: 1.0}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{3: 1.0}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{3: 1.0}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{3: 1.0}\n",
      "elbowkick\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{5: 1.0}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{2: 0.5714285714285714, 3: 0.42857142857142855}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{5: 0.7142857142857143, 3: 0.14285714285714285, 0: 0.14285714285714285}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{3: 0.7142857142857143, 2: 0.2857142857142857}\n",
      "gun\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{3: 1.0}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{2: 0.7142857142857143, 3: 0.2857142857142857}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{2: 0.7142857142857143, 3: 0.2857142857142857}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{2: 0.8571428571428571, 3: 0.14285714285714285}\n",
      "hair\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{3: 0.8571428571428571, 5: 0.14285714285714285}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{3: 1.0}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{2: 1.0}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{3: 1.0}\n",
      "listen\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{3: 0.8571428571428571, 2: 0.14285714285714285}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{2: 0.7142857142857143, 3: 0.14285714285714285, 5: 0.14285714285714285}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{3: 1.0}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{3: 1.0}\n",
      "pointhigh\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-1b9113030eef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m                     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[0mdf_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m                 \u001b[0mdf_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_target\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-f184b95c7117>\u001b[0m in \u001b[0;36mfeature_extraction\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_extract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[1;31m# print(features.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-f184b95c7117>\u001b[0m in \u001b[0;36mfeature_extract\u001b[1;34m(df, window_size)\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[1;31m# full_features = np.append(full_features, add_cwt(ax))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[0mfull_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_no_peaks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                 \u001b[0mfull_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_recurring_dp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m                 \u001b[1;31m# full_features = np.append(full_features, add_ratio_v_tsl(ax))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[1;31m# full_features = np.append(full_features, add_sum_recurring_dp(ax))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\CG4002_B07\\feature_extraction.py\u001b[0m in \u001b[0;36madd_recurring_dp\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0madd_recurring_dp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfeature_calculators\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpercentage_of_reoccurring_datapoints_to_all_datapoints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0madd_ratio_v_tsl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tsfresh\\feature_extraction\\feature_calculators.py\u001b[0m in \u001b[0;36mpercentage_of_reoccurring_datapoints_to_all_datapoints\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    925\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 927\u001b[1;33m     \u001b[0mvalue_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    928\u001b[0m     \u001b[0mreoccuring_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue_counts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalue_counts\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36mvalue_counts\u001b[1;34m(self, normalize, sort, ascending, bins, dropna)\u001b[0m\n\u001b[0;32m   1242\u001b[0m             \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m             \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1244\u001b[1;33m             \u001b[0mdropna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1245\u001b[0m         )\n\u001b[0;32m   1246\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mvalue_counts\u001b[1;34m(values, sort, ascending, normalize, bins, dropna)\u001b[0m\n\u001b[0;32m    726\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36msort_values\u001b[1;34m(self, axis, ascending, inplace, kind, na_position, ignore_index)\u001b[0m\n\u001b[0;32m   2977\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mna_position\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"last\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgood\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2979\u001b[1;33m             \u001b[0msorted_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgood\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margsorted\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2980\u001b[0m             \u001b[0msorted_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbad\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2981\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mna_position\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"first\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\range.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    706\u001b[0m             )\n\u001b[0;32m    707\u001b[0m         \u001b[1;31m# fall back to Int64Index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__floordiv__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3923\u001b[0m         \u001b[1;31m# There's no custom logic to be implemented in __getslice__, so it's\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3924\u001b[0m         \u001b[1;31m# not overloaded intentionally.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3925\u001b[1;33m         \u001b[0mgetitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3926\u001b[0m         \u001b[0mpromote\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shallow_copy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\range.py\u001b[0m in \u001b[0;36m_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cached_data\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             self._cached_data = np.arange(\n\u001b[1;32m--> 166\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m             )\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cached_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "dances = ['dab', 'elbowkick', 'gun', 'hair', 'listen', 'pointhigh', 'sidepump', 'wipetable']\n",
    "# dances = ['gun', 'hair', 'sidepump']\n",
    "# dances = ['elbowkick', 'pointhigh', 'wipetable']\n",
    "persons = ['kelvin', 'guiyong', 'xiaoxue', 'john']\n",
    "beetles = ['1', '2']\n",
    "\n",
    "test_range = 12\n",
    "leap = 80\n",
    "truth, total, skipped = 0,0,0\n",
    "for i in range(0,0+test_range):\n",
    "    print(\"Phase:\", i)\n",
    "    start, end = i * leap, i * leap + leap\n",
    "    for d in dances:\n",
    "        print(d)\n",
    "        df_full = pd.DataFrame()\n",
    "        collection = [np.array([]) for x in range(16)]\n",
    "        j = 0\n",
    "        for p in persons:\n",
    "            for b in beetles:\n",
    "                if b == '1':\n",
    "                    continue\n",
    "                move_json = 'collected_data/' + d + b + '_' + p + '.json'\n",
    "                with open(move_json) as f:\n",
    "                    x = json.load(f)\n",
    "                x = pd.DataFrame.from_dict(x)[start:end]\n",
    "                df_target = torch.from_numpy(np.array(feature_extraction(x)))\n",
    "                df_target = df_target\n",
    "                output = clf.predict(df_target)\n",
    "                proba_dict = {}\n",
    "\n",
    "                for x in output:\n",
    "                    x = int(x)\n",
    "                    if x not in proba_dict:\n",
    "                        proba_dict[x] = 1\n",
    "                    else:\n",
    "                        proba_dict[x] += 1\n",
    "                for k in proba_dict.keys():\n",
    "                    proba_dict[k] /= len(output)\n",
    "\n",
    "                print(dict(sorted(proba_dict.items(), key=lambda item: -item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase: 0\n",
      "dab\n",
      "{7: 0.6, 4: 0.225, 5: 0.1125, 6: 0.0375, 2: 0.025}\n",
      "{6: 0.4625, 7: 0.375, 5: 0.1625}\n",
      "{5: 0.35, 6: 0.3125, 7: 0.2875, 2: 0.05}\n",
      "{6: 0.3625, 2: 0.25, 7: 0.2, 5: 0.1875}\n",
      "elbowkick\n",
      "{7: 0.4, 3: 0.275, 5: 0.175, 4: 0.0875, 6: 0.0375, 2: 0.025}\n",
      "{2: 0.3, 6: 0.275, 7: 0.2375, 5: 0.1875}\n",
      "{2: 0.4125, 6: 0.3875, 7: 0.2}\n",
      "{7: 0.45, 2: 0.375, 6: 0.175}\n",
      "gun\n",
      "{7: 0.4375, 4: 0.2, 3: 0.15, 6: 0.1, 5: 0.0625, 2: 0.05}\n",
      "{7: 0.325, 6: 0.325, 2: 0.25, 5: 0.1}\n",
      "{2: 0.4, 7: 0.3125, 5: 0.1875, 6: 0.1}\n",
      "{7: 0.35, 2: 0.2625, 5: 0.225, 6: 0.1625}\n",
      "hair\n",
      "{7: 0.5, 4: 0.2875, 5: 0.15, 6: 0.05, 3: 0.0125}\n",
      "{6: 0.325, 2: 0.275, 5: 0.2625, 7: 0.1375}\n",
      "{6: 0.325, 2: 0.275, 5: 0.2625, 7: 0.1375}\n",
      "{2: 0.3625, 6: 0.2875, 5: 0.275, 7: 0.075}\n",
      "listen\n",
      "{7: 0.6625, 4: 0.175, 5: 0.0875, 2: 0.0375, 6: 0.0375}\n",
      "{6: 0.3125, 7: 0.2875, 5: 0.2375, 2: 0.1375, 4: 0.025}\n",
      "{6: 0.5125, 2: 0.2375, 4: 0.1625, 5: 0.075, 3: 0.0125}\n",
      "{7: 0.4, 2: 0.275, 5: 0.175, 6: 0.15}\n",
      "pointhigh\n",
      "{4: 0.475, 7: 0.3625, 5: 0.15, 6: 0.0125}\n",
      "{6: 0.5625, 2: 0.175, 5: 0.1625, 7: 0.1}\n",
      "{2: 0.375, 6: 0.2375, 5: 0.2375, 7: 0.1125, 4: 0.0375}\n",
      "{5: 0.4125, 6: 0.3875, 7: 0.1125, 2: 0.0875}\n",
      "sidepump\n",
      "{7: 0.5125, 4: 0.1875, 3: 0.1125, 2: 0.1, 5: 0.0875}\n",
      "{6: 0.375, 7: 0.2625, 2: 0.25, 5: 0.075, 4: 0.0375}\n",
      "{2: 0.3, 6: 0.2625, 5: 0.2, 7: 0.1625, 4: 0.075}\n",
      "{2: 0.4375, 6: 0.35, 7: 0.1875, 4: 0.025}\n",
      "wipetable\n",
      "{7: 0.7125, 3: 0.2625, 2: 0.025}\n",
      "{7: 0.4125, 2: 0.3625, 6: 0.225}\n",
      "{6: 0.4125, 7: 0.3, 2: 0.2875}\n",
      "{6: 0.6375, 2: 0.25, 7: 0.1125}\n",
      "Phase: 1\n",
      "dab\n",
      "{7: 0.55, 4: 0.1875, 5: 0.1875, 6: 0.075}\n",
      "{6: 0.475, 5: 0.3125, 7: 0.1875, 2: 0.025}\n",
      "{6: 0.3375, 5: 0.3125, 7: 0.2, 2: 0.15}\n",
      "{6: 0.3125, 7: 0.3125, 2: 0.225, 5: 0.15}\n",
      "elbowkick\n",
      "{7: 0.3875, 3: 0.2625, 4: 0.15, 6: 0.1, 2: 0.0625, 5: 0.0375}\n",
      "{2: 0.3875, 7: 0.3375, 6: 0.2125, 5: 0.0625}\n",
      "{2: 0.5625, 7: 0.275, 6: 0.1625}\n",
      "{2: 0.4375, 7: 0.425, 6: 0.125, 4: 0.0125}\n",
      "gun\n",
      "{7: 0.4375, 4: 0.225, 3: 0.1625, 6: 0.1125, 5: 0.0375, 2: 0.025}\n",
      "{6: 0.35, 7: 0.275, 2: 0.2125, 5: 0.1625}\n",
      "{7: 0.475, 2: 0.2625, 5: 0.1375, 6: 0.125}\n",
      "{7: 0.4, 5: 0.2375, 2: 0.2, 6: 0.1625}\n",
      "hair\n",
      "{7: 0.4, 4: 0.275, 5: 0.1, 6: 0.0875, 3: 0.075, 2: 0.0625}\n",
      "{6: 0.4, 2: 0.225, 7: 0.2125, 5: 0.1625}\n",
      "{5: 0.375, 6: 0.25, 2: 0.225, 7: 0.15}\n",
      "{5: 0.375, 2: 0.35, 6: 0.2625, 7: 0.0125}\n",
      "listen\n",
      "{7: 0.6375, 4: 0.175, 6: 0.1, 5: 0.05, 2: 0.0375}\n",
      "{7: 0.4125, 6: 0.2875, 5: 0.1625, 2: 0.125, 4: 0.0125}\n",
      "{6: 0.475, 2: 0.3125, 5: 0.1375, 4: 0.075}\n",
      "{7: 0.35, 2: 0.2625, 5: 0.225, 6: 0.1625}\n",
      "pointhigh\n",
      "{4: 0.45, 7: 0.275, 5: 0.1875, 3: 0.075, 6: 0.0125}\n",
      "{6: 0.5, 5: 0.3, 2: 0.1375, 7: 0.0625}\n",
      "{2: 0.4625, 5: 0.3375, 6: 0.15, 7: 0.0375, 4: 0.0125}\n",
      "{5: 0.475, 6: 0.4125, 2: 0.0875, 7: 0.025}\n",
      "sidepump\n",
      "{4: 0.4125, 7: 0.325, 3: 0.1125, 2: 0.0875, 5: 0.05, 6: 0.0125}\n",
      "{6: 0.3375, 7: 0.2875, 2: 0.25, 5: 0.0875, 4: 0.0375}\n",
      "{2: 0.3875, 5: 0.2625, 6: 0.175, 7: 0.1125, 4: 0.0625}\n",
      "{6: 0.5375, 2: 0.3375, 7: 0.125}\n",
      "wipetable\n",
      "{7: 0.55, 3: 0.4125, 2: 0.025, 5: 0.0125}\n",
      "{2: 0.4625, 7: 0.325, 6: 0.2125}\n",
      "{6: 0.5125, 2: 0.3, 7: 0.1875}\n",
      "{6: 0.575, 2: 0.3, 7: 0.125}\n",
      "Phase: 2\n",
      "dab\n",
      "{7: 0.5625, 5: 0.2, 6: 0.125, 4: 0.1125}\n",
      "{6: 0.5625, 5: 0.2625, 7: 0.1375, 2: 0.0375}\n",
      "{6: 0.4375, 5: 0.275, 7: 0.25, 2: 0.0375}\n",
      "{6: 0.375, 2: 0.3125, 7: 0.1625, 5: 0.15}\n",
      "elbowkick\n",
      "{7: 0.375, 3: 0.3, 4: 0.1625, 5: 0.075, 6: 0.0625, 2: 0.025}\n",
      "{2: 0.375, 7: 0.2875, 6: 0.2125, 5: 0.125}\n",
      "{2: 0.525, 7: 0.3125, 6: 0.1625}\n",
      "{2: 0.425, 7: 0.3625, 6: 0.2125}\n",
      "gun\n",
      "{7: 0.5625, 3: 0.125, 4: 0.1125, 6: 0.075, 2: 0.0625, 5: 0.0625}\n",
      "{7: 0.3, 6: 0.2875, 2: 0.2625, 5: 0.15}\n",
      "{7: 0.5, 2: 0.2625, 6: 0.125, 5: 0.1125}\n",
      "{7: 0.35, 5: 0.275, 6: 0.2125, 2: 0.1625}\n",
      "hair\n",
      "{7: 0.475, 5: 0.2125, 4: 0.1125, 3: 0.075, 6: 0.075, 2: 0.05}\n",
      "{2: 0.275, 5: 0.2625, 6: 0.2625, 7: 0.2}\n",
      "{5: 0.3875, 2: 0.3, 6: 0.1875, 7: 0.125}\n",
      "{6: 0.45, 5: 0.275, 2: 0.1875, 7: 0.0875}\n",
      "listen\n",
      "{7: 0.6875, 6: 0.1125, 4: 0.1, 5: 0.0625, 3: 0.025, 2: 0.0125}\n",
      "{6: 0.35, 7: 0.3125, 5: 0.2125, 2: 0.125}\n",
      "{6: 0.4875, 2: 0.225, 4: 0.1875, 5: 0.1}\n",
      "{7: 0.3375, 2: 0.3, 5: 0.2375, 6: 0.125}\n",
      "pointhigh\n",
      "{4: 0.3625, 7: 0.3625, 5: 0.15, 3: 0.125}\n",
      "{6: 0.6, 5: 0.1875, 2: 0.15, 7: 0.0625}\n",
      "{2: 0.55, 5: 0.25, 6: 0.1125, 7: 0.075, 4: 0.0125}\n",
      "{6: 0.5625, 5: 0.3375, 7: 0.0625, 2: 0.0375}\n",
      "sidepump\n",
      "{4: 0.5875, 7: 0.3125, 5: 0.05, 3: 0.0375, 2: 0.0125}\n",
      "{7: 0.3875, 6: 0.3375, 2: 0.175, 5: 0.075, 4: 0.025}\n",
      "{2: 0.55, 6: 0.2875, 5: 0.1625}\n",
      "{2: 0.525, 6: 0.2625, 7: 0.2125}\n",
      "wipetable\n",
      "{7: 0.7375, 3: 0.2625}\n",
      "{7: 0.35, 6: 0.325, 2: 0.325}\n",
      "{6: 0.5625, 2: 0.3, 7: 0.1375}\n",
      "{6: 0.6, 7: 0.2375, 2: 0.1625}\n",
      "Phase: 3\n",
      "dab\n",
      "{7: 0.4875, 4: 0.1875, 5: 0.175, 6: 0.15}\n",
      "{6: 0.55, 5: 0.2625, 7: 0.15, 2: 0.0375}\n",
      "{6: 0.375, 7: 0.275, 5: 0.225, 2: 0.125}\n",
      "{2: 0.3875, 6: 0.325, 5: 0.2, 7: 0.0875}\n",
      "elbowkick\n",
      "{7: 0.35, 3: 0.2, 4: 0.1625, 5: 0.1625, 6: 0.075, 2: 0.05}\n",
      "{2: 0.4125, 7: 0.3125, 6: 0.2125, 5: 0.0625}\n",
      "{7: 0.5375, 2: 0.2375, 6: 0.225}\n",
      "{2: 0.5, 7: 0.3875, 6: 0.1125}\n",
      "gun\n",
      "{7: 0.625, 3: 0.15, 4: 0.0875, 6: 0.075, 5: 0.05, 2: 0.0125}\n",
      "{2: 0.2875, 6: 0.275, 7: 0.275, 5: 0.1625}\n",
      "{7: 0.3875, 2: 0.3875, 5: 0.1375, 6: 0.0875}\n",
      "{7: 0.5125, 5: 0.2125, 2: 0.1375, 6: 0.125, 4: 0.0125}\n",
      "hair\n",
      "{4: 0.3625, 7: 0.3125, 3: 0.1, 5: 0.1, 6: 0.0875, 2: 0.0375}\n",
      "{6: 0.375, 2: 0.2875, 5: 0.2125, 7: 0.125}\n",
      "{5: 0.3625, 2: 0.2875, 6: 0.225, 7: 0.125}\n",
      "{5: 0.4, 6: 0.2875, 2: 0.2625, 7: 0.05}\n",
      "listen\n",
      "{7: 0.6875, 4: 0.1875, 6: 0.0875, 5: 0.025, 2: 0.0125}\n",
      "{6: 0.3, 7: 0.3, 5: 0.275, 2: 0.125}\n",
      "{6: 0.6, 2: 0.2, 4: 0.175, 5: 0.025}\n",
      "{2: 0.3, 7: 0.2875, 5: 0.2125, 6: 0.2}\n",
      "pointhigh\n",
      "{4: 0.5, 7: 0.325, 3: 0.0875, 5: 0.0875}\n",
      "{6: 0.425, 5: 0.325, 2: 0.1625, 7: 0.0875}\n",
      "{2: 0.5375, 6: 0.1875, 5: 0.1625, 7: 0.1125}\n",
      "{5: 0.6, 6: 0.2625, 7: 0.1375}\n",
      "sidepump\n",
      "{4: 0.5875, 7: 0.2125, 3: 0.0875, 5: 0.0625, 2: 0.05}\n",
      "{7: 0.375, 2: 0.2875, 6: 0.2875, 5: 0.025, 4: 0.025}\n",
      "{2: 0.575, 6: 0.2, 5: 0.1125, 7: 0.0875, 4: 0.025}\n",
      "{2: 0.4125, 6: 0.2875, 7: 0.275, 4: 0.0125, 5: 0.0125}\n",
      "wipetable\n",
      "{7: 0.65, 3: 0.3125, 5: 0.025, 2: 0.0125}\n",
      "{2: 0.375, 7: 0.35, 6: 0.275}\n",
      "{6: 0.45, 2: 0.4, 7: 0.15}\n",
      "{6: 0.6125, 2: 0.2125, 7: 0.175}\n",
      "Phase: 4\n",
      "dab\n",
      "{7: 0.6625, 4: 0.15, 5: 0.125, 6: 0.0625}\n",
      "{6: 0.4875, 5: 0.3, 7: 0.175, 2: 0.0375}\n",
      "{5: 0.2875, 7: 0.275, 6: 0.25, 2: 0.15, 4: 0.0375}\n",
      "{6: 0.3875, 7: 0.2625, 2: 0.2625, 5: 0.0875}\n",
      "elbowkick\n",
      "{7: 0.4375, 3: 0.2625, 4: 0.1125, 5: 0.0875, 6: 0.0625, 2: 0.0375}\n",
      "{2: 0.4625, 7: 0.2375, 6: 0.2125, 5: 0.0875}\n",
      "{2: 0.5625, 7: 0.225, 6: 0.2125}\n",
      "{7: 0.4125, 2: 0.3875, 6: 0.1875, 4: 0.0125}\n",
      "gun\n",
      "{7: 0.3375, 4: 0.2125, 3: 0.2, 6: 0.1, 5: 0.0875, 2: 0.0625}\n",
      "{2: 0.375, 6: 0.2375, 7: 0.225, 5: 0.1625}\n",
      "{7: 0.575, 2: 0.2625, 6: 0.1125, 5: 0.05}\n",
      "{7: 0.5875, 6: 0.1625, 2: 0.15, 5: 0.1}\n",
      "hair\n",
      "{7: 0.3875, 4: 0.2, 5: 0.1875, 3: 0.1375, 6: 0.05, 2: 0.0375}\n",
      "{6: 0.3875, 2: 0.2375, 7: 0.225, 5: 0.1125, 4: 0.0375}\n",
      "{5: 0.325, 2: 0.2875, 6: 0.225, 7: 0.1625}\n",
      "{5: 0.425, 6: 0.25, 2: 0.2375, 7: 0.0875}\n",
      "listen\n",
      "{7: 0.675, 4: 0.1625, 6: 0.1, 5: 0.0375, 2: 0.025}\n",
      "{6: 0.325, 5: 0.3125, 7: 0.2125, 2: 0.15}\n",
      "{4: 0.35, 6: 0.3125, 2: 0.2, 5: 0.1375}\n",
      "{2: 0.35, 7: 0.2625, 5: 0.2375, 6: 0.15}\n",
      "pointhigh\n",
      "{4: 0.4, 7: 0.3875, 3: 0.125, 5: 0.075, 2: 0.0125}\n",
      "{6: 0.6625, 5: 0.175, 2: 0.1125, 7: 0.05}\n",
      "{2: 0.3625, 5: 0.275, 6: 0.2625, 7: 0.075, 4: 0.025}\n",
      "{6: 0.575, 5: 0.3125, 7: 0.0875, 2: 0.025}\n",
      "sidepump\n",
      "{7: 0.5, 4: 0.2625, 5: 0.1, 2: 0.0625, 3: 0.05, 6: 0.025}\n",
      "{7: 0.35, 2: 0.3125, 6: 0.3, 5: 0.0375}\n",
      "{2: 0.625, 6: 0.15, 7: 0.125, 5: 0.0625, 4: 0.0375}\n",
      "{2: 0.3875, 6: 0.3375, 7: 0.2625, 4: 0.0125}\n",
      "wipetable\n",
      "{7: 0.6625, 3: 0.2625, 5: 0.0625, 2: 0.0125}\n",
      "{2: 0.35, 7: 0.35, 6: 0.3}\n",
      "{6: 0.525, 2: 0.325, 7: 0.15}\n",
      "{6: 0.7125, 2: 0.25, 7: 0.0375}\n",
      "Phase: 5\n",
      "dab\n",
      "{7: 0.675, 4: 0.1625, 5: 0.1125, 6: 0.0375, 2: 0.0125}\n",
      "{6: 0.525, 5: 0.3, 2: 0.125, 7: 0.05}\n",
      "{7: 0.2875, 2: 0.2625, 5: 0.225, 6: 0.1875, 4: 0.0375}\n",
      "{6: 0.375, 2: 0.3, 7: 0.2375, 5: 0.0875}\n",
      "elbowkick\n",
      "{7: 0.4125, 3: 0.25, 4: 0.15, 5: 0.075, 6: 0.0625, 2: 0.05}\n",
      "{7: 0.4, 2: 0.275, 6: 0.25, 5: 0.075}\n",
      "{7: 0.5375, 2: 0.2375, 6: 0.225}\n",
      "{2: 0.4875, 7: 0.35, 6: 0.15, 4: 0.0125}\n",
      "gun\n",
      "{7: 0.4125, 3: 0.1875, 4: 0.1625, 6: 0.125, 5: 0.075, 2: 0.0375}\n",
      "{2: 0.3125, 6: 0.275, 7: 0.2625, 5: 0.15}\n",
      "{7: 0.425, 2: 0.2875, 5: 0.15, 6: 0.1375}\n",
      "{7: 0.6125, 5: 0.1875, 6: 0.15, 2: 0.05}\n",
      "hair\n",
      "{4: 0.3125, 7: 0.3, 3: 0.1875, 6: 0.0875, 5: 0.0625, 2: 0.05}\n",
      "{6: 0.3375, 7: 0.2625, 2: 0.2, 5: 0.1875, 4: 0.0125}\n",
      "{5: 0.3875, 6: 0.275, 2: 0.275, 7: 0.0625}\n",
      "{6: 0.375, 2: 0.2875, 5: 0.2875, 7: 0.05}\n",
      "listen\n",
      "{7: 0.7875, 6: 0.1125, 4: 0.0875, 2: 0.0125}\n",
      "{6: 0.35, 7: 0.35, 5: 0.1625, 2: 0.1375}\n",
      "{6: 0.5, 2: 0.2, 4: 0.175, 5: 0.1125, 3: 0.0125}\n",
      "{2: 0.325, 7: 0.3125, 5: 0.2, 6: 0.1625}\n",
      "pointhigh\n",
      "{4: 0.425, 7: 0.3125, 5: 0.2, 3: 0.0625}\n",
      "{6: 0.5125, 5: 0.275, 2: 0.1375, 7: 0.075}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 0.475, 5: 0.3625, 6: 0.1375, 7: 0.025}\n",
      "{6: 0.4625, 5: 0.4125, 2: 0.125}\n",
      "sidepump\n",
      "{7: 0.4, 4: 0.35, 3: 0.1, 2: 0.0875, 5: 0.05, 6: 0.0125}\n",
      "{2: 0.475, 6: 0.3125, 7: 0.1875, 4: 0.025}\n",
      "{2: 0.4625, 6: 0.2375, 7: 0.175, 5: 0.1125, 4: 0.0125}\n",
      "{2: 0.675, 7: 0.2375, 6: 0.0625, 5: 0.0125, 4: 0.0125}\n",
      "wipetable\n",
      "{7: 0.6375, 3: 0.275, 2: 0.05, 5: 0.0375}\n",
      "{6: 0.3875, 7: 0.325, 2: 0.2875}\n",
      "{6: 0.5125, 2: 0.275, 7: 0.2125}\n",
      "{6: 0.65, 2: 0.325, 7: 0.025}\n",
      "Phase: 6\n",
      "dab\n",
      "{7: 0.5375, 5: 0.2125, 4: 0.1375, 6: 0.1125}\n",
      "{6: 0.5625, 5: 0.3, 7: 0.1, 2: 0.025, 4: 0.0125}\n",
      "{2: 0.275, 7: 0.275, 6: 0.2375, 5: 0.15, 4: 0.0625}\n",
      "{7: 0.325, 2: 0.2875, 6: 0.275, 5: 0.1125}\n",
      "elbowkick\n",
      "{7: 0.5, 3: 0.2125, 4: 0.1, 5: 0.0875, 6: 0.075, 2: 0.025}\n",
      "{6: 0.35, 2: 0.3375, 7: 0.2125, 5: 0.1}\n",
      "{2: 0.5, 7: 0.3125, 6: 0.175, 4: 0.0125}\n",
      "{2: 0.45, 7: 0.3375, 6: 0.2, 4: 0.0125}\n",
      "gun\n",
      "{7: 0.4125, 3: 0.2, 4: 0.175, 6: 0.125, 2: 0.05, 5: 0.0375}\n",
      "{2: 0.3, 6: 0.2875, 7: 0.25, 5: 0.1625}\n",
      "{7: 0.4375, 2: 0.3125, 5: 0.15, 6: 0.1}\n",
      "{7: 0.3125, 5: 0.275, 6: 0.2125, 2: 0.2}\n",
      "hair\n",
      "{7: 0.3125, 5: 0.1875, 4: 0.175, 3: 0.1375, 6: 0.125, 2: 0.0625}\n",
      "{6: 0.3375, 2: 0.2125, 5: 0.2125, 7: 0.2, 4: 0.0375}\n",
      "{2: 0.35, 5: 0.325, 6: 0.2625, 7: 0.0625}\n",
      "{6: 0.3875, 5: 0.3, 2: 0.2375, 7: 0.075}\n",
      "listen\n",
      "{7: 0.8375, 4: 0.125, 5: 0.0125, 2: 0.0125, 6: 0.0125}\n",
      "{6: 0.3375, 5: 0.275, 7: 0.25, 2: 0.1375}\n",
      "{2: 0.3625, 6: 0.325, 5: 0.1625, 4: 0.15}\n",
      "{2: 0.3375, 7: 0.2625, 5: 0.225, 6: 0.175}\n",
      "pointhigh\n",
      "{4: 0.525, 7: 0.35, 5: 0.1125, 2: 0.0125}\n",
      "{6: 0.55, 5: 0.2125, 2: 0.1625, 7: 0.075}\n",
      "{2: 0.3625, 5: 0.35, 6: 0.2, 7: 0.075, 4: 0.0125}\n",
      "{6: 0.4875, 5: 0.4, 2: 0.075, 7: 0.0375}\n",
      "sidepump\n",
      "{4: 0.6375, 7: 0.25, 5: 0.05, 3: 0.05, 2: 0.0125}\n",
      "{2: 0.5375, 6: 0.225, 7: 0.1375, 5: 0.1}\n",
      "{2: 0.7875, 6: 0.175, 7: 0.025, 4: 0.0125}\n",
      "{7: 0.4375, 6: 0.3, 2: 0.25, 4: 0.0125}\n",
      "wipetable\n",
      "{7: 0.6, 3: 0.3, 5: 0.1}\n",
      "{6: 0.4, 2: 0.3, 7: 0.3}\n",
      "{6: 0.5375, 2: 0.2875, 7: 0.175}\n",
      "{6: 0.6875, 2: 0.3, 7: 0.0125}\n",
      "Phase: 7\n",
      "dab\n",
      "{7: 0.4875, 4: 0.225, 5: 0.1625, 6: 0.125}\n",
      "{6: 0.5875, 5: 0.3, 7: 0.0875, 2: 0.025}\n",
      "{7: 0.2875, 5: 0.275, 6: 0.225, 2: 0.1625, 4: 0.05}\n",
      "{6: 0.3375, 7: 0.2875, 5: 0.2125, 2: 0.1625}\n",
      "elbowkick\n",
      "{7: 0.3625, 3: 0.3375, 4: 0.1375, 6: 0.075, 5: 0.075, 2: 0.0125}\n",
      "{2: 0.3625, 7: 0.325, 6: 0.275, 5: 0.0375}\n",
      "{2: 0.5375, 7: 0.3625, 6: 0.1}\n",
      "{2: 0.45, 7: 0.3625, 6: 0.1875}\n",
      "gun\n",
      "{7: 0.6125, 3: 0.1125, 4: 0.1125, 6: 0.0625, 5: 0.05, 2: 0.05}\n",
      "{2: 0.3125, 6: 0.2875, 7: 0.2375, 5: 0.1625}\n",
      "{7: 0.4875, 2: 0.275, 6: 0.125, 5: 0.1125}\n",
      "{7: 0.2875, 5: 0.275, 6: 0.25, 2: 0.1875}\n",
      "hair\n",
      "{4: 0.3125, 7: 0.3125, 5: 0.1625, 3: 0.15, 2: 0.0375, 6: 0.025}\n",
      "{6: 0.4625, 2: 0.2625, 7: 0.2125, 5: 0.05, 4: 0.0125}\n",
      "{5: 0.375, 6: 0.3125, 2: 0.225, 7: 0.0875}\n",
      "{2: 0.325, 6: 0.3125, 5: 0.2875, 7: 0.075}\n",
      "listen\n",
      "{7: 0.825, 6: 0.0875, 4: 0.075, 5: 0.0125}\n",
      "{5: 0.2875, 6: 0.275, 7: 0.2625, 2: 0.175}\n",
      "{6: 0.4125, 2: 0.2625, 4: 0.2125, 5: 0.1125}\n",
      "{2: 0.325, 7: 0.3, 5: 0.2, 6: 0.175}\n",
      "pointhigh\n",
      "{7: 0.4375, 4: 0.325, 5: 0.175, 3: 0.0625}\n",
      "{6: 0.5875, 5: 0.2375, 7: 0.0875, 2: 0.0875}\n",
      "{2: 0.4625, 6: 0.2125, 5: 0.2, 7: 0.125}\n",
      "{5: 0.5, 6: 0.4125, 7: 0.075, 2: 0.0125}\n",
      "sidepump\n",
      "{4: 0.5875, 7: 0.275, 3: 0.0625, 5: 0.05, 2: 0.025}\n",
      "{2: 0.325, 6: 0.3125, 7: 0.275, 5: 0.0625, 4: 0.025}\n",
      "{2: 0.6875, 6: 0.2625, 4: 0.025, 7: 0.025}\n",
      "{6: 0.4, 2: 0.3125, 7: 0.2625, 4: 0.0125, 5: 0.0125}\n",
      "wipetable\n",
      "{7: 0.6875, 3: 0.3, 5: 0.0125}\n",
      "{6: 0.4125, 7: 0.35, 2: 0.2375}\n",
      "{6: 0.4, 2: 0.3875, 7: 0.2125}\n",
      "{6: 0.775, 2: 0.225}\n",
      "Phase: 8\n",
      "dab\n",
      "{7: 0.6, 4: 0.175, 5: 0.125, 6: 0.1}\n",
      "{6: 0.5375, 5: 0.3375, 7: 0.075, 2: 0.05}\n",
      "{7: 0.4, 2: 0.2625, 5: 0.1875, 6: 0.125, 4: 0.025}\n",
      "{6: 0.375, 7: 0.275, 5: 0.2125, 2: 0.1375}\n",
      "elbowkick\n",
      "{7: 0.3375, 3: 0.3, 4: 0.125, 2: 0.0875, 6: 0.075, 5: 0.075}\n",
      "{2: 0.4875, 6: 0.2125, 7: 0.2125, 5: 0.0875}\n",
      "{7: 0.5, 2: 0.3125, 6: 0.1875}\n",
      "{7: 0.4, 2: 0.4, 6: 0.2}\n",
      "gun\n",
      "{7: 0.6375, 3: 0.125, 4: 0.1125, 5: 0.0875, 6: 0.025, 2: 0.0125}\n",
      "{6: 0.3125, 2: 0.2625, 7: 0.2625, 5: 0.1625}\n",
      "{7: 0.4875, 2: 0.35, 5: 0.1, 6: 0.0625}\n",
      "{7: 0.4875, 5: 0.2625, 2: 0.175, 6: 0.075}\n",
      "hair\n",
      "{7: 0.45, 4: 0.2, 5: 0.1625, 3: 0.1, 6: 0.05, 2: 0.0375}\n",
      "{6: 0.3625, 2: 0.3125, 5: 0.1875, 7: 0.1375}\n",
      "{5: 0.4125, 6: 0.3625, 2: 0.2, 7: 0.025}\n",
      "{5: 0.5, 6: 0.2625, 2: 0.1875, 7: 0.05}\n",
      "listen\n",
      "{7: 0.6875, 4: 0.125, 6: 0.1, 5: 0.0625, 3: 0.0125, 2: 0.0125}\n",
      "{6: 0.4125, 7: 0.2625, 5: 0.1875, 2: 0.1375}\n",
      "{6: 0.3875, 4: 0.275, 2: 0.2375, 5: 0.0875, 3: 0.0125}\n",
      "{2: 0.375, 7: 0.2375, 5: 0.2125, 6: 0.175}\n",
      "pointhigh\n",
      "{7: 0.425, 4: 0.325, 5: 0.175, 6: 0.05, 3: 0.025}\n",
      "{6: 0.4875, 5: 0.325, 2: 0.1375, 7: 0.05}\n",
      "{2: 0.45, 6: 0.2375, 7: 0.1625, 5: 0.15}\n",
      "{6: 0.475, 5: 0.3875, 7: 0.0875, 2: 0.05}\n",
      "sidepump\n",
      "{4: 0.4, 7: 0.275, 5: 0.1375, 3: 0.125, 2: 0.0625}\n",
      "{2: 0.3625, 7: 0.3125, 6: 0.2875, 5: 0.0375}\n",
      "{2: 0.675, 6: 0.275, 5: 0.05}\n",
      "{7: 0.475, 6: 0.2375, 2: 0.2, 5: 0.075, 4: 0.0125}\n",
      "wipetable\n",
      "{7: 0.6625, 3: 0.2625, 5: 0.075}\n",
      "{6: 0.475, 7: 0.275, 2: 0.25}\n",
      "{6: 0.475, 2: 0.4, 7: 0.125}\n",
      "{6: 0.6625, 2: 0.3125, 7: 0.025}\n",
      "Phase: 9\n",
      "dab\n",
      "{7: 0.575, 5: 0.2, 4: 0.1125, 6: 0.1, 2: 0.0125}\n",
      "{6: 0.525, 5: 0.375, 7: 0.0625, 2: 0.0375}\n",
      "{6: 0.35, 5: 0.275, 2: 0.225, 7: 0.1375, 4: 0.0125}\n",
      "{2: 0.3875, 6: 0.2875, 7: 0.2375, 5: 0.0875}\n",
      "elbowkick\n",
      "{3: 0.3875, 7: 0.3375, 4: 0.15, 2: 0.05, 5: 0.0375, 6: 0.0375}\n",
      "{2: 0.375, 7: 0.375, 6: 0.225, 5: 0.025}\n",
      "{7: 0.45, 2: 0.3875, 6: 0.1625}\n",
      "{2: 0.45, 7: 0.4, 6: 0.15}\n",
      "gun\n",
      "{7: 0.4625, 4: 0.1625, 3: 0.1375, 6: 0.1375, 2: 0.05, 5: 0.05}\n",
      "{6: 0.2625, 7: 0.2625, 2: 0.25, 5: 0.225}\n",
      "{7: 0.475, 2: 0.3375, 6: 0.1, 5: 0.0875}\n",
      "{7: 0.6625, 6: 0.2125, 2: 0.125}\n",
      "hair\n",
      "{7: 0.3125, 4: 0.25, 3: 0.1875, 5: 0.15, 6: 0.0625, 2: 0.0375}\n",
      "{6: 0.4625, 7: 0.3, 2: 0.1625, 5: 0.0625, 4: 0.0125}\n",
      "{6: 0.4125, 5: 0.275, 2: 0.225, 7: 0.0875}\n",
      "{5: 0.35, 6: 0.35, 2: 0.3}\n",
      "listen\n",
      "{7: 0.6625, 6: 0.1375, 4: 0.125, 5: 0.05, 2: 0.025}\n",
      "{5: 0.3375, 6: 0.325, 7: 0.175, 2: 0.1625}\n",
      "{6: 0.3625, 4: 0.275, 2: 0.225, 5: 0.0875, 3: 0.05}\n",
      "{2: 0.3125, 7: 0.3, 5: 0.25, 6: 0.1375}\n",
      "pointhigh\n",
      "{7: 0.3875, 4: 0.3375, 5: 0.1625, 3: 0.075, 6: 0.025, 2: 0.0125}\n",
      "{6: 0.6625, 5: 0.1625, 2: 0.1, 7: 0.075}\n",
      "{2: 0.4125, 6: 0.2625, 5: 0.25, 7: 0.075}\n",
      "{5: 0.55, 6: 0.3375, 7: 0.0625, 2: 0.0375, 4: 0.0125}\n",
      "sidepump\n",
      "{4: 0.4125, 7: 0.375, 5: 0.0875, 3: 0.075, 2: 0.05}\n",
      "{2: 0.5125, 6: 0.3, 7: 0.1625, 5: 0.025}\n",
      "{2: 0.6, 6: 0.3125, 4: 0.05, 5: 0.025, 7: 0.0125}\n",
      "{2: 0.5875, 7: 0.2875, 6: 0.125}\n",
      "wipetable\n",
      "{7: 0.5, 3: 0.375, 5: 0.1, 2: 0.025}\n",
      "{6: 0.4375, 7: 0.3625, 2: 0.2}\n",
      "{6: 0.55, 2: 0.35, 7: 0.1}\n",
      "{6: 0.6875, 2: 0.3125}\n",
      "Phase: 10\n",
      "dab\n",
      "{7: 0.525, 5: 0.2, 4: 0.2, 6: 0.075}\n",
      "{6: 0.575, 5: 0.2125, 7: 0.125, 2: 0.0875}\n",
      "{5: 0.325, 7: 0.325, 6: 0.2125, 2: 0.125, 4: 0.0125}\n",
      "{2: 0.375, 6: 0.325, 7: 0.2625, 5: 0.0375}\n",
      "elbowkick\n",
      "{7: 0.4, 3: 0.35, 4: 0.1625, 5: 0.0625, 6: 0.025}\n",
      "{2: 0.5625, 6: 0.2125, 7: 0.15, 5: 0.075}\n",
      "{2: 0.45, 7: 0.425, 6: 0.125}\n",
      "{7: 0.5, 2: 0.3, 6: 0.1625, 5: 0.0375}\n",
      "gun\n",
      "{7: 0.3375, 3: 0.25, 4: 0.2125, 5: 0.0875, 6: 0.075, 2: 0.0375}\n",
      "{2: 0.3375, 6: 0.2625, 7: 0.2375, 5: 0.1625}\n",
      "{2: 0.4125, 7: 0.375, 5: 0.1125, 6: 0.1}\n",
      "{7: 0.45, 5: 0.25, 2: 0.1875, 6: 0.1125}\n",
      "hair\n",
      "{4: 0.3, 5: 0.2, 7: 0.1875, 3: 0.175, 6: 0.1, 2: 0.0375}\n",
      "{6: 0.4125, 7: 0.25, 2: 0.2, 5: 0.1375}\n",
      "{5: 0.4375, 2: 0.375, 6: 0.15, 7: 0.0375}\n",
      "{6: 0.375, 5: 0.35, 2: 0.175, 7: 0.1}\n",
      "listen\n",
      "{7: 0.6875, 4: 0.1, 5: 0.075, 6: 0.075, 3: 0.05, 2: 0.0125}\n",
      "{6: 0.4, 7: 0.3125, 5: 0.175, 2: 0.1125}\n",
      "{2: 0.3625, 6: 0.3, 4: 0.2125, 5: 0.0875, 3: 0.0375}\n",
      "{2: 0.35, 7: 0.25, 5: 0.225, 6: 0.175}\n",
      "pointhigh\n",
      "{4: 0.5125, 7: 0.325, 5: 0.0875, 3: 0.075}\n",
      "{6: 0.475, 5: 0.3125, 2: 0.1625, 7: 0.05}\n",
      "{2: 0.4, 5: 0.275, 6: 0.175, 7: 0.15}\n",
      "{6: 0.55, 5: 0.3875, 2: 0.0625}\n",
      "sidepump\n",
      "{4: 0.5125, 7: 0.2625, 5: 0.1125, 2: 0.0625, 3: 0.05}\n",
      "{2: 0.475, 6: 0.3625, 7: 0.1625}\n",
      "{2: 0.85, 6: 0.125, 4: 0.025}\n",
      "{6: 0.4125, 2: 0.2875, 7: 0.225, 5: 0.05, 4: 0.025}\n",
      "wipetable\n",
      "{7: 0.6125, 3: 0.3125, 5: 0.05, 2: 0.025}\n",
      "{6: 0.4375, 7: 0.3375, 2: 0.225}\n",
      "{6: 0.525, 2: 0.3625, 7: 0.1125}\n",
      "{6: 0.625, 2: 0.3375, 7: 0.0375}\n",
      "Phase: 11\n",
      "dab\n",
      "{7: 0.5, 4: 0.1875, 5: 0.175, 6: 0.1125, 3: 0.025}\n",
      "{5: 0.3875, 6: 0.325, 7: 0.2125, 2: 0.0625, 4: 0.0125}\n",
      "{2: 0.3, 7: 0.2875, 6: 0.2, 5: 0.1375, 4: 0.075}\n",
      "{7: 0.3625, 2: 0.3125, 6: 0.175, 5: 0.15}\n",
      "elbowkick\n",
      "{7: 0.4125, 3: 0.3, 4: 0.125, 6: 0.075, 5: 0.0625, 2: 0.025}\n",
      "{7: 0.3625, 2: 0.2875, 6: 0.275, 5: 0.075}\n",
      "{7: 0.4125, 2: 0.3625, 6: 0.225}\n",
      "{7: 0.425, 2: 0.375, 6: 0.125, 5: 0.0625, 4: 0.0125}\n",
      "gun\n",
      "{7: 0.5, 3: 0.2125, 4: 0.15, 5: 0.05, 2: 0.05, 6: 0.0375}\n",
      "{7: 0.325, 6: 0.2875, 5: 0.2125, 2: 0.175}\n",
      "{7: 0.35, 2: 0.3375, 5: 0.225, 6: 0.0875}\n",
      "{2: 0.375, 5: 0.35, 7: 0.2375, 6: 0.0375}\n",
      "hair\n",
      "{7: 0.35, 4: 0.2, 5: 0.175, 3: 0.175, 2: 0.075, 6: 0.025}\n",
      "{6: 0.425, 2: 0.2125, 7: 0.175, 5: 0.1625, 4: 0.025}\n",
      "{5: 0.3625, 2: 0.3125, 6: 0.2625, 7: 0.0625}\n",
      "{6: 0.425, 2: 0.275, 5: 0.225, 7: 0.075}\n",
      "listen\n",
      "{7: 0.65, 4: 0.2125, 5: 0.0625, 3: 0.0375, 6: 0.025, 2: 0.0125}\n",
      "{6: 0.3125, 7: 0.3125, 5: 0.2625, 2: 0.1125}\n",
      "{6: 0.4375, 2: 0.2375, 5: 0.175, 4: 0.15}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{7: 0.3875, 2: 0.3125, 5: 0.1625, 6: 0.1375}\n",
      "pointhigh\n",
      "{4: 0.425, 7: 0.2875, 5: 0.175, 3: 0.075, 6: 0.0375}\n",
      "{6: 0.6125, 5: 0.2, 2: 0.1125, 7: 0.075}\n",
      "{2: 0.4, 6: 0.2375, 5: 0.2375, 7: 0.125}\n",
      "{5: 0.55, 6: 0.3625, 7: 0.0875}\n",
      "sidepump\n",
      "{4: 0.5625, 7: 0.3125, 5: 0.05, 2: 0.0375, 3: 0.0375}\n",
      "{2: 0.5875, 6: 0.2, 7: 0.175, 4: 0.0375}\n",
      "{2: 0.675, 6: 0.2625, 7: 0.0375, 5: 0.025}\n",
      "{2: 0.3, 7: 0.2625, 6: 0.2625, 5: 0.1625, 4: 0.0125}\n",
      "wipetable\n",
      "{7: 0.7125, 3: 0.25, 5: 0.0375}\n",
      "{6: 0.425, 7: 0.3, 2: 0.275}\n",
      "{6: 0.5, 2: 0.325, 7: 0.175}\n",
      "{6: 0.65, 2: 0.35}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "dances = ['dab', 'elbowkick', 'gun', 'hair', 'listen', 'pointhigh', 'sidepump', 'wipetable']\n",
    "# dances = ['gun', 'hair', 'sidepump']\n",
    "# dances = ['elbowkick', 'pointhigh', 'wipetable']\n",
    "persons = ['kelvin', 'guiyong', 'xiaoxue', 'john']\n",
    "beetles = ['1', '2']\n",
    "\n",
    "test_range = 12\n",
    "leap = 80\n",
    "truth, total, skipped = 0,0,0\n",
    "for i in range(0,0+test_range):\n",
    "    print(\"Phase:\", i)\n",
    "    start, end = i * leap, i * leap + leap\n",
    "    for d in dances:\n",
    "        print(d)\n",
    "        df_full = pd.DataFrame()\n",
    "        collection = [np.array([]) for x in range(16)]\n",
    "        j = 0\n",
    "        for p in persons:\n",
    "            for b in beetles:\n",
    "                if b == '1':\n",
    "                    continue\n",
    "                move_json = 'collected_data/' + d + b + '_' + p + '.json'\n",
    "                with open(move_json) as f:\n",
    "                    x = json.load(f)\n",
    "                x = pd.DataFrame.from_dict(x)[start:end]\n",
    "                df_target = torch.from_numpy(np.array(x))\n",
    "                df_target = df_target\n",
    "                output = clf.predict(df_target)\n",
    "                proba_dict = {}\n",
    "\n",
    "                for x in output:\n",
    "                    x = int(x)\n",
    "                    if x not in proba_dict:\n",
    "                        proba_dict[x] = 1\n",
    "                    else:\n",
    "                        proba_dict[x] += 1\n",
    "                for k in proba_dict.keys():\n",
    "                    proba_dict[k] /= len(output)\n",
    "\n",
    "                print(dict(sorted(proba_dict.items(), key=lambda item: -item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
