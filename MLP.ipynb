{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dab1_guiyong.json', 'dab1_john.json', 'dab1_kelvin.json', 'dab1_xiaoxue.json', 'dab2_guiyong.json', 'dab2_john.json', 'dab2_kelvin.json', 'dab2_xiaoxue.json', 'dab2_yujie.json', 'elbowkick1_guiyong.json', 'elbowkick1_john.json', 'elbowkick1_kelvin.json', 'elbowkick1_xiaoxue.json', 'elbowkick2_guiyong.json', 'elbowkick2_john.json', 'elbowkick2_kelvin.json', 'elbowkick2_xiaoxue.json', 'elbowkick2_yujie.json', 'gun1_guiyong.json', 'gun2_kelvin.json', 'gun2_xiaoxue.json', 'gun2_yujie.json', 'hair1_guiyong.json', 'hair2_guiyong.json', 'hair2_john.json', 'hair2_kelvin.json', 'hair2_xiaoxue.json', 'hair2_yujie.json', 'listen1_guiyong.json', 'listen1_john.json', 'listen1_kelvin.json', 'listen1_xiaoxue.json', 'listen2_guiyong.json', 'listen2_john.json', 'listen2_kelvin.json', 'listen2_xiaoxue.json', 'listen2_yujie.json', 'pointhigh1_guiyong.json', 'pointhigh1_john.json', 'pointhigh1_kelvin.json', 'pointhigh1_xiaoxue.json', 'pointhigh2_guiyong.json', 'pointhigh2_john.json', 'pointhigh2_kelvin.json', 'pointhigh2_xiaoxue.json', 'pointhigh2_yujie.json', 'sidepump1_guiyong.json', 'sidepump1_john.json', 'sidepump2_yujie.json', 'wipetable1_guiyong.json', 'wipetable1_john.json', 'wipetable1_kelvin.json', 'wipetable1_xiaoxue.json', 'wipetable2_guiyong.json', 'wipetable2_john.json', 'wipetable2_kelvin.json', 'wipetable2_xiaoxue.json', 'wipetable2_yujie.json']\n",
      "{0: 'dab1_guiyong', 1: 'dab1_john', 2: 'dab1_kelvin', 3: 'dab1_xiaoxue', 4: 'dab2_guiyong', 5: 'dab2_john', 6: 'dab2_kelvin', 7: 'dab2_xiaoxue', 8: 'dab2_yujie', 9: 'elbowkick1_guiyong', 10: 'elbowkick1_john', 11: 'elbowkick1_kelvin', 12: 'elbowkick1_xiaoxue', 13: 'elbowkick2_guiyong', 14: 'elbowkick2_john', 15: 'elbowkick2_kelvin', 16: 'elbowkick2_xiaoxue', 17: 'elbowkick2_yujie', 18: 'gun1_guiyong', 19: 'gun2_kelvin', 20: 'gun2_xiaoxue', 21: 'gun2_yujie', 22: 'hair1_guiyong', 23: 'hair2_guiyong', 24: 'hair2_john', 25: 'hair2_kelvin', 26: 'hair2_xiaoxue', 27: 'hair2_yujie', 28: 'listen1_guiyong', 29: 'listen1_john', 30: 'listen1_kelvin', 31: 'listen1_xiaoxue', 32: 'listen2_guiyong', 33: 'listen2_john', 34: 'listen2_kelvin', 35: 'listen2_xiaoxue', 36: 'listen2_yujie', 37: 'pointhigh1_guiyong', 38: 'pointhigh1_john', 39: 'pointhigh1_kelvin', 40: 'pointhigh1_xiaoxue', 41: 'pointhigh2_guiyong', 42: 'pointhigh2_john', 43: 'pointhigh2_kelvin', 44: 'pointhigh2_xiaoxue', 45: 'pointhigh2_yujie', 46: 'sidepump1_guiyong', 47: 'sidepump1_john', 48: 'sidepump2_yujie', 49: 'wipetable1_guiyong', 50: 'wipetable1_john', 51: 'wipetable1_kelvin', 52: 'wipetable1_xiaoxue', 53: 'wipetable2_guiyong', 54: 'wipetable2_john', 55: 'wipetable2_kelvin', 56: 'wipetable2_xiaoxue', 57: 'wipetable2_yujie'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, TimeSeriesSplit, cross_val_score\n",
    "\n",
    "import brevitas.nn as nn\n",
    "\n",
    "from config import *\n",
    "from classic_models import *\n",
    "from data_preprocessing import *\n",
    "from feature_extraction import *\n",
    "from helpers import *\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tslearn.preprocessing import TimeSeriesScalerMinMax\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_accel1</th>\n",
       "      <th>mean_accel2</th>\n",
       "      <th>mean_accel3</th>\n",
       "      <th>mean_gyro1</th>\n",
       "      <th>mean_gyro2</th>\n",
       "      <th>mean_gyro3</th>\n",
       "      <th>max_accel1</th>\n",
       "      <th>max_accel2</th>\n",
       "      <th>max_accel3</th>\n",
       "      <th>max_gyro1</th>\n",
       "      <th>...</th>\n",
       "      <th>var_coeff_gyro1</th>\n",
       "      <th>var_coeff_gyro2</th>\n",
       "      <th>var_coeff_gyro3</th>\n",
       "      <th>kurtosis_accel1</th>\n",
       "      <th>kurtosis_accel2</th>\n",
       "      <th>kurtosis_accel3</th>\n",
       "      <th>kurtosis_gyro1</th>\n",
       "      <th>kurtosis_gyro2</th>\n",
       "      <th>kurtosis_gyro3</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.406297</td>\n",
       "      <td>0.594615</td>\n",
       "      <td>0.115632</td>\n",
       "      <td>0.451036</td>\n",
       "      <td>-0.002366</td>\n",
       "      <td>0.133253</td>\n",
       "      <td>0.243177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463385</td>\n",
       "      <td>-0.000575</td>\n",
       "      <td>0.186508</td>\n",
       "      <td>0.334034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.383757</td>\n",
       "      <td>-1.486205</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.392612</td>\n",
       "      <td>0.594615</td>\n",
       "      <td>0.115632</td>\n",
       "      <td>0.398074</td>\n",
       "      <td>-0.002944</td>\n",
       "      <td>0.140580</td>\n",
       "      <td>0.253709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498800</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>0.183374</td>\n",
       "      <td>0.324730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.372215</td>\n",
       "      <td>-1.434352</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.385094</td>\n",
       "      <td>0.594615</td>\n",
       "      <td>0.115632</td>\n",
       "      <td>0.372615</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.140671</td>\n",
       "      <td>0.253282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536615</td>\n",
       "      <td>0.004052</td>\n",
       "      <td>0.176289</td>\n",
       "      <td>0.324730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.344688</td>\n",
       "      <td>-1.458927</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.393722</td>\n",
       "      <td>0.602552</td>\n",
       "      <td>0.115632</td>\n",
       "      <td>0.403721</td>\n",
       "      <td>0.002407</td>\n",
       "      <td>0.145101</td>\n",
       "      <td>0.261783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563625</td>\n",
       "      <td>0.002841</td>\n",
       "      <td>0.173437</td>\n",
       "      <td>0.333733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.327319</td>\n",
       "      <td>-1.417270</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.406477</td>\n",
       "      <td>0.602552</td>\n",
       "      <td>0.115632</td>\n",
       "      <td>0.460362</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>0.146091</td>\n",
       "      <td>0.259371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570828</td>\n",
       "      <td>-0.000995</td>\n",
       "      <td>0.172075</td>\n",
       "      <td>0.330132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.322097</td>\n",
       "      <td>-1.360785</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_accel1  mean_accel2  mean_accel3  mean_gyro1  mean_gyro2  mean_gyro3  \\\n",
       "0     0.406297     0.594615     0.115632    0.451036   -0.002366    0.133253   \n",
       "1     0.392612     0.594615     0.115632    0.398074   -0.002944    0.140580   \n",
       "2     0.385094     0.594615     0.115632    0.372615    0.000251    0.140671   \n",
       "3     0.393722     0.602552     0.115632    0.403721    0.002407    0.145101   \n",
       "4     0.406477     0.602552     0.115632    0.460362    0.002489    0.146091   \n",
       "\n",
       "   max_accel1  max_accel2  max_accel3  max_gyro1  ...  var_coeff_gyro1  \\\n",
       "0    0.243177         0.0         5.0        0.0  ...         0.463385   \n",
       "1    0.253709         0.0         4.0        0.0  ...         0.498800   \n",
       "2    0.253282         0.0         4.0        0.0  ...         0.536615   \n",
       "3    0.261783         0.0         4.0        0.0  ...         0.563625   \n",
       "4    0.259371         0.0         5.0        0.0  ...         0.570828   \n",
       "\n",
       "   var_coeff_gyro2  var_coeff_gyro3  kurtosis_accel1  kurtosis_accel2  \\\n",
       "0        -0.000575         0.186508         0.334034              0.0   \n",
       "1         0.002896         0.183374         0.324730              0.0   \n",
       "2         0.004052         0.176289         0.324730              0.0   \n",
       "3         0.002841         0.173437         0.333733              0.0   \n",
       "4        -0.000995         0.172075         0.330132              0.0   \n",
       "\n",
       "   kurtosis_accel3  kurtosis_gyro1  kurtosis_gyro2  kurtosis_gyro3  tag  \n",
       "0              2.0        0.216667        0.383757       -1.486205  0.0  \n",
       "1              2.0        0.216667        0.372215       -1.434352  0.0  \n",
       "2              2.0        0.216667        0.344688       -1.458927  0.0  \n",
       "3              2.0        0.166667        0.327319       -1.417270  0.0  \n",
       "4              3.0        0.166667        0.322097       -1.360785  0.0  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "df_train = pd.read_csv('out_15_train.csv')\n",
    "# df_train = df_train.iloc[:, list(range(21)) + [-1]]\n",
    "df_test = pd.read_csv('out_15_test.csv')\n",
    "# df_test = df_test.iloc[:, list(range(21)) + [-1]]\n",
    "df_train['tag'] = df_train['tag'].apply(lambda x: x-1)\n",
    "df_test['tag'] = df_test['tag'].apply(lambda x: x-1)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "# mean gyro 2, max accel 3, max gyro 2, min gyro 2, median gyro 2, std accel 3, zero crossing accel 3, \n",
    "# recurring dp gyro 2, kurtosis gyro 2\n",
    "plt.figure(figsize=(12,10))\n",
    "cor = df_train[['mean_gyro2', 'max_accel3', 'max_gyro2', 'min_gyro2', \\\n",
    "                'median_gyro2', 'std_accel3', 'zero_crossing_accel3']].corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()\n",
    "df_tag = df_train['tag']\n",
    "df_train = df_train[['mean_gyro2', 'max_accel3', 'max_gyro2', 'min_gyro2', \\\n",
    "                'median_gyro2', 'std_accel3', 'zero_crossing_accel3']]\n",
    "df_train['tag'] = df_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 18\n"
     ]
    }
   ],
   "source": [
    "print(window_size, overlap)\n",
    "window_size = 160\n",
    "overlap = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            df_np = df.to_numpy()\n",
    "        self.X = df_np[:,:-1]\n",
    "        self.y = df_np[:,-1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get item by index\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        # returns length of data\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 8\n"
     ]
    }
   ],
   "source": [
    "dataset = FeatureDataset(df_train)\n",
    "D_in = 72 # df.shape[1]-1\n",
    "D_out = 8 # len(dances)\n",
    "print(D_in, D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_hidden, d_out):\n",
    "        super(MLP, self).__init__()\n",
    "        self.d_in = d_in\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(d_in, d_hidden, bias=True)\n",
    "        self.linear2 = torch.nn.Linear(d_hidden, d_hidden//2, bias=True)\n",
    "        self.linear3 = torch.nn.Linear(d_hidden//2, d_hidden//4, bias=True)\n",
    "        self.linear4 = torch.nn.Linear(d_hidden//4, d_hidden//8, bias=True)\n",
    "        self.linear5 = torch.nn.Linear(d_hidden//8, d_out, bias=False)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = X.view(-1, self.d_in)\n",
    "        X = self.relu(self.linear1(X.float()))\n",
    "        X = self.relu(self.linear2(X))\n",
    "        X = self.relu(self.linear3(X))\n",
    "        X = self.relu(self.linear4(X))\n",
    "        X = self.relu(self.linear5(X))\n",
    "        return torch.nn.functional.log_softmax(X, dim=1)\n",
    "    \n",
    "    def load(self, model_path):\n",
    "        self.load_state_dict(torch.load(model_path))\n",
    "        self.eval()\n",
    "\n",
    "    def predict(self, X):\n",
    "        outputs = self(X.float())\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [-1, 70]           5,110\n",
      "              ReLU-2                   [-1, 70]               0\n",
      "            Linear-3                   [-1, 35]           2,485\n",
      "              ReLU-4                   [-1, 35]               0\n",
      "            Linear-5                   [-1, 17]             612\n",
      "              ReLU-6                   [-1, 17]               0\n",
      "            Linear-7                    [-1, 8]             144\n",
      "              ReLU-8                    [-1, 8]               0\n",
      "            Linear-9                    [-1, 8]              64\n",
      "             ReLU-10                    [-1, 8]               0\n",
      "================================================================\n",
      "Total params: 8,415\n",
      "Trainable params: 8,415\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 0.04\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "model = MLP(D_in, 70, D_out)\n",
    "summary(model, (5, 72))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_model(model, criterion, optimizer, X, y, num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # Store losses and accuracies accross epochs\n",
    "    losses, accuracies = dict(train=[], val=[]), dict(train=[], val=[])\n",
    "\n",
    "    # tscv = TimeSeriesSplit(n_splits=15, max_train_size=3000)\n",
    "    kf = KFold(n_splits=9)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    confusion_matrix = torch.zeros(8, 8)\n",
    "\n",
    "    for i in range(1,num_epochs+1):\n",
    "        print('Epoch {}/{}'.format(i, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "        \n",
    "        # for fold, (train_index, test_index) in enumerate(tscv.split(X_train, y_train)):\n",
    "        for fold, (train_index, test_index) in enumerate(kf.split(X_train)):\n",
    "#             if len(train_index) > 500:\n",
    "#                 train_index = train_index[len(train_index)-500:]\n",
    "            ### Dividing data into folds\n",
    "            # print(train_index, test_index, len(X_train))\n",
    "            x_train_fold = X_train[train_index]\n",
    "            x_test_fold = X_train[test_index]\n",
    "            y_train_fold = y_train[train_index]\n",
    "            y_test_fold = y_train[test_index]\n",
    "\n",
    "            print('Train Index Length:', len(train_index), end='\\t\\t')\n",
    "            print('Test Index Length:', len(test_index), end='\\n\\n')\n",
    "\n",
    "            train = torch.utils.data.TensorDataset(torch.tensor(x_train_fold), torch.tensor(y_train_fold))\n",
    "            test = torch.utils.data.TensorDataset(torch.tensor(x_test_fold), torch.tensor(y_test_fold))\n",
    "            train_loader = torch.utils.data.DataLoader(train, batch_size = 20, shuffle = False)\n",
    "            test_loader = torch.utils.data.DataLoader(test, batch_size = 20, shuffle = False)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            for batch_index, (x_batch, y_batch) in enumerate(train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                y_pred = model(x_batch)\n",
    "                _, preds = torch.max(y_pred, 1)\n",
    "                for t, p in zip(y_batch.view(-1), preds.view(-1)):\n",
    "                        confusion_matrix[t.long(), p.long()] += 1\n",
    "                # print(y_pred.shape, y_batch.view(-1, 1).shape)\n",
    "                single_loss = criterion(y_pred, y_batch.long())\n",
    "                single_loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += single_loss.item() * x_batch.size(0)\n",
    "                running_corrects += torch.sum(preds == y_batch.data)\n",
    "            print('Fold No. {}/{}\\tEpoch {}/{}\\t'.format(fold + 1 , kf.get_n_splits(X_train), i, num_epochs), end='')\n",
    "            print(f'loss: {single_loss.item():10.8f}')\n",
    "            \n",
    "            nsamples = len(train_index)\n",
    "            epoch_loss = running_loss / nsamples\n",
    "            epoch_acc = running_corrects.double() / nsamples\n",
    "\n",
    "            losses[phase].append(epoch_loss)\n",
    "            accuracies[phase].append(epoch_acc)\n",
    "            print('{} Loss: {:.4f} Acc: {:.2f}%'.format(\n",
    "                    phase, epoch_loss, 100 * epoch_acc)\n",
    "            )\n",
    "            print()\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.2f}%'.format(100 * best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    print(confusion_matrix.diag()/confusion_matrix.sum(1))\n",
    "    return model, losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([70, 72])\n",
      "torch.Size([70])\n",
      "torch.Size([35, 70])\n",
      "torch.Size([35])\n",
      "torch.Size([17, 35])\n",
      "torch.Size([17])\n",
      "torch.Size([8, 17])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 8])\n",
      "Total number of parameters = 8415\n"
     ]
    }
   ],
   "source": [
    "model = MLP(D_in, 70, D_out)\n",
    "# model = MultiHead4MLP(D_in, D_out)\n",
    "# Explore the model\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "\n",
    "print(\"Total number of parameters =\", np.sum([np.prod(parameter.shape) for parameter in model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "----------\n",
      "Train Index Length: 2937\t\tTest Index Length: 368\n",
      "\n",
      "Fold No. 1/9\tEpoch 1/1\tloss: 2.07944131\n",
      "val Loss: 2.0794 Acc: 8.61%\n",
      "\n",
      "Train Index Length: 2937\t\tTest Index Length: 368\n",
      "\n",
      "Fold No. 2/9\tEpoch 1/1\tloss: 2.07944131\n",
      "val Loss: 2.0794 Acc: 8.72%\n",
      "\n",
      "Train Index Length: 2938\t\tTest Index Length: 367\n",
      "\n",
      "Fold No. 3/9\tEpoch 1/1\tloss: 2.07944131\n",
      "val Loss: 2.0794 Acc: 8.61%\n",
      "\n",
      "Train Index Length: 2938\t\tTest Index Length: 367\n",
      "\n",
      "Fold No. 4/9\tEpoch 1/1\tloss: 2.07944131\n",
      "val Loss: 2.0794 Acc: 8.65%\n",
      "\n",
      "Train Index Length: 2938\t\tTest Index Length: 367\n",
      "\n",
      "Fold No. 5/9\tEpoch 1/1\tloss: 2.07944131\n",
      "val Loss: 2.0794 Acc: 8.41%\n",
      "\n",
      "Train Index Length: 2938\t\tTest Index Length: 367\n",
      "\n",
      "Fold No. 6/9\tEpoch 1/1\tloss: 2.07944131\n",
      "val Loss: 2.0794 Acc: 8.75%\n",
      "\n",
      "Train Index Length: 2938\t\tTest Index Length: 367\n",
      "\n",
      "Fold No. 7/9\tEpoch 1/1\tloss: 2.07944131\n",
      "val Loss: 2.0794 Acc: 8.17%\n",
      "\n",
      "Train Index Length: 2938\t\tTest Index Length: 367\n",
      "\n",
      "Fold No. 8/9\tEpoch 1/1\tloss: 2.07944131\n",
      "val Loss: 2.0794 Acc: 8.71%\n",
      "\n",
      "Train Index Length: 2938\t\tTest Index Length: 367\n",
      "\n",
      "Fold No. 9/9\tEpoch 1/1\tloss: 2.07944131\n",
      "val Loss: 2.0794 Acc: 8.71%\n",
      "\n",
      "Training complete in 0m 20s\n",
      "Best val Acc: 8.75%\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.4)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "model, losses, accuracies = train_val_model(model, criterion, optimizer, dataset.X, dataset.y, num_epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.plot(losses['train'], '-b', losses['val'], '--r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'MLP_Model_moves_{D_out}_windowsize{window_size}_overlap{overlap}_epoch{NUM_EPOCHS}'\n",
    "torch.save(model.state_dict(), name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MLP:\n\tsize mismatch for linear1.weight: copying a param with shape torch.Size([7, 7]) from checkpoint, the shape in current model is torch.Size([70, 7]).\n\tsize mismatch for linear1.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([70]).\n\tsize mismatch for linear2.weight: copying a param with shape torch.Size([8, 7]) from checkpoint, the shape in current model is torch.Size([8, 70]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-6b663fd4d333>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmlp_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmlp_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# Print model's state_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Model's state_dict:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mparam_tensor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmlp_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-106-1332bc29feec>\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, model_path)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m-> 1052\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m   1053\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MLP:\n\tsize mismatch for linear1.weight: copying a param with shape torch.Size([7, 7]) from checkpoint, the shape in current model is torch.Size([70, 7]).\n\tsize mismatch for linear1.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([70]).\n\tsize mismatch for linear2.weight: copying a param with shape torch.Size([8, 7]) from checkpoint, the shape in current model is torch.Size([8, 70])."
     ]
    }
   ],
   "source": [
    "mlp_model = MLP(D_in, 70, D_out)\n",
    "mlp_model.load(name)\n",
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in mlp_model.state_dict():\n",
    "    print(param_tensor, \"\\t\\t\", mlp_model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "\n",
    "with open('weights.txt', 'w') as outfile:\n",
    "    for var_name in optimizer.state_dict():\n",
    "        if var_name == 'state':\n",
    "            for i in range(len(mlp_model.state_dict())):\n",
    "                print(var_name, \"\\t\", optimizer.state_dict()[var_name][i]['momentum_buffer'].shape)\n",
    "                # print(var_name, \"\\t\", np.array(optimizer.state_dict()[var_name][i]['momentum_buffer']))\n",
    "                y = np.array(optimizer.state_dict()[var_name][i]['momentum_buffer'])\n",
    "                for x in y:\n",
    "                    x = str(x)\n",
    "                    x = x.replace('[','{').replace(']','}').replace(' ', ', ').replace('{,', '{').replace(', ,', ',').replace('\\n,', ',\\n')\n",
    "                    outfile.write(x)\n",
    "                # np.savetxt(outfile, np.array(optimizer.state_dict()[var_name][i]['momentum_buffer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MLP:\n\tsize mismatch for linear1.weight: copying a param with shape torch.Size([7, 7]) from checkpoint, the shape in current model is torch.Size([70, 7]).\n\tsize mismatch for linear1.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([70]).\n\tsize mismatch for linear2.weight: copying a param with shape torch.Size([8, 7]) from checkpoint, the shape in current model is torch.Size([8, 70]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-119-f5c2602d6379>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmlp_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmlp_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmlp_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mto_predict\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-106-1332bc29feec>\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, model_path)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m-> 1052\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m   1053\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MLP:\n\tsize mismatch for linear1.weight: copying a param with shape torch.Size([7, 7]) from checkpoint, the shape in current model is torch.Size([70, 7]).\n\tsize mismatch for linear1.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([70]).\n\tsize mismatch for linear2.weight: copying a param with shape torch.Size([8, 7]) from checkpoint, the shape in current model is torch.Size([8, 70])."
     ]
    }
   ],
   "source": [
    "mlp_model = MLP(D_in, 70, D_out)\n",
    "mlp_model.load(name)\n",
    "mlp_model.eval()\n",
    "\n",
    "for to_predict in range(D_out):\n",
    "    df_target = df_test[df_test['tag'] == to_predict]\n",
    "    df_target = torch.from_numpy(np.array(df_target)[:,:-1])\n",
    "\n",
    "#     df_random = df_test\n",
    "\n",
    "#     df_filtered = torch.from_numpy(np.array(pd.merge(df_target, df_random))[:,:-1])\n",
    "    output = mlp_model.predict(df_target)\n",
    "    proba_dict = {}\n",
    "\n",
    "    for x in output:\n",
    "        x = int(x)\n",
    "        if x not in proba_dict:\n",
    "            proba_dict[x] = 1\n",
    "        else:\n",
    "            proba_dict[x] += 1\n",
    "    for k in proba_dict.keys():\n",
    "        proba_dict[k] /= len(output)\n",
    "\n",
    "    print(dict(sorted(proba_dict.items(), key=lambda item: -item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(df, window_size):\n",
    "    full_features = np.array([])\n",
    "    axis = ['accel1', 'accel2', 'accel3', 'gyro1', 'gyro2', 'gyro3']\n",
    "    titles = np.ravel(np.array([i+'_'+j for i in feature_list for j in axis]))\n",
    "\n",
    "    # print(\"Begin Feature Extraction\")\n",
    "    windows = set_sliding_windows(df, 158, window_size)\n",
    "    # windows = set_windows(df, window_size)\n",
    "\n",
    "    for window in windows:\n",
    "        for _,ax in enumerate(window.T):\n",
    "                full_features = np.append(full_features, add_mean(ax))\n",
    "                full_features = np.append(full_features, add_max(ax))\n",
    "                full_features = np.append(full_features, add_min(ax))\n",
    "                full_features = np.append(full_features, add_median(ax))\n",
    "                full_features = np.append(full_features, add_gradient(ax))\n",
    "                full_features = np.append(full_features, add_std(ax))\n",
    "                full_features = np.append(full_features, add_iqr(ax))\n",
    "                # full_features = np.append(full_features, add_skew(ax))\n",
    "                full_features = np.append(full_features, add_zero_crossing_count(ax))\n",
    "                # full_features = np.append(full_features, add_cwt(ax))\n",
    "                full_features = np.append(full_features, add_no_peaks(ax))\n",
    "                full_features = np.append(full_features, add_recurring_dp(ax))\n",
    "                # full_features = np.append(full_features, add_ratio_v_tsl(ax))\n",
    "                # full_features = np.append(full_features, add_sum_recurring_dp(ax))\n",
    "                full_features = np.append(full_features, add_var_coeff(ax))\n",
    "                full_features = np.append(full_features, add_kurtosis(ax)) \n",
    "\n",
    "    full_features = full_features.reshape(\n",
    "        -1,\n",
    "        len(feature_list) * 6,\n",
    "    )   \n",
    "    full_features_df = pd.DataFrame(full_features)\n",
    "    full_features_df.columns = titles\n",
    "    return full_features_df\n",
    "\n",
    "def feature_extraction(data):\n",
    "    data = pd.DataFrame.from_dict(data)\n",
    "    if 'dance' in data:\n",
    "        del data['dance']\n",
    "\n",
    "    df = data.apply(pd.to_numeric).interpolate(method='polynomial', order=2)\n",
    "    col = df.columns\n",
    "    # X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0)\n",
    "    # df_scaled = df.apply(lambda x: (x - mean(x)) / std(x))\n",
    "    df_scaled = df.apply(lambda x: (x - min(x)) / (max(x) - min(x)))\n",
    "    # min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    # df_scaled = min_max_scaler.fit_transform(df)\n",
    "    df = pd.DataFrame(df_scaled, columns=col)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # print(df.shape)\n",
    "    features = feature_extract(df, window_size=160).reset_index(drop=True)\n",
    "    # print(features.shape)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase: 0\n",
      "dab\n",
      "Set sliding windows: 41\n",
      "Sliding: 0\n",
      "{0: 0.9512195121951219, 2: 0.04878048780487805}\n",
      "Set sliding windows: 41\n",
      "Sliding: 0\n",
      "{2: 0.6829268292682927, 0: 0.3170731707317073}\n",
      "elbowkick\n",
      "Set sliding windows: 41\n",
      "Sliding: 0\n",
      "{0: 0.7317073170731707, 2: 0.2682926829268293}\n",
      "Set sliding windows: 41\n",
      "Sliding: 0\n",
      "{0: 0.7073170731707317, 2: 0.2926829268292683}\n",
      "Set sliding windows: 41\n",
      "Sliding: 0\n",
      "{0: 1.0}\n",
      "gun\n",
      "Set sliding windows: 41\n",
      "Sliding: 0\n",
      "{0: 0.6097560975609756, 2: 0.3902439024390244}\n",
      "Set sliding windows: 41\n",
      "Sliding: 0\n",
      "{2: 1.0}\n",
      "Set sliding windows: 41\n",
      "Sliding: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-2bea14bc8979>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m                     \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m                 \u001b[0mdf_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmlp_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[0mproba_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-97-517193a7522b>\u001b[0m in \u001b[0;36mfeature_extraction\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;31m# print(df.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_extract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m160\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[1;31m# print(features.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-97-517193a7522b>\u001b[0m in \u001b[0;36mfeature_extract\u001b[1;34m(df, window_size)\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[1;31m# full_features = np.append(full_features, add_cwt(ax))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[0mfull_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_no_peaks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                 \u001b[0mfull_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_recurring_dp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m                 \u001b[1;31m# full_features = np.append(full_features, add_ratio_v_tsl(ax))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[1;31m# full_features = np.append(full_features, add_sum_recurring_dp(ax))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\CG4002_B07\\feature_extraction.py\u001b[0m in \u001b[0;36madd_recurring_dp\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0madd_recurring_dp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpercentage_of_reoccurring_datapoints_to_all_datapoints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mvariation_coefficient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\CG4002_B07\\feature_extraction.py\u001b[0m in \u001b[0;36mpercentage_of_reoccurring_datapoints_to_all_datapoints\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m     \u001b[0mvalue_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m     \u001b[0mreoccuring_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue_counts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalue_counts\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36mvalue_counts\u001b[1;34m(self, normalize, sort, ascending, bins, dropna)\u001b[0m\n\u001b[0;32m   1242\u001b[0m             \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m             \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1244\u001b[1;33m             \u001b[0mdropna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1245\u001b[0m         )\n\u001b[0;32m   1246\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mvalue_counts\u001b[1;34m(values, sort, ascending, normalize, bins, dropna)\u001b[0m\n\u001b[0;32m    726\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36msort_values\u001b[1;34m(self, axis, ascending, inplace, kind, na_position, ignore_index)\u001b[0m\n\u001b[0;32m   2960\u001b[0m         \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mibase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2962\u001b[1;33m         \u001b[0margsorted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_try_kind_sort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgood\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2964\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_try_kind_sort\u001b[1;34m(arr)\u001b[0m\n\u001b[0;32m   2946\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2947\u001b[0m                 \u001b[1;31m# if kind==mergesort, it can fail for object dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2948\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2949\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2950\u001b[0m                 \u001b[1;31m# stable sort not available for object dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "dances = ['dab', 'elbowkick', 'gun', 'hair', 'listen', 'pointhigh', 'sidepump', 'wipetable']\n",
    "# dances = ['gun', 'hair', 'sidepump']\n",
    "# dances = ['elbowkick', 'pointhigh', 'wipetable']\n",
    "persons = ['kelvin', 'guiyong', 'xiaoxue', 'john']\n",
    "beetles = ['1', '2']\n",
    "\n",
    "test_range = 12\n",
    "leap = 240\n",
    "truth, total, skipped = 0,0,0\n",
    "for i in range(0,0+test_range):\n",
    "    print(\"Phase:\", i)\n",
    "    start, end = i * leap, i * leap + leap\n",
    "    for d in dances:\n",
    "        print(d)\n",
    "        df_full = pd.DataFrame()\n",
    "        collection = [np.array([]) for x in range(16)]\n",
    "        j = 0\n",
    "        for p in persons:\n",
    "            for b in beetles:\n",
    "                move_json = 'collected_data/' + d + b + '_' + p + '.json'\n",
    "                try:\n",
    "                    with open(move_json) as f:\n",
    "                        x = json.load(f)\n",
    "                except FileNotFoundError:\n",
    "                    continue\n",
    "                x = pd.DataFrame.from_dict(x)[start:end]\n",
    "                df_target = torch.from_numpy(np.array(feature_extraction(x)))\n",
    "                output = mlp_model.predict(df_target)\n",
    "                proba_dict = {}\n",
    "\n",
    "                for x in output:\n",
    "                    x = int(x)\n",
    "                    if x not in proba_dict:\n",
    "                        proba_dict[x] = 1\n",
    "                    else:\n",
    "                        proba_dict[x] += 1\n",
    "                for k in proba_dict.keys():\n",
    "                    proba_dict[k] /= len(output)\n",
    "\n",
    "                print(dict(sorted(proba_dict.items(), key=lambda item: -item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"collected_data/dab2_guiyong.json\") as f:\n",
    "    x = json.load(f)\n",
    "x = pd.DataFrame.from_dict(x)[120:240]\n",
    "feature_extraction(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_accel1</th>\n",
       "      <th>mean_accel2</th>\n",
       "      <th>mean_accel3</th>\n",
       "      <th>mean_gyro1</th>\n",
       "      <th>mean_gyro2</th>\n",
       "      <th>mean_gyro3</th>\n",
       "      <th>max_accel1</th>\n",
       "      <th>max_gyro2</th>\n",
       "      <th>max_gyro3</th>\n",
       "      <th>min_accel1</th>\n",
       "      <th>...</th>\n",
       "      <th>var_coeff_accel2</th>\n",
       "      <th>var_coeff_accel3</th>\n",
       "      <th>var_coeff_gyro1</th>\n",
       "      <th>var_coeff_gyro2</th>\n",
       "      <th>var_coeff_gyro3</th>\n",
       "      <th>kurtosis_accel1</th>\n",
       "      <th>kurtosis_gyro1</th>\n",
       "      <th>kurtosis_gyro2</th>\n",
       "      <th>kurtosis_gyro3</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.561574</td>\n",
       "      <td>0.871486</td>\n",
       "      <td>0.341006</td>\n",
       "      <td>0.561113</td>\n",
       "      <td>2.551716e-03</td>\n",
       "      <td>0.139505</td>\n",
       "      <td>0.239064</td>\n",
       "      <td>0.248417</td>\n",
       "      <td>-1.044620</td>\n",
       "      <td>0.368823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743764</td>\n",
       "      <td>0.280045</td>\n",
       "      <td>0.518141</td>\n",
       "      <td>-0.000987</td>\n",
       "      <td>0.119250</td>\n",
       "      <td>0.178005</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.233208</td>\n",
       "      <td>-0.868082</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.564740</td>\n",
       "      <td>0.871486</td>\n",
       "      <td>0.341006</td>\n",
       "      <td>0.567646</td>\n",
       "      <td>3.837370e-04</td>\n",
       "      <td>0.140682</td>\n",
       "      <td>0.245009</td>\n",
       "      <td>0.249109</td>\n",
       "      <td>-1.096264</td>\n",
       "      <td>0.354788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743764</td>\n",
       "      <td>0.280045</td>\n",
       "      <td>0.548753</td>\n",
       "      <td>-0.001082</td>\n",
       "      <td>0.124935</td>\n",
       "      <td>0.181122</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.236689</td>\n",
       "      <td>-0.893391</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.584284</td>\n",
       "      <td>0.873378</td>\n",
       "      <td>0.341006</td>\n",
       "      <td>0.602842</td>\n",
       "      <td>-2.702565e-03</td>\n",
       "      <td>0.153713</td>\n",
       "      <td>0.260264</td>\n",
       "      <td>0.263080</td>\n",
       "      <td>-1.073073</td>\n",
       "      <td>0.365117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743764</td>\n",
       "      <td>0.289116</td>\n",
       "      <td>0.546485</td>\n",
       "      <td>-0.001767</td>\n",
       "      <td>0.109728</td>\n",
       "      <td>0.149660</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.203380</td>\n",
       "      <td>-0.566786</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.599317</td>\n",
       "      <td>0.873378</td>\n",
       "      <td>0.341006</td>\n",
       "      <td>0.624393</td>\n",
       "      <td>1.604648e-03</td>\n",
       "      <td>0.151911</td>\n",
       "      <td>0.248146</td>\n",
       "      <td>0.253473</td>\n",
       "      <td>-1.079889</td>\n",
       "      <td>0.374148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.708617</td>\n",
       "      <td>0.243764</td>\n",
       "      <td>0.522109</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>0.116401</td>\n",
       "      <td>0.164116</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.229301</td>\n",
       "      <td>-0.564880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.602256</td>\n",
       "      <td>0.873378</td>\n",
       "      <td>0.341006</td>\n",
       "      <td>0.633078</td>\n",
       "      <td>1.790984e-03</td>\n",
       "      <td>0.145675</td>\n",
       "      <td>0.243094</td>\n",
       "      <td>0.241882</td>\n",
       "      <td>-1.133215</td>\n",
       "      <td>0.370184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.708617</td>\n",
       "      <td>0.243764</td>\n",
       "      <td>0.526077</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>0.112535</td>\n",
       "      <td>0.139172</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.216835</td>\n",
       "      <td>-0.297306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.596881</td>\n",
       "      <td>0.849629</td>\n",
       "      <td>0.379529</td>\n",
       "      <td>0.587579</td>\n",
       "      <td>2.640500e-04</td>\n",
       "      <td>0.128211</td>\n",
       "      <td>0.213025</td>\n",
       "      <td>0.214802</td>\n",
       "      <td>-0.994379</td>\n",
       "      <td>0.354892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.287982</td>\n",
       "      <td>0.512472</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.111596</td>\n",
       "      <td>0.107426</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.219081</td>\n",
       "      <td>-0.354742</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.615668</td>\n",
       "      <td>0.849629</td>\n",
       "      <td>0.379529</td>\n",
       "      <td>0.605009</td>\n",
       "      <td>1.803321e-03</td>\n",
       "      <td>0.132408</td>\n",
       "      <td>0.188536</td>\n",
       "      <td>0.215064</td>\n",
       "      <td>-1.082186</td>\n",
       "      <td>0.367120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.274376</td>\n",
       "      <td>0.517574</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>0.110549</td>\n",
       "      <td>0.088152</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.214807</td>\n",
       "      <td>-0.141811</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.622675</td>\n",
       "      <td>0.855948</td>\n",
       "      <td>0.379529</td>\n",
       "      <td>0.618792</td>\n",
       "      <td>2.540000e-07</td>\n",
       "      <td>0.138154</td>\n",
       "      <td>0.206760</td>\n",
       "      <td>0.221872</td>\n",
       "      <td>-1.154258</td>\n",
       "      <td>0.369442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717687</td>\n",
       "      <td>0.274376</td>\n",
       "      <td>0.518141</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.106450</td>\n",
       "      <td>0.090420</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.204696</td>\n",
       "      <td>-0.062467</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.618663</td>\n",
       "      <td>0.855948</td>\n",
       "      <td>0.405751</td>\n",
       "      <td>0.608520</td>\n",
       "      <td>1.840334e-03</td>\n",
       "      <td>0.129487</td>\n",
       "      <td>0.192741</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>-1.070088</td>\n",
       "      <td>0.364344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717687</td>\n",
       "      <td>0.260771</td>\n",
       "      <td>0.518141</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>0.111256</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.215122</td>\n",
       "      <td>-0.195709</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.614310</td>\n",
       "      <td>0.855948</td>\n",
       "      <td>0.395891</td>\n",
       "      <td>0.608520</td>\n",
       "      <td>-2.318192e-03</td>\n",
       "      <td>0.132454</td>\n",
       "      <td>0.200159</td>\n",
       "      <td>0.215615</td>\n",
       "      <td>-1.032085</td>\n",
       "      <td>0.362111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.696145</td>\n",
       "      <td>0.260771</td>\n",
       "      <td>0.520975</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.115312</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.219126</td>\n",
       "      <td>-0.405906</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_accel1  mean_accel2  mean_accel3  mean_gyro1    mean_gyro2  \\\n",
       "0      0.561574     0.871486     0.341006    0.561113  2.551716e-03   \n",
       "1      0.564740     0.871486     0.341006    0.567646  3.837370e-04   \n",
       "2      0.584284     0.873378     0.341006    0.602842 -2.702565e-03   \n",
       "3      0.599317     0.873378     0.341006    0.624393  1.604648e-03   \n",
       "4      0.602256     0.873378     0.341006    0.633078  1.790984e-03   \n",
       "..          ...          ...          ...         ...           ...   \n",
       "67     0.596881     0.849629     0.379529    0.587579  2.640500e-04   \n",
       "68     0.615668     0.849629     0.379529    0.605009  1.803321e-03   \n",
       "69     0.622675     0.855948     0.379529    0.618792  2.540000e-07   \n",
       "70     0.618663     0.855948     0.405751    0.608520  1.840334e-03   \n",
       "71     0.614310     0.855948     0.395891    0.608520 -2.318192e-03   \n",
       "\n",
       "    mean_gyro3  max_accel1  max_gyro2  max_gyro3  min_accel1  ...  \\\n",
       "0     0.139505    0.239064   0.248417  -1.044620    0.368823  ...   \n",
       "1     0.140682    0.245009   0.249109  -1.096264    0.354788  ...   \n",
       "2     0.153713    0.260264   0.263080  -1.073073    0.365117  ...   \n",
       "3     0.151911    0.248146   0.253473  -1.079889    0.374148  ...   \n",
       "4     0.145675    0.243094   0.241882  -1.133215    0.370184  ...   \n",
       "..         ...         ...        ...        ...         ...  ...   \n",
       "67    0.128211    0.213025   0.214802  -0.994379    0.354892  ...   \n",
       "68    0.132408    0.188536   0.215064  -1.082186    0.367120  ...   \n",
       "69    0.138154    0.206760   0.221872  -1.154258    0.369442  ...   \n",
       "70    0.129487    0.192741   0.209302  -1.070088    0.364344  ...   \n",
       "71    0.132454    0.200159   0.215615  -1.032085    0.362111  ...   \n",
       "\n",
       "    var_coeff_accel2  var_coeff_accel3  var_coeff_gyro1  var_coeff_gyro2  \\\n",
       "0           0.743764          0.280045         0.518141        -0.000987   \n",
       "1           0.743764          0.280045         0.548753        -0.001082   \n",
       "2           0.743764          0.289116         0.546485        -0.001767   \n",
       "3           0.708617          0.243764         0.522109         0.001786   \n",
       "4           0.708617          0.243764         0.526077         0.001512   \n",
       "..               ...               ...              ...              ...   \n",
       "67          0.730159          0.287982         0.512472         0.000184   \n",
       "68          0.730159          0.274376         0.517574         0.002551   \n",
       "69          0.717687          0.274376         0.518141         0.000094   \n",
       "70          0.717687          0.260771         0.518141         0.001635   \n",
       "71          0.696145          0.260771         0.520975         0.000430   \n",
       "\n",
       "    var_coeff_gyro3  kurtosis_accel1  kurtosis_gyro1  kurtosis_gyro2  \\\n",
       "0          0.119250         0.178005        0.233333        0.233208   \n",
       "1          0.124935         0.181122        0.208333        0.236689   \n",
       "2          0.109728         0.149660        0.225000        0.203380   \n",
       "3          0.116401         0.164116        0.250000        0.229301   \n",
       "4          0.112535         0.139172        0.250000        0.216835   \n",
       "..              ...              ...             ...             ...   \n",
       "67         0.111596         0.107426        0.291667        0.219081   \n",
       "68         0.110549         0.088152        0.283333        0.214807   \n",
       "69         0.106450         0.090420        0.325000        0.204696   \n",
       "70         0.111256         0.102041        0.325000        0.215122   \n",
       "71         0.115312         0.138889        0.291667        0.219126   \n",
       "\n",
       "    kurtosis_gyro3  tag  \n",
       "0        -0.868082    0  \n",
       "1        -0.893391    0  \n",
       "2        -0.566786    0  \n",
       "3        -0.564880    0  \n",
       "4        -0.297306    0  \n",
       "..             ...  ...  \n",
       "67       -0.354742    0  \n",
       "68       -0.141811    0  \n",
       "69       -0.062467    0  \n",
       "70       -0.195709    0  \n",
       "71       -0.405906    0  \n",
       "\n",
       "[72 rows x 58 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.df.head(72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hierarchical = df.copy()\n",
    "df_hierarchical['tag'] = df_hierarchical['tag'].apply(lambda x: 0 if x <= 7 else 1)\n",
    "\n",
    "msk = np.random.rand(len(df_hierarchical)) < 0.8\n",
    "df_train = df_hierarchical[msk]\n",
    "df_test = df_hierarchical[~msk]\n",
    "\n",
    "dataset = FeatureDataset(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hierarchical = MLP(D_in, 50, 2)\n",
    "optimizer = torch.optim.SGD(model_hierarchical.parameters(), lr=0.01, momentum=0.5)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "model, losses, accuracies = train_val_model(model_hierarchical, criterion, optimizer, dataset.X, dataset.y, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'MLP_Model_Hierarchical_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(losses['train'], '-b', losses['val'], '--r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = MLP(D_in, 50, 2)\n",
    "mlp_model.load('MLP_Model_Hierarchical_1')\n",
    "mlp_model.eval()\n",
    "\n",
    "for to_predict in range(2):\n",
    "    df_target = df_test[df_test['tag'] == to_predict]\n",
    "\n",
    "    df_random = df_test\n",
    "\n",
    "    df_filtered = torch.from_numpy(np.array(pd.merge(df_target, df_random))[:,:-1])\n",
    "    output = mlp_model.predict(df_filtered)\n",
    "    # print(output)\n",
    "    proba_dict = {}\n",
    "\n",
    "    for x in output:\n",
    "        x = int(x)\n",
    "        if x not in proba_dict:\n",
    "            proba_dict[x] = 1\n",
    "        else:\n",
    "            proba_dict[x] += 1\n",
    "    for k in proba_dict.keys():\n",
    "        proba_dict[k] /= len(output)\n",
    "    print(dict(sorted(proba_dict.items(), key=lambda item: -item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hierarchical_2 = df.copy()\n",
    "df_hierarchical_2 = df_hierarchical_2[df_hierarchical_2['tag'] >= 8]\n",
    "df_hierarchical_2 = df_hierarchical_2.apply(lambda x: x-8)\n",
    "msk = np.random.rand(len(df_hierarchical_2)) < 0.8\n",
    "df_train = df_hierarchical_2[msk]\n",
    "df_test = df_hierarchical_2[~msk]\n",
    "\n",
    "dataset = FeatureDataset(df_train)\n",
    "\n",
    "model_hierarchical_2 = MLP(D_in, 50, 2)\n",
    "# optimizer = torch.optim.Adam(model_hierarchical_2.parameters(), lr=1e-4)\n",
    "optimizer = torch.optim.SGD(model_hierarchical_2.parameters(), lr=0.01, momentum=0.5)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model, losses, accuracies = train_val_model(model_hierarchical_2, criterion, optimizer, dataset.X, dataset.y, num_epochs=20)\n",
    "\n",
    "torch.save(model.state_dict(), 'MLP_Model_Hierarchical_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(losses['train'], '-b', losses['val'], '--r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = MLP(D_in, 50, 2)\n",
    "mlp_model.load('MLP_Model_Hierarchical_2')\n",
    "mlp_model.eval()\n",
    "\n",
    "for to_predict in range(2):\n",
    "    df_target = df_test[df_test['tag'] == to_predict]\n",
    "\n",
    "    df_random = df_test\n",
    "\n",
    "    df_filtered = torch.from_numpy(np.array(pd.merge(df_target, df_random))[:,:-1])\n",
    "    output = mlp_model.predict(df_filtered)\n",
    "    # print(output)\n",
    "    proba_dict = {}\n",
    "\n",
    "    for x in output:\n",
    "        x = int(x) + 8\n",
    "        if x not in proba_dict:\n",
    "            proba_dict[x] = 1\n",
    "        else:\n",
    "            proba_dict[x] += 1\n",
    "    for k in proba_dict.keys():\n",
    "        proba_dict[k] /= len(output)\n",
    "\n",
    "    print(dict(sorted(proba_dict.items(), key=lambda item: -item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hierarchical_3 = df.copy()\n",
    "df_hierarchical_3 = df_hierarchical_3[df_hierarchical_3['tag'] < 8]\n",
    "msk = np.random.rand(len(df_hierarchical_3)) < 0.8\n",
    "df_train = df_hierarchical_3[msk]\n",
    "df_test = df_hierarchical_3[~msk]\n",
    "\n",
    "dataset = FeatureDataset(df_train)\n",
    "\n",
    "model_hierarchical_3 = MLP(D_in, 50, 8)\n",
    "# optimizer = torch.optim.Adam(model_hierarchical_2.parameters(), lr=1e-4)\n",
    "optimizer = torch.optim.SGD(model_hierarchical_3.parameters(), lr=0.01, momentum=0.5)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "model, losses, accuracies = train_val_model(model_hierarchical_3, criterion, optimizer, dataset.X, dataset.y, num_epochs=30)\n",
    "\n",
    "torch.save(model.state_dict(), 'MLP_Model_Hierarchical_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(losses['train'], '-b', losses['val'], '--r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = MLP(D_in, 50, 8)\n",
    "mlp_model.load('MLP_Model_Hierarchical_3')\n",
    "mlp_model.eval()\n",
    "\n",
    "for to_predict in range(8):\n",
    "    df_target = df_test[df_test['tag'] == to_predict]\n",
    "\n",
    "    df_random = df_test\n",
    "\n",
    "    df_filtered = torch.from_numpy(np.array(pd.merge(df_target, df_random))[:,:-1])\n",
    "    output = mlp_model.predict(df_filtered)\n",
    "    # print(output)\n",
    "    proba_dict = {}\n",
    "\n",
    "    for x in output:\n",
    "        x = int(x)\n",
    "        if x not in proba_dict:\n",
    "            proba_dict[x] = 1\n",
    "        else:\n",
    "            proba_dict[x] += 1\n",
    "    for k in proba_dict.keys():\n",
    "        proba_dict[k] /= len(output)\n",
    "\n",
    "    print(dict(sorted(proba_dict.items(), key=lambda item: -item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 4)]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "lst = [1,1,1,1,2,3]\n",
    "print(statistics._counts(lst))\n",
    "print(max([p[0] for p in statistics._counts(lst)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidating Data\n",
      "(4352, 7) (4338, 7)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "# X, y = make_classification(n_samples=100, random_state=1)\n",
    "train, test = consolidate_data()\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(train)[:,:-1], np.array(train)[:,-1], random_state=1)\n",
    "# print(X_train.shape, y_train.shape)\n",
    "clf = MLPClassifier(solver='adam', alpha=1e-5, random_state=1, max_iter=2000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6167279411764706"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(490, 6)\n",
      "{1: 0.6, 7: 0.16938775510204082, 5: 0.07959183673469387, 6: 0.07755102040816327, 4: 0.036734693877551024, 8: 0.014285714285714285, 2: 0.012244897959183673, 3: 0.01020408163265306}\n",
      "(554, 6)\n",
      "{2: 0.33393501805054154, 5: 0.24548736462093862, 3: 0.16787003610108303, 1: 0.07581227436823104, 7: 0.06498194945848375, 6: 0.05595667870036101, 4: 0.039711191335740074, 8: 0.016245487364620937}\n",
      "(538, 6)\n",
      "{3: 0.2899628252788104, 5: 0.25650557620817843, 4: 0.12825278810408922, 2: 0.09851301115241635, 6: 0.07434944237918216, 7: 0.05947955390334572, 1: 0.048327137546468404, 8: 0.04460966542750929}\n",
      "(536, 6)\n",
      "{4: 0.34328358208955223, 3: 0.1623134328358209, 5: 0.14925373134328357, 2: 0.125, 1: 0.11194029850746269, 6: 0.08768656716417911, 7: 0.011194029850746268, 8: 0.009328358208955223}\n",
      "(546, 6)\n",
      "{5: 0.38644688644688646, 2: 0.152014652014652, 4: 0.10989010989010989, 1: 0.1043956043956044, 6: 0.1043956043956044, 7: 0.06227106227106227, 3: 0.04395604395604396, 8: 0.03663003663003663}\n",
      "(555, 6)\n",
      "{6: 0.572972972972973, 7: 0.12072072072072072, 1: 0.1063063063063063, 8: 0.055855855855855854, 4: 0.05405405405405406, 5: 0.032432432432432434, 2: 0.032432432432432434, 3: 0.025225225225225224}\n",
      "(573, 6)\n",
      "{7: 0.7958115183246073, 1: 0.05410122164048865, 8: 0.0506108202443281, 5: 0.04886561954624782, 2: 0.019197207678883072, 6: 0.012216404886561954, 3: 0.010471204188481676, 4: 0.008726003490401396}\n",
      "(546, 6)\n",
      "{8: 0.8992673992673993, 2: 0.05311355311355311, 7: 0.02564102564102564, 1: 0.01098901098901099, 5: 0.009157509157509158, 3: 0.0018315018315018315}\n"
     ]
    }
   ],
   "source": [
    "test = np.array(test)\n",
    "for to_predict in range(8):\n",
    "    df_target = test[test[:,-1] == to_predict+1][:,:-1]\n",
    "    print(df_target.shape)\n",
    "    output = clf.predict(df_target)\n",
    "    # print(output)\n",
    "    proba_dict = {}\n",
    "\n",
    "    for x in output:\n",
    "        x = int(x)\n",
    "        if x not in proba_dict:\n",
    "            proba_dict[x] = 1\n",
    "        else:\n",
    "            proba_dict[x] += 1\n",
    "    for k in proba_dict.keys():\n",
    "        proba_dict[k] /= len(output)\n",
    "\n",
    "    print(dict(sorted(proba_dict.items(), key=lambda item: -item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 6 is different from 72)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-131-930d625d1bae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mdf_filtered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_random\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mdf_filtered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_filtered\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_filtered\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;31m# print(output)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mproba_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    969\u001b[0m         \"\"\"\n\u001b[0;32m    970\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 971\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    973\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    683\u001b[0m                                          layer_units[i + 1])))\n\u001b[0;32m    684\u001b[0m         \u001b[1;31m# forward propagate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_forward_pass\u001b[1;34m(self, activations)\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_layers_\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m             activations[i + 1] = safe_sparse_dot(activations[i],\n\u001b[1;32m--> 104\u001b[1;33m                                                  self.coefs_[i])\n\u001b[0m\u001b[0;32m    105\u001b[0m             \u001b[0mactivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercepts_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    149\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 6 is different from 72)"
     ]
    }
   ],
   "source": [
    "# mlp_model = MLP(D_in, 50, 8)\n",
    "# mlp_model.load('MLP_Model_Hierarchical_3')\n",
    "# mlp_model.eval()\n",
    "\n",
    "for to_predict in range(8):\n",
    "    df_target = df_test[df_test['tag'] == to_predict]\n",
    "\n",
    "    df_random = df_test\n",
    "\n",
    "    df_filtered = torch.from_numpy(np.array(pd.merge(df_target, df_random))[:,:-1])\n",
    "    df_filtered = df_filtered\n",
    "    output = clf.predict(df_filtered)\n",
    "    # print(output)\n",
    "    proba_dict = {}\n",
    "\n",
    "    for x in output:\n",
    "        x = int(x)\n",
    "        if x not in proba_dict:\n",
    "            proba_dict[x] = 1\n",
    "        else:\n",
    "            proba_dict[x] += 1\n",
    "    for k in proba_dict.keys():\n",
    "        proba_dict[k] /= len(output)\n",
    "\n",
    "    print(dict(sorted(proba_dict.items(), key=lambda item: -item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase: 0\n",
      "dab\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{3: 1.0}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{3: 1.0}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{3: 1.0}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{3: 1.0}\n",
      "elbowkick\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{5: 1.0}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{2: 0.5714285714285714, 3: 0.42857142857142855}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{5: 0.7142857142857143, 3: 0.14285714285714285, 0: 0.14285714285714285}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{3: 0.7142857142857143, 2: 0.2857142857142857}\n",
      "gun\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{3: 1.0}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{2: 0.7142857142857143, 3: 0.2857142857142857}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{2: 0.7142857142857143, 3: 0.2857142857142857}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{2: 0.8571428571428571, 3: 0.14285714285714285}\n",
      "hair\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{3: 0.8571428571428571, 5: 0.14285714285714285}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{3: 1.0}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{2: 1.0}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{3: 1.0}\n",
      "listen\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{3: 0.8571428571428571, 2: 0.14285714285714285}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{2: 0.7142857142857143, 3: 0.14285714285714285, 5: 0.14285714285714285}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{3: 1.0}\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n",
      "{3: 1.0}\n",
      "pointhigh\n",
      "(80, 6)\n",
      "Set sliding windows: 7\n",
      "Sliding: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-1b9113030eef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m                     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[0mdf_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m                 \u001b[0mdf_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_target\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-f184b95c7117>\u001b[0m in \u001b[0;36mfeature_extraction\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_extract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[1;31m# print(features.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-f184b95c7117>\u001b[0m in \u001b[0;36mfeature_extract\u001b[1;34m(df, window_size)\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[1;31m# full_features = np.append(full_features, add_cwt(ax))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[0mfull_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_no_peaks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                 \u001b[0mfull_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_recurring_dp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m                 \u001b[1;31m# full_features = np.append(full_features, add_ratio_v_tsl(ax))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[1;31m# full_features = np.append(full_features, add_sum_recurring_dp(ax))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\CG4002_B07\\feature_extraction.py\u001b[0m in \u001b[0;36madd_recurring_dp\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0madd_recurring_dp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfeature_calculators\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpercentage_of_reoccurring_datapoints_to_all_datapoints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0madd_ratio_v_tsl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tsfresh\\feature_extraction\\feature_calculators.py\u001b[0m in \u001b[0;36mpercentage_of_reoccurring_datapoints_to_all_datapoints\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    925\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 927\u001b[1;33m     \u001b[0mvalue_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    928\u001b[0m     \u001b[0mreoccuring_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue_counts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalue_counts\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36mvalue_counts\u001b[1;34m(self, normalize, sort, ascending, bins, dropna)\u001b[0m\n\u001b[0;32m   1242\u001b[0m             \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m             \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1244\u001b[1;33m             \u001b[0mdropna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1245\u001b[0m         )\n\u001b[0;32m   1246\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mvalue_counts\u001b[1;34m(values, sort, ascending, normalize, bins, dropna)\u001b[0m\n\u001b[0;32m    726\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36msort_values\u001b[1;34m(self, axis, ascending, inplace, kind, na_position, ignore_index)\u001b[0m\n\u001b[0;32m   2977\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mna_position\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"last\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgood\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2979\u001b[1;33m             \u001b[0msorted_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgood\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margsorted\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2980\u001b[0m             \u001b[0msorted_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbad\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2981\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mna_position\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"first\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\range.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    706\u001b[0m             )\n\u001b[0;32m    707\u001b[0m         \u001b[1;31m# fall back to Int64Index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__floordiv__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3923\u001b[0m         \u001b[1;31m# There's no custom logic to be implemented in __getslice__, so it's\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3924\u001b[0m         \u001b[1;31m# not overloaded intentionally.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3925\u001b[1;33m         \u001b[0mgetitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3926\u001b[0m         \u001b[0mpromote\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shallow_copy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\range.py\u001b[0m in \u001b[0;36m_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cached_data\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             self._cached_data = np.arange(\n\u001b[1;32m--> 166\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m             )\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cached_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "dances = ['dab', 'elbowkick', 'gun', 'hair', 'listen', 'pointhigh', 'sidepump', 'wipetable']\n",
    "# dances = ['gun', 'hair', 'sidepump']\n",
    "# dances = ['elbowkick', 'pointhigh', 'wipetable']\n",
    "persons = ['kelvin', 'guiyong', 'xiaoxue', 'john']\n",
    "beetles = ['1', '2']\n",
    "\n",
    "test_range = 12\n",
    "leap = 80\n",
    "truth, total, skipped = 0,0,0\n",
    "for i in range(0,0+test_range):\n",
    "    print(\"Phase:\", i)\n",
    "    start, end = i * leap, i * leap + leap\n",
    "    for d in dances:\n",
    "        print(d)\n",
    "        df_full = pd.DataFrame()\n",
    "        collection = [np.array([]) for x in range(16)]\n",
    "        j = 0\n",
    "        for p in persons:\n",
    "            for b in beetles:\n",
    "                if b == '1':\n",
    "                    continue\n",
    "                move_json = 'collected_data/' + d + b + '_' + p + '.json'\n",
    "                with open(move_json) as f:\n",
    "                    x = json.load(f)\n",
    "                x = pd.DataFrame.from_dict(x)[start:end]\n",
    "                df_target = torch.from_numpy(np.array(feature_extraction(x)))\n",
    "                df_target = df_target\n",
    "                output = clf.predict(df_target)\n",
    "                proba_dict = {}\n",
    "\n",
    "                for x in output:\n",
    "                    x = int(x)\n",
    "                    if x not in proba_dict:\n",
    "                        proba_dict[x] = 1\n",
    "                    else:\n",
    "                        proba_dict[x] += 1\n",
    "                for k in proba_dict.keys():\n",
    "                    proba_dict[k] /= len(output)\n",
    "\n",
    "                print(dict(sorted(proba_dict.items(), key=lambda item: -item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase: 0\n",
      "dab\n",
      "{7: 0.6, 4: 0.225, 5: 0.1125, 6: 0.0375, 2: 0.025}\n",
      "{6: 0.4625, 7: 0.375, 5: 0.1625}\n",
      "{5: 0.35, 6: 0.3125, 7: 0.2875, 2: 0.05}\n",
      "{6: 0.3625, 2: 0.25, 7: 0.2, 5: 0.1875}\n",
      "elbowkick\n",
      "{7: 0.4, 3: 0.275, 5: 0.175, 4: 0.0875, 6: 0.0375, 2: 0.025}\n",
      "{2: 0.3, 6: 0.275, 7: 0.2375, 5: 0.1875}\n",
      "{2: 0.4125, 6: 0.3875, 7: 0.2}\n",
      "{7: 0.45, 2: 0.375, 6: 0.175}\n",
      "gun\n",
      "{7: 0.4375, 4: 0.2, 3: 0.15, 6: 0.1, 5: 0.0625, 2: 0.05}\n",
      "{7: 0.325, 6: 0.325, 2: 0.25, 5: 0.1}\n",
      "{2: 0.4, 7: 0.3125, 5: 0.1875, 6: 0.1}\n",
      "{7: 0.35, 2: 0.2625, 5: 0.225, 6: 0.1625}\n",
      "hair\n",
      "{7: 0.5, 4: 0.2875, 5: 0.15, 6: 0.05, 3: 0.0125}\n",
      "{6: 0.325, 2: 0.275, 5: 0.2625, 7: 0.1375}\n",
      "{6: 0.325, 2: 0.275, 5: 0.2625, 7: 0.1375}\n",
      "{2: 0.3625, 6: 0.2875, 5: 0.275, 7: 0.075}\n",
      "listen\n",
      "{7: 0.6625, 4: 0.175, 5: 0.0875, 2: 0.0375, 6: 0.0375}\n",
      "{6: 0.3125, 7: 0.2875, 5: 0.2375, 2: 0.1375, 4: 0.025}\n",
      "{6: 0.5125, 2: 0.2375, 4: 0.1625, 5: 0.075, 3: 0.0125}\n",
      "{7: 0.4, 2: 0.275, 5: 0.175, 6: 0.15}\n",
      "pointhigh\n",
      "{4: 0.475, 7: 0.3625, 5: 0.15, 6: 0.0125}\n",
      "{6: 0.5625, 2: 0.175, 5: 0.1625, 7: 0.1}\n",
      "{2: 0.375, 6: 0.2375, 5: 0.2375, 7: 0.1125, 4: 0.0375}\n",
      "{5: 0.4125, 6: 0.3875, 7: 0.1125, 2: 0.0875}\n",
      "sidepump\n",
      "{7: 0.5125, 4: 0.1875, 3: 0.1125, 2: 0.1, 5: 0.0875}\n",
      "{6: 0.375, 7: 0.2625, 2: 0.25, 5: 0.075, 4: 0.0375}\n",
      "{2: 0.3, 6: 0.2625, 5: 0.2, 7: 0.1625, 4: 0.075}\n",
      "{2: 0.4375, 6: 0.35, 7: 0.1875, 4: 0.025}\n",
      "wipetable\n",
      "{7: 0.7125, 3: 0.2625, 2: 0.025}\n",
      "{7: 0.4125, 2: 0.3625, 6: 0.225}\n",
      "{6: 0.4125, 7: 0.3, 2: 0.2875}\n",
      "{6: 0.6375, 2: 0.25, 7: 0.1125}\n",
      "Phase: 1\n",
      "dab\n",
      "{7: 0.55, 4: 0.1875, 5: 0.1875, 6: 0.075}\n",
      "{6: 0.475, 5: 0.3125, 7: 0.1875, 2: 0.025}\n",
      "{6: 0.3375, 5: 0.3125, 7: 0.2, 2: 0.15}\n",
      "{6: 0.3125, 7: 0.3125, 2: 0.225, 5: 0.15}\n",
      "elbowkick\n",
      "{7: 0.3875, 3: 0.2625, 4: 0.15, 6: 0.1, 2: 0.0625, 5: 0.0375}\n",
      "{2: 0.3875, 7: 0.3375, 6: 0.2125, 5: 0.0625}\n",
      "{2: 0.5625, 7: 0.275, 6: 0.1625}\n",
      "{2: 0.4375, 7: 0.425, 6: 0.125, 4: 0.0125}\n",
      "gun\n",
      "{7: 0.4375, 4: 0.225, 3: 0.1625, 6: 0.1125, 5: 0.0375, 2: 0.025}\n",
      "{6: 0.35, 7: 0.275, 2: 0.2125, 5: 0.1625}\n",
      "{7: 0.475, 2: 0.2625, 5: 0.1375, 6: 0.125}\n",
      "{7: 0.4, 5: 0.2375, 2: 0.2, 6: 0.1625}\n",
      "hair\n",
      "{7: 0.4, 4: 0.275, 5: 0.1, 6: 0.0875, 3: 0.075, 2: 0.0625}\n",
      "{6: 0.4, 2: 0.225, 7: 0.2125, 5: 0.1625}\n",
      "{5: 0.375, 6: 0.25, 2: 0.225, 7: 0.15}\n",
      "{5: 0.375, 2: 0.35, 6: 0.2625, 7: 0.0125}\n",
      "listen\n",
      "{7: 0.6375, 4: 0.175, 6: 0.1, 5: 0.05, 2: 0.0375}\n",
      "{7: 0.4125, 6: 0.2875, 5: 0.1625, 2: 0.125, 4: 0.0125}\n",
      "{6: 0.475, 2: 0.3125, 5: 0.1375, 4: 0.075}\n",
      "{7: 0.35, 2: 0.2625, 5: 0.225, 6: 0.1625}\n",
      "pointhigh\n",
      "{4: 0.45, 7: 0.275, 5: 0.1875, 3: 0.075, 6: 0.0125}\n",
      "{6: 0.5, 5: 0.3, 2: 0.1375, 7: 0.0625}\n",
      "{2: 0.4625, 5: 0.3375, 6: 0.15, 7: 0.0375, 4: 0.0125}\n",
      "{5: 0.475, 6: 0.4125, 2: 0.0875, 7: 0.025}\n",
      "sidepump\n",
      "{4: 0.4125, 7: 0.325, 3: 0.1125, 2: 0.0875, 5: 0.05, 6: 0.0125}\n",
      "{6: 0.3375, 7: 0.2875, 2: 0.25, 5: 0.0875, 4: 0.0375}\n",
      "{2: 0.3875, 5: 0.2625, 6: 0.175, 7: 0.1125, 4: 0.0625}\n",
      "{6: 0.5375, 2: 0.3375, 7: 0.125}\n",
      "wipetable\n",
      "{7: 0.55, 3: 0.4125, 2: 0.025, 5: 0.0125}\n",
      "{2: 0.4625, 7: 0.325, 6: 0.2125}\n",
      "{6: 0.5125, 2: 0.3, 7: 0.1875}\n",
      "{6: 0.575, 2: 0.3, 7: 0.125}\n",
      "Phase: 2\n",
      "dab\n",
      "{7: 0.5625, 5: 0.2, 6: 0.125, 4: 0.1125}\n",
      "{6: 0.5625, 5: 0.2625, 7: 0.1375, 2: 0.0375}\n",
      "{6: 0.4375, 5: 0.275, 7: 0.25, 2: 0.0375}\n",
      "{6: 0.375, 2: 0.3125, 7: 0.1625, 5: 0.15}\n",
      "elbowkick\n",
      "{7: 0.375, 3: 0.3, 4: 0.1625, 5: 0.075, 6: 0.0625, 2: 0.025}\n",
      "{2: 0.375, 7: 0.2875, 6: 0.2125, 5: 0.125}\n",
      "{2: 0.525, 7: 0.3125, 6: 0.1625}\n",
      "{2: 0.425, 7: 0.3625, 6: 0.2125}\n",
      "gun\n",
      "{7: 0.5625, 3: 0.125, 4: 0.1125, 6: 0.075, 2: 0.0625, 5: 0.0625}\n",
      "{7: 0.3, 6: 0.2875, 2: 0.2625, 5: 0.15}\n",
      "{7: 0.5, 2: 0.2625, 6: 0.125, 5: 0.1125}\n",
      "{7: 0.35, 5: 0.275, 6: 0.2125, 2: 0.1625}\n",
      "hair\n",
      "{7: 0.475, 5: 0.2125, 4: 0.1125, 3: 0.075, 6: 0.075, 2: 0.05}\n",
      "{2: 0.275, 5: 0.2625, 6: 0.2625, 7: 0.2}\n",
      "{5: 0.3875, 2: 0.3, 6: 0.1875, 7: 0.125}\n",
      "{6: 0.45, 5: 0.275, 2: 0.1875, 7: 0.0875}\n",
      "listen\n",
      "{7: 0.6875, 6: 0.1125, 4: 0.1, 5: 0.0625, 3: 0.025, 2: 0.0125}\n",
      "{6: 0.35, 7: 0.3125, 5: 0.2125, 2: 0.125}\n",
      "{6: 0.4875, 2: 0.225, 4: 0.1875, 5: 0.1}\n",
      "{7: 0.3375, 2: 0.3, 5: 0.2375, 6: 0.125}\n",
      "pointhigh\n",
      "{4: 0.3625, 7: 0.3625, 5: 0.15, 3: 0.125}\n",
      "{6: 0.6, 5: 0.1875, 2: 0.15, 7: 0.0625}\n",
      "{2: 0.55, 5: 0.25, 6: 0.1125, 7: 0.075, 4: 0.0125}\n",
      "{6: 0.5625, 5: 0.3375, 7: 0.0625, 2: 0.0375}\n",
      "sidepump\n",
      "{4: 0.5875, 7: 0.3125, 5: 0.05, 3: 0.0375, 2: 0.0125}\n",
      "{7: 0.3875, 6: 0.3375, 2: 0.175, 5: 0.075, 4: 0.025}\n",
      "{2: 0.55, 6: 0.2875, 5: 0.1625}\n",
      "{2: 0.525, 6: 0.2625, 7: 0.2125}\n",
      "wipetable\n",
      "{7: 0.7375, 3: 0.2625}\n",
      "{7: 0.35, 6: 0.325, 2: 0.325}\n",
      "{6: 0.5625, 2: 0.3, 7: 0.1375}\n",
      "{6: 0.6, 7: 0.2375, 2: 0.1625}\n",
      "Phase: 3\n",
      "dab\n",
      "{7: 0.4875, 4: 0.1875, 5: 0.175, 6: 0.15}\n",
      "{6: 0.55, 5: 0.2625, 7: 0.15, 2: 0.0375}\n",
      "{6: 0.375, 7: 0.275, 5: 0.225, 2: 0.125}\n",
      "{2: 0.3875, 6: 0.325, 5: 0.2, 7: 0.0875}\n",
      "elbowkick\n",
      "{7: 0.35, 3: 0.2, 4: 0.1625, 5: 0.1625, 6: 0.075, 2: 0.05}\n",
      "{2: 0.4125, 7: 0.3125, 6: 0.2125, 5: 0.0625}\n",
      "{7: 0.5375, 2: 0.2375, 6: 0.225}\n",
      "{2: 0.5, 7: 0.3875, 6: 0.1125}\n",
      "gun\n",
      "{7: 0.625, 3: 0.15, 4: 0.0875, 6: 0.075, 5: 0.05, 2: 0.0125}\n",
      "{2: 0.2875, 6: 0.275, 7: 0.275, 5: 0.1625}\n",
      "{7: 0.3875, 2: 0.3875, 5: 0.1375, 6: 0.0875}\n",
      "{7: 0.5125, 5: 0.2125, 2: 0.1375, 6: 0.125, 4: 0.0125}\n",
      "hair\n",
      "{4: 0.3625, 7: 0.3125, 3: 0.1, 5: 0.1, 6: 0.0875, 2: 0.0375}\n",
      "{6: 0.375, 2: 0.2875, 5: 0.2125, 7: 0.125}\n",
      "{5: 0.3625, 2: 0.2875, 6: 0.225, 7: 0.125}\n",
      "{5: 0.4, 6: 0.2875, 2: 0.2625, 7: 0.05}\n",
      "listen\n",
      "{7: 0.6875, 4: 0.1875, 6: 0.0875, 5: 0.025, 2: 0.0125}\n",
      "{6: 0.3, 7: 0.3, 5: 0.275, 2: 0.125}\n",
      "{6: 0.6, 2: 0.2, 4: 0.175, 5: 0.025}\n",
      "{2: 0.3, 7: 0.2875, 5: 0.2125, 6: 0.2}\n",
      "pointhigh\n",
      "{4: 0.5, 7: 0.325, 3: 0.0875, 5: 0.0875}\n",
      "{6: 0.425, 5: 0.325, 2: 0.1625, 7: 0.0875}\n",
      "{2: 0.5375, 6: 0.1875, 5: 0.1625, 7: 0.1125}\n",
      "{5: 0.6, 6: 0.2625, 7: 0.1375}\n",
      "sidepump\n",
      "{4: 0.5875, 7: 0.2125, 3: 0.0875, 5: 0.0625, 2: 0.05}\n",
      "{7: 0.375, 2: 0.2875, 6: 0.2875, 5: 0.025, 4: 0.025}\n",
      "{2: 0.575, 6: 0.2, 5: 0.1125, 7: 0.0875, 4: 0.025}\n",
      "{2: 0.4125, 6: 0.2875, 7: 0.275, 4: 0.0125, 5: 0.0125}\n",
      "wipetable\n",
      "{7: 0.65, 3: 0.3125, 5: 0.025, 2: 0.0125}\n",
      "{2: 0.375, 7: 0.35, 6: 0.275}\n",
      "{6: 0.45, 2: 0.4, 7: 0.15}\n",
      "{6: 0.6125, 2: 0.2125, 7: 0.175}\n",
      "Phase: 4\n",
      "dab\n",
      "{7: 0.6625, 4: 0.15, 5: 0.125, 6: 0.0625}\n",
      "{6: 0.4875, 5: 0.3, 7: 0.175, 2: 0.0375}\n",
      "{5: 0.2875, 7: 0.275, 6: 0.25, 2: 0.15, 4: 0.0375}\n",
      "{6: 0.3875, 7: 0.2625, 2: 0.2625, 5: 0.0875}\n",
      "elbowkick\n",
      "{7: 0.4375, 3: 0.2625, 4: 0.1125, 5: 0.0875, 6: 0.0625, 2: 0.0375}\n",
      "{2: 0.4625, 7: 0.2375, 6: 0.2125, 5: 0.0875}\n",
      "{2: 0.5625, 7: 0.225, 6: 0.2125}\n",
      "{7: 0.4125, 2: 0.3875, 6: 0.1875, 4: 0.0125}\n",
      "gun\n",
      "{7: 0.3375, 4: 0.2125, 3: 0.2, 6: 0.1, 5: 0.0875, 2: 0.0625}\n",
      "{2: 0.375, 6: 0.2375, 7: 0.225, 5: 0.1625}\n",
      "{7: 0.575, 2: 0.2625, 6: 0.1125, 5: 0.05}\n",
      "{7: 0.5875, 6: 0.1625, 2: 0.15, 5: 0.1}\n",
      "hair\n",
      "{7: 0.3875, 4: 0.2, 5: 0.1875, 3: 0.1375, 6: 0.05, 2: 0.0375}\n",
      "{6: 0.3875, 2: 0.2375, 7: 0.225, 5: 0.1125, 4: 0.0375}\n",
      "{5: 0.325, 2: 0.2875, 6: 0.225, 7: 0.1625}\n",
      "{5: 0.425, 6: 0.25, 2: 0.2375, 7: 0.0875}\n",
      "listen\n",
      "{7: 0.675, 4: 0.1625, 6: 0.1, 5: 0.0375, 2: 0.025}\n",
      "{6: 0.325, 5: 0.3125, 7: 0.2125, 2: 0.15}\n",
      "{4: 0.35, 6: 0.3125, 2: 0.2, 5: 0.1375}\n",
      "{2: 0.35, 7: 0.2625, 5: 0.2375, 6: 0.15}\n",
      "pointhigh\n",
      "{4: 0.4, 7: 0.3875, 3: 0.125, 5: 0.075, 2: 0.0125}\n",
      "{6: 0.6625, 5: 0.175, 2: 0.1125, 7: 0.05}\n",
      "{2: 0.3625, 5: 0.275, 6: 0.2625, 7: 0.075, 4: 0.025}\n",
      "{6: 0.575, 5: 0.3125, 7: 0.0875, 2: 0.025}\n",
      "sidepump\n",
      "{7: 0.5, 4: 0.2625, 5: 0.1, 2: 0.0625, 3: 0.05, 6: 0.025}\n",
      "{7: 0.35, 2: 0.3125, 6: 0.3, 5: 0.0375}\n",
      "{2: 0.625, 6: 0.15, 7: 0.125, 5: 0.0625, 4: 0.0375}\n",
      "{2: 0.3875, 6: 0.3375, 7: 0.2625, 4: 0.0125}\n",
      "wipetable\n",
      "{7: 0.6625, 3: 0.2625, 5: 0.0625, 2: 0.0125}\n",
      "{2: 0.35, 7: 0.35, 6: 0.3}\n",
      "{6: 0.525, 2: 0.325, 7: 0.15}\n",
      "{6: 0.7125, 2: 0.25, 7: 0.0375}\n",
      "Phase: 5\n",
      "dab\n",
      "{7: 0.675, 4: 0.1625, 5: 0.1125, 6: 0.0375, 2: 0.0125}\n",
      "{6: 0.525, 5: 0.3, 2: 0.125, 7: 0.05}\n",
      "{7: 0.2875, 2: 0.2625, 5: 0.225, 6: 0.1875, 4: 0.0375}\n",
      "{6: 0.375, 2: 0.3, 7: 0.2375, 5: 0.0875}\n",
      "elbowkick\n",
      "{7: 0.4125, 3: 0.25, 4: 0.15, 5: 0.075, 6: 0.0625, 2: 0.05}\n",
      "{7: 0.4, 2: 0.275, 6: 0.25, 5: 0.075}\n",
      "{7: 0.5375, 2: 0.2375, 6: 0.225}\n",
      "{2: 0.4875, 7: 0.35, 6: 0.15, 4: 0.0125}\n",
      "gun\n",
      "{7: 0.4125, 3: 0.1875, 4: 0.1625, 6: 0.125, 5: 0.075, 2: 0.0375}\n",
      "{2: 0.3125, 6: 0.275, 7: 0.2625, 5: 0.15}\n",
      "{7: 0.425, 2: 0.2875, 5: 0.15, 6: 0.1375}\n",
      "{7: 0.6125, 5: 0.1875, 6: 0.15, 2: 0.05}\n",
      "hair\n",
      "{4: 0.3125, 7: 0.3, 3: 0.1875, 6: 0.0875, 5: 0.0625, 2: 0.05}\n",
      "{6: 0.3375, 7: 0.2625, 2: 0.2, 5: 0.1875, 4: 0.0125}\n",
      "{5: 0.3875, 6: 0.275, 2: 0.275, 7: 0.0625}\n",
      "{6: 0.375, 2: 0.2875, 5: 0.2875, 7: 0.05}\n",
      "listen\n",
      "{7: 0.7875, 6: 0.1125, 4: 0.0875, 2: 0.0125}\n",
      "{6: 0.35, 7: 0.35, 5: 0.1625, 2: 0.1375}\n",
      "{6: 0.5, 2: 0.2, 4: 0.175, 5: 0.1125, 3: 0.0125}\n",
      "{2: 0.325, 7: 0.3125, 5: 0.2, 6: 0.1625}\n",
      "pointhigh\n",
      "{4: 0.425, 7: 0.3125, 5: 0.2, 3: 0.0625}\n",
      "{6: 0.5125, 5: 0.275, 2: 0.1375, 7: 0.075}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 0.475, 5: 0.3625, 6: 0.1375, 7: 0.025}\n",
      "{6: 0.4625, 5: 0.4125, 2: 0.125}\n",
      "sidepump\n",
      "{7: 0.4, 4: 0.35, 3: 0.1, 2: 0.0875, 5: 0.05, 6: 0.0125}\n",
      "{2: 0.475, 6: 0.3125, 7: 0.1875, 4: 0.025}\n",
      "{2: 0.4625, 6: 0.2375, 7: 0.175, 5: 0.1125, 4: 0.0125}\n",
      "{2: 0.675, 7: 0.2375, 6: 0.0625, 5: 0.0125, 4: 0.0125}\n",
      "wipetable\n",
      "{7: 0.6375, 3: 0.275, 2: 0.05, 5: 0.0375}\n",
      "{6: 0.3875, 7: 0.325, 2: 0.2875}\n",
      "{6: 0.5125, 2: 0.275, 7: 0.2125}\n",
      "{6: 0.65, 2: 0.325, 7: 0.025}\n",
      "Phase: 6\n",
      "dab\n",
      "{7: 0.5375, 5: 0.2125, 4: 0.1375, 6: 0.1125}\n",
      "{6: 0.5625, 5: 0.3, 7: 0.1, 2: 0.025, 4: 0.0125}\n",
      "{2: 0.275, 7: 0.275, 6: 0.2375, 5: 0.15, 4: 0.0625}\n",
      "{7: 0.325, 2: 0.2875, 6: 0.275, 5: 0.1125}\n",
      "elbowkick\n",
      "{7: 0.5, 3: 0.2125, 4: 0.1, 5: 0.0875, 6: 0.075, 2: 0.025}\n",
      "{6: 0.35, 2: 0.3375, 7: 0.2125, 5: 0.1}\n",
      "{2: 0.5, 7: 0.3125, 6: 0.175, 4: 0.0125}\n",
      "{2: 0.45, 7: 0.3375, 6: 0.2, 4: 0.0125}\n",
      "gun\n",
      "{7: 0.4125, 3: 0.2, 4: 0.175, 6: 0.125, 2: 0.05, 5: 0.0375}\n",
      "{2: 0.3, 6: 0.2875, 7: 0.25, 5: 0.1625}\n",
      "{7: 0.4375, 2: 0.3125, 5: 0.15, 6: 0.1}\n",
      "{7: 0.3125, 5: 0.275, 6: 0.2125, 2: 0.2}\n",
      "hair\n",
      "{7: 0.3125, 5: 0.1875, 4: 0.175, 3: 0.1375, 6: 0.125, 2: 0.0625}\n",
      "{6: 0.3375, 2: 0.2125, 5: 0.2125, 7: 0.2, 4: 0.0375}\n",
      "{2: 0.35, 5: 0.325, 6: 0.2625, 7: 0.0625}\n",
      "{6: 0.3875, 5: 0.3, 2: 0.2375, 7: 0.075}\n",
      "listen\n",
      "{7: 0.8375, 4: 0.125, 5: 0.0125, 2: 0.0125, 6: 0.0125}\n",
      "{6: 0.3375, 5: 0.275, 7: 0.25, 2: 0.1375}\n",
      "{2: 0.3625, 6: 0.325, 5: 0.1625, 4: 0.15}\n",
      "{2: 0.3375, 7: 0.2625, 5: 0.225, 6: 0.175}\n",
      "pointhigh\n",
      "{4: 0.525, 7: 0.35, 5: 0.1125, 2: 0.0125}\n",
      "{6: 0.55, 5: 0.2125, 2: 0.1625, 7: 0.075}\n",
      "{2: 0.3625, 5: 0.35, 6: 0.2, 7: 0.075, 4: 0.0125}\n",
      "{6: 0.4875, 5: 0.4, 2: 0.075, 7: 0.0375}\n",
      "sidepump\n",
      "{4: 0.6375, 7: 0.25, 5: 0.05, 3: 0.05, 2: 0.0125}\n",
      "{2: 0.5375, 6: 0.225, 7: 0.1375, 5: 0.1}\n",
      "{2: 0.7875, 6: 0.175, 7: 0.025, 4: 0.0125}\n",
      "{7: 0.4375, 6: 0.3, 2: 0.25, 4: 0.0125}\n",
      "wipetable\n",
      "{7: 0.6, 3: 0.3, 5: 0.1}\n",
      "{6: 0.4, 2: 0.3, 7: 0.3}\n",
      "{6: 0.5375, 2: 0.2875, 7: 0.175}\n",
      "{6: 0.6875, 2: 0.3, 7: 0.0125}\n",
      "Phase: 7\n",
      "dab\n",
      "{7: 0.4875, 4: 0.225, 5: 0.1625, 6: 0.125}\n",
      "{6: 0.5875, 5: 0.3, 7: 0.0875, 2: 0.025}\n",
      "{7: 0.2875, 5: 0.275, 6: 0.225, 2: 0.1625, 4: 0.05}\n",
      "{6: 0.3375, 7: 0.2875, 5: 0.2125, 2: 0.1625}\n",
      "elbowkick\n",
      "{7: 0.3625, 3: 0.3375, 4: 0.1375, 6: 0.075, 5: 0.075, 2: 0.0125}\n",
      "{2: 0.3625, 7: 0.325, 6: 0.275, 5: 0.0375}\n",
      "{2: 0.5375, 7: 0.3625, 6: 0.1}\n",
      "{2: 0.45, 7: 0.3625, 6: 0.1875}\n",
      "gun\n",
      "{7: 0.6125, 3: 0.1125, 4: 0.1125, 6: 0.0625, 5: 0.05, 2: 0.05}\n",
      "{2: 0.3125, 6: 0.2875, 7: 0.2375, 5: 0.1625}\n",
      "{7: 0.4875, 2: 0.275, 6: 0.125, 5: 0.1125}\n",
      "{7: 0.2875, 5: 0.275, 6: 0.25, 2: 0.1875}\n",
      "hair\n",
      "{4: 0.3125, 7: 0.3125, 5: 0.1625, 3: 0.15, 2: 0.0375, 6: 0.025}\n",
      "{6: 0.4625, 2: 0.2625, 7: 0.2125, 5: 0.05, 4: 0.0125}\n",
      "{5: 0.375, 6: 0.3125, 2: 0.225, 7: 0.0875}\n",
      "{2: 0.325, 6: 0.3125, 5: 0.2875, 7: 0.075}\n",
      "listen\n",
      "{7: 0.825, 6: 0.0875, 4: 0.075, 5: 0.0125}\n",
      "{5: 0.2875, 6: 0.275, 7: 0.2625, 2: 0.175}\n",
      "{6: 0.4125, 2: 0.2625, 4: 0.2125, 5: 0.1125}\n",
      "{2: 0.325, 7: 0.3, 5: 0.2, 6: 0.175}\n",
      "pointhigh\n",
      "{7: 0.4375, 4: 0.325, 5: 0.175, 3: 0.0625}\n",
      "{6: 0.5875, 5: 0.2375, 7: 0.0875, 2: 0.0875}\n",
      "{2: 0.4625, 6: 0.2125, 5: 0.2, 7: 0.125}\n",
      "{5: 0.5, 6: 0.4125, 7: 0.075, 2: 0.0125}\n",
      "sidepump\n",
      "{4: 0.5875, 7: 0.275, 3: 0.0625, 5: 0.05, 2: 0.025}\n",
      "{2: 0.325, 6: 0.3125, 7: 0.275, 5: 0.0625, 4: 0.025}\n",
      "{2: 0.6875, 6: 0.2625, 4: 0.025, 7: 0.025}\n",
      "{6: 0.4, 2: 0.3125, 7: 0.2625, 4: 0.0125, 5: 0.0125}\n",
      "wipetable\n",
      "{7: 0.6875, 3: 0.3, 5: 0.0125}\n",
      "{6: 0.4125, 7: 0.35, 2: 0.2375}\n",
      "{6: 0.4, 2: 0.3875, 7: 0.2125}\n",
      "{6: 0.775, 2: 0.225}\n",
      "Phase: 8\n",
      "dab\n",
      "{7: 0.6, 4: 0.175, 5: 0.125, 6: 0.1}\n",
      "{6: 0.5375, 5: 0.3375, 7: 0.075, 2: 0.05}\n",
      "{7: 0.4, 2: 0.2625, 5: 0.1875, 6: 0.125, 4: 0.025}\n",
      "{6: 0.375, 7: 0.275, 5: 0.2125, 2: 0.1375}\n",
      "elbowkick\n",
      "{7: 0.3375, 3: 0.3, 4: 0.125, 2: 0.0875, 6: 0.075, 5: 0.075}\n",
      "{2: 0.4875, 6: 0.2125, 7: 0.2125, 5: 0.0875}\n",
      "{7: 0.5, 2: 0.3125, 6: 0.1875}\n",
      "{7: 0.4, 2: 0.4, 6: 0.2}\n",
      "gun\n",
      "{7: 0.6375, 3: 0.125, 4: 0.1125, 5: 0.0875, 6: 0.025, 2: 0.0125}\n",
      "{6: 0.3125, 2: 0.2625, 7: 0.2625, 5: 0.1625}\n",
      "{7: 0.4875, 2: 0.35, 5: 0.1, 6: 0.0625}\n",
      "{7: 0.4875, 5: 0.2625, 2: 0.175, 6: 0.075}\n",
      "hair\n",
      "{7: 0.45, 4: 0.2, 5: 0.1625, 3: 0.1, 6: 0.05, 2: 0.0375}\n",
      "{6: 0.3625, 2: 0.3125, 5: 0.1875, 7: 0.1375}\n",
      "{5: 0.4125, 6: 0.3625, 2: 0.2, 7: 0.025}\n",
      "{5: 0.5, 6: 0.2625, 2: 0.1875, 7: 0.05}\n",
      "listen\n",
      "{7: 0.6875, 4: 0.125, 6: 0.1, 5: 0.0625, 3: 0.0125, 2: 0.0125}\n",
      "{6: 0.4125, 7: 0.2625, 5: 0.1875, 2: 0.1375}\n",
      "{6: 0.3875, 4: 0.275, 2: 0.2375, 5: 0.0875, 3: 0.0125}\n",
      "{2: 0.375, 7: 0.2375, 5: 0.2125, 6: 0.175}\n",
      "pointhigh\n",
      "{7: 0.425, 4: 0.325, 5: 0.175, 6: 0.05, 3: 0.025}\n",
      "{6: 0.4875, 5: 0.325, 2: 0.1375, 7: 0.05}\n",
      "{2: 0.45, 6: 0.2375, 7: 0.1625, 5: 0.15}\n",
      "{6: 0.475, 5: 0.3875, 7: 0.0875, 2: 0.05}\n",
      "sidepump\n",
      "{4: 0.4, 7: 0.275, 5: 0.1375, 3: 0.125, 2: 0.0625}\n",
      "{2: 0.3625, 7: 0.3125, 6: 0.2875, 5: 0.0375}\n",
      "{2: 0.675, 6: 0.275, 5: 0.05}\n",
      "{7: 0.475, 6: 0.2375, 2: 0.2, 5: 0.075, 4: 0.0125}\n",
      "wipetable\n",
      "{7: 0.6625, 3: 0.2625, 5: 0.075}\n",
      "{6: 0.475, 7: 0.275, 2: 0.25}\n",
      "{6: 0.475, 2: 0.4, 7: 0.125}\n",
      "{6: 0.6625, 2: 0.3125, 7: 0.025}\n",
      "Phase: 9\n",
      "dab\n",
      "{7: 0.575, 5: 0.2, 4: 0.1125, 6: 0.1, 2: 0.0125}\n",
      "{6: 0.525, 5: 0.375, 7: 0.0625, 2: 0.0375}\n",
      "{6: 0.35, 5: 0.275, 2: 0.225, 7: 0.1375, 4: 0.0125}\n",
      "{2: 0.3875, 6: 0.2875, 7: 0.2375, 5: 0.0875}\n",
      "elbowkick\n",
      "{3: 0.3875, 7: 0.3375, 4: 0.15, 2: 0.05, 5: 0.0375, 6: 0.0375}\n",
      "{2: 0.375, 7: 0.375, 6: 0.225, 5: 0.025}\n",
      "{7: 0.45, 2: 0.3875, 6: 0.1625}\n",
      "{2: 0.45, 7: 0.4, 6: 0.15}\n",
      "gun\n",
      "{7: 0.4625, 4: 0.1625, 3: 0.1375, 6: 0.1375, 2: 0.05, 5: 0.05}\n",
      "{6: 0.2625, 7: 0.2625, 2: 0.25, 5: 0.225}\n",
      "{7: 0.475, 2: 0.3375, 6: 0.1, 5: 0.0875}\n",
      "{7: 0.6625, 6: 0.2125, 2: 0.125}\n",
      "hair\n",
      "{7: 0.3125, 4: 0.25, 3: 0.1875, 5: 0.15, 6: 0.0625, 2: 0.0375}\n",
      "{6: 0.4625, 7: 0.3, 2: 0.1625, 5: 0.0625, 4: 0.0125}\n",
      "{6: 0.4125, 5: 0.275, 2: 0.225, 7: 0.0875}\n",
      "{5: 0.35, 6: 0.35, 2: 0.3}\n",
      "listen\n",
      "{7: 0.6625, 6: 0.1375, 4: 0.125, 5: 0.05, 2: 0.025}\n",
      "{5: 0.3375, 6: 0.325, 7: 0.175, 2: 0.1625}\n",
      "{6: 0.3625, 4: 0.275, 2: 0.225, 5: 0.0875, 3: 0.05}\n",
      "{2: 0.3125, 7: 0.3, 5: 0.25, 6: 0.1375}\n",
      "pointhigh\n",
      "{7: 0.3875, 4: 0.3375, 5: 0.1625, 3: 0.075, 6: 0.025, 2: 0.0125}\n",
      "{6: 0.6625, 5: 0.1625, 2: 0.1, 7: 0.075}\n",
      "{2: 0.4125, 6: 0.2625, 5: 0.25, 7: 0.075}\n",
      "{5: 0.55, 6: 0.3375, 7: 0.0625, 2: 0.0375, 4: 0.0125}\n",
      "sidepump\n",
      "{4: 0.4125, 7: 0.375, 5: 0.0875, 3: 0.075, 2: 0.05}\n",
      "{2: 0.5125, 6: 0.3, 7: 0.1625, 5: 0.025}\n",
      "{2: 0.6, 6: 0.3125, 4: 0.05, 5: 0.025, 7: 0.0125}\n",
      "{2: 0.5875, 7: 0.2875, 6: 0.125}\n",
      "wipetable\n",
      "{7: 0.5, 3: 0.375, 5: 0.1, 2: 0.025}\n",
      "{6: 0.4375, 7: 0.3625, 2: 0.2}\n",
      "{6: 0.55, 2: 0.35, 7: 0.1}\n",
      "{6: 0.6875, 2: 0.3125}\n",
      "Phase: 10\n",
      "dab\n",
      "{7: 0.525, 5: 0.2, 4: 0.2, 6: 0.075}\n",
      "{6: 0.575, 5: 0.2125, 7: 0.125, 2: 0.0875}\n",
      "{5: 0.325, 7: 0.325, 6: 0.2125, 2: 0.125, 4: 0.0125}\n",
      "{2: 0.375, 6: 0.325, 7: 0.2625, 5: 0.0375}\n",
      "elbowkick\n",
      "{7: 0.4, 3: 0.35, 4: 0.1625, 5: 0.0625, 6: 0.025}\n",
      "{2: 0.5625, 6: 0.2125, 7: 0.15, 5: 0.075}\n",
      "{2: 0.45, 7: 0.425, 6: 0.125}\n",
      "{7: 0.5, 2: 0.3, 6: 0.1625, 5: 0.0375}\n",
      "gun\n",
      "{7: 0.3375, 3: 0.25, 4: 0.2125, 5: 0.0875, 6: 0.075, 2: 0.0375}\n",
      "{2: 0.3375, 6: 0.2625, 7: 0.2375, 5: 0.1625}\n",
      "{2: 0.4125, 7: 0.375, 5: 0.1125, 6: 0.1}\n",
      "{7: 0.45, 5: 0.25, 2: 0.1875, 6: 0.1125}\n",
      "hair\n",
      "{4: 0.3, 5: 0.2, 7: 0.1875, 3: 0.175, 6: 0.1, 2: 0.0375}\n",
      "{6: 0.4125, 7: 0.25, 2: 0.2, 5: 0.1375}\n",
      "{5: 0.4375, 2: 0.375, 6: 0.15, 7: 0.0375}\n",
      "{6: 0.375, 5: 0.35, 2: 0.175, 7: 0.1}\n",
      "listen\n",
      "{7: 0.6875, 4: 0.1, 5: 0.075, 6: 0.075, 3: 0.05, 2: 0.0125}\n",
      "{6: 0.4, 7: 0.3125, 5: 0.175, 2: 0.1125}\n",
      "{2: 0.3625, 6: 0.3, 4: 0.2125, 5: 0.0875, 3: 0.0375}\n",
      "{2: 0.35, 7: 0.25, 5: 0.225, 6: 0.175}\n",
      "pointhigh\n",
      "{4: 0.5125, 7: 0.325, 5: 0.0875, 3: 0.075}\n",
      "{6: 0.475, 5: 0.3125, 2: 0.1625, 7: 0.05}\n",
      "{2: 0.4, 5: 0.275, 6: 0.175, 7: 0.15}\n",
      "{6: 0.55, 5: 0.3875, 2: 0.0625}\n",
      "sidepump\n",
      "{4: 0.5125, 7: 0.2625, 5: 0.1125, 2: 0.0625, 3: 0.05}\n",
      "{2: 0.475, 6: 0.3625, 7: 0.1625}\n",
      "{2: 0.85, 6: 0.125, 4: 0.025}\n",
      "{6: 0.4125, 2: 0.2875, 7: 0.225, 5: 0.05, 4: 0.025}\n",
      "wipetable\n",
      "{7: 0.6125, 3: 0.3125, 5: 0.05, 2: 0.025}\n",
      "{6: 0.4375, 7: 0.3375, 2: 0.225}\n",
      "{6: 0.525, 2: 0.3625, 7: 0.1125}\n",
      "{6: 0.625, 2: 0.3375, 7: 0.0375}\n",
      "Phase: 11\n",
      "dab\n",
      "{7: 0.5, 4: 0.1875, 5: 0.175, 6: 0.1125, 3: 0.025}\n",
      "{5: 0.3875, 6: 0.325, 7: 0.2125, 2: 0.0625, 4: 0.0125}\n",
      "{2: 0.3, 7: 0.2875, 6: 0.2, 5: 0.1375, 4: 0.075}\n",
      "{7: 0.3625, 2: 0.3125, 6: 0.175, 5: 0.15}\n",
      "elbowkick\n",
      "{7: 0.4125, 3: 0.3, 4: 0.125, 6: 0.075, 5: 0.0625, 2: 0.025}\n",
      "{7: 0.3625, 2: 0.2875, 6: 0.275, 5: 0.075}\n",
      "{7: 0.4125, 2: 0.3625, 6: 0.225}\n",
      "{7: 0.425, 2: 0.375, 6: 0.125, 5: 0.0625, 4: 0.0125}\n",
      "gun\n",
      "{7: 0.5, 3: 0.2125, 4: 0.15, 5: 0.05, 2: 0.05, 6: 0.0375}\n",
      "{7: 0.325, 6: 0.2875, 5: 0.2125, 2: 0.175}\n",
      "{7: 0.35, 2: 0.3375, 5: 0.225, 6: 0.0875}\n",
      "{2: 0.375, 5: 0.35, 7: 0.2375, 6: 0.0375}\n",
      "hair\n",
      "{7: 0.35, 4: 0.2, 5: 0.175, 3: 0.175, 2: 0.075, 6: 0.025}\n",
      "{6: 0.425, 2: 0.2125, 7: 0.175, 5: 0.1625, 4: 0.025}\n",
      "{5: 0.3625, 2: 0.3125, 6: 0.2625, 7: 0.0625}\n",
      "{6: 0.425, 2: 0.275, 5: 0.225, 7: 0.075}\n",
      "listen\n",
      "{7: 0.65, 4: 0.2125, 5: 0.0625, 3: 0.0375, 6: 0.025, 2: 0.0125}\n",
      "{6: 0.3125, 7: 0.3125, 5: 0.2625, 2: 0.1125}\n",
      "{6: 0.4375, 2: 0.2375, 5: 0.175, 4: 0.15}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{7: 0.3875, 2: 0.3125, 5: 0.1625, 6: 0.1375}\n",
      "pointhigh\n",
      "{4: 0.425, 7: 0.2875, 5: 0.175, 3: 0.075, 6: 0.0375}\n",
      "{6: 0.6125, 5: 0.2, 2: 0.1125, 7: 0.075}\n",
      "{2: 0.4, 6: 0.2375, 5: 0.2375, 7: 0.125}\n",
      "{5: 0.55, 6: 0.3625, 7: 0.0875}\n",
      "sidepump\n",
      "{4: 0.5625, 7: 0.3125, 5: 0.05, 2: 0.0375, 3: 0.0375}\n",
      "{2: 0.5875, 6: 0.2, 7: 0.175, 4: 0.0375}\n",
      "{2: 0.675, 6: 0.2625, 7: 0.0375, 5: 0.025}\n",
      "{2: 0.3, 7: 0.2625, 6: 0.2625, 5: 0.1625, 4: 0.0125}\n",
      "wipetable\n",
      "{7: 0.7125, 3: 0.25, 5: 0.0375}\n",
      "{6: 0.425, 7: 0.3, 2: 0.275}\n",
      "{6: 0.5, 2: 0.325, 7: 0.175}\n",
      "{6: 0.65, 2: 0.35}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "dances = ['dab', 'elbowkick', 'gun', 'hair', 'listen', 'pointhigh', 'sidepump', 'wipetable']\n",
    "# dances = ['gun', 'hair', 'sidepump']\n",
    "# dances = ['elbowkick', 'pointhigh', 'wipetable']\n",
    "persons = ['kelvin', 'guiyong', 'xiaoxue', 'john']\n",
    "beetles = ['1', '2']\n",
    "\n",
    "test_range = 12\n",
    "leap = 80\n",
    "truth, total, skipped = 0,0,0\n",
    "for i in range(0,0+test_range):\n",
    "    print(\"Phase:\", i)\n",
    "    start, end = i * leap, i * leap + leap\n",
    "    for d in dances:\n",
    "        print(d)\n",
    "        df_full = pd.DataFrame()\n",
    "        collection = [np.array([]) for x in range(16)]\n",
    "        j = 0\n",
    "        for p in persons:\n",
    "            for b in beetles:\n",
    "                if b == '1':\n",
    "                    continue\n",
    "                move_json = 'collected_data/' + d + b + '_' + p + '.json'\n",
    "                with open(move_json) as f:\n",
    "                    x = json.load(f)\n",
    "                x = pd.DataFrame.from_dict(x)[start:end]\n",
    "                df_target = torch.from_numpy(np.array(x))\n",
    "                df_target = df_target\n",
    "                output = clf.predict(df_target)\n",
    "                proba_dict = {}\n",
    "\n",
    "                for x in output:\n",
    "                    x = int(x)\n",
    "                    if x not in proba_dict:\n",
    "                        proba_dict[x] = 1\n",
    "                    else:\n",
    "                        proba_dict[x] += 1\n",
    "                for k in proba_dict.keys():\n",
    "                    proba_dict[k] /= len(output)\n",
    "\n",
    "                print(dict(sorted(proba_dict.items(), key=lambda item: -item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "df must be a DataFrame or a dict of DataFrames. See https://tsfresh.readthedocs.io/en/latest/text/data_formats.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-75ef3cbb39a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtsfresh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mComprehensiveFCParameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msettings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mComprehensiveFCParameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_fc_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tsfresh\\feature_extraction\\extraction.py\u001b[0m in \u001b[0;36mextract_features\u001b[1;34m(timeseries_container, default_fc_parameters, kind_to_fc_parameters, column_id, column_sort, column_kind, column_value, chunksize, n_jobs, show_warnings, disable_progressbar, impute_function, profile, profiling_filename, profiling_sorting, distributor, pivot)\u001b[0m\n\u001b[0;32m    159\u001b[0m                                 \u001b[0mkind_to_fc_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind_to_fc_parameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m                                 \u001b[0mdistributor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdistributor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m                                 pivot=pivot)\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;31m# Impute the result if requested\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tsfresh\\feature_extraction\\extraction.py\u001b[0m in \u001b[0;36m_do_extraction\u001b[1;34m(df, column_id, column_value, column_kind, column_sort, default_fc_parameters, kind_to_fc_parameters, n_jobs, chunk_size, disable_progressbar, show_warnings, distributor, pivot)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \"\"\"\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_tsdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_kind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_sort\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdistributor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tsfresh\\feature_extraction\\data.py\u001b[0m in \u001b[0;36mto_tsdata\u001b[1;34m(df, column_id, column_kind, column_value, column_sort)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         raise ValueError(\"df must be a DataFrame or a dict of DataFrames. \"\n\u001b[0m\u001b[0;32m    444\u001b[0m                          \"See https://tsfresh.readthedocs.io/en/latest/text/data_formats.html\")\n",
      "\u001b[1;31mValueError\u001b[0m: df must be a DataFrame or a dict of DataFrames. See https://tsfresh.readthedocs.io/en/latest/text/data_formats.html"
     ]
    }
   ],
   "source": [
    "from tsfresh.feature_extraction import extract_features\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters\n",
    "settings = ComprehensiveFCParameters()\n",
    "extract_features(dataset.X, default_fc_parameters=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
