{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dab1_guiyong.json', 'dab1_john.json', 'dab1_kelvin.json', 'dab1_xiaoxue.json', 'dab2_guiyong.json', 'dab2_john.json', 'dab2_kelvin.json', 'dab2_xiaoxue.json', 'dab2_yujie.json', 'elbowkick1_guiyong.json', 'elbowkick1_john.json', 'elbowkick1_kelvin.json', 'elbowkick1_xiaoxue.json', 'elbowkick2_guiyong.json', 'elbowkick2_john.json', 'elbowkick2_kelvin.json', 'elbowkick2_xiaoxue.json', 'elbowkick2_yujie.json', 'gun1_guiyong.json', 'gun1_john.json', 'gun1_kelvin.json', 'gun1_xiaoxue.json', 'gun2_guiyong.json', 'gun2_john.json', 'gun2_kelvin.json', 'gun2_xiaoxue.json', 'gun2_yujie.json', 'hair1_guiyong.json', 'hair1_john.json', 'hair1_kelvin.json', 'hair1_xiaoxue.json', 'hair2_guiyong.json', 'hair2_john.json', 'hair2_kelvin.json', 'hair2_xiaoxue.json', 'hair2_yujie.json', 'listen1_guiyong.json', 'listen1_john.json', 'listen1_kelvin.json', 'listen1_xiaoxue.json', 'listen2_guiyong.json', 'listen2_john.json', 'listen2_kelvin.json', 'listen2_xiaoxue.json', 'listen2_yujie.json', 'pointhigh1_guiyong.json', 'pointhigh1_john.json', 'pointhigh1_kelvin.json', 'pointhigh1_xiaoxue.json', 'pointhigh2_guiyong.json', 'pointhigh2_john.json', 'pointhigh2_kelvin.json', 'pointhigh2_xiaoxue.json', 'pointhigh2_yujie.json', 'sidepump1_guiyong.json', 'sidepump1_john.json', 'sidepump1_kelvin.json', 'sidepump1_xiaoxue.json', 'sidepump2_guiyong.json', 'sidepump2_john.json', 'sidepump2_kelvin.json', 'sidepump2_xiaoxue.json', 'sidepump2_yujie.json', 'wipetable1_guiyong.json', 'wipetable1_john.json', 'wipetable1_kelvin.json', 'wipetable1_xiaoxue.json', 'wipetable2_guiyong.json', 'wipetable2_john.json', 'wipetable2_kelvin.json', 'wipetable2_xiaoxue.json', 'wipetable2_yujie.json']\n",
      "{0: 'dab1_guiyong', 1: 'dab1_john', 2: 'dab1_kelvin', 3: 'dab1_xiaoxue', 4: 'dab2_guiyong', 5: 'dab2_john', 6: 'dab2_kelvin', 7: 'dab2_xiaoxue', 8: 'dab2_yujie', 9: 'elbowkick1_guiyong', 10: 'elbowkick1_john', 11: 'elbowkick1_kelvin', 12: 'elbowkick1_xiaoxue', 13: 'elbowkick2_guiyong', 14: 'elbowkick2_john', 15: 'elbowkick2_kelvin', 16: 'elbowkick2_xiaoxue', 17: 'elbowkick2_yujie', 18: 'gun1_guiyong', 19: 'gun1_john', 20: 'gun1_kelvin', 21: 'gun1_xiaoxue', 22: 'gun2_guiyong', 23: 'gun2_john', 24: 'gun2_kelvin', 25: 'gun2_xiaoxue', 26: 'gun2_yujie', 27: 'hair1_guiyong', 28: 'hair1_john', 29: 'hair1_kelvin', 30: 'hair1_xiaoxue', 31: 'hair2_guiyong', 32: 'hair2_john', 33: 'hair2_kelvin', 34: 'hair2_xiaoxue', 35: 'hair2_yujie', 36: 'listen1_guiyong', 37: 'listen1_john', 38: 'listen1_kelvin', 39: 'listen1_xiaoxue', 40: 'listen2_guiyong', 41: 'listen2_john', 42: 'listen2_kelvin', 43: 'listen2_xiaoxue', 44: 'listen2_yujie', 45: 'pointhigh1_guiyong', 46: 'pointhigh1_john', 47: 'pointhigh1_kelvin', 48: 'pointhigh1_xiaoxue', 49: 'pointhigh2_guiyong', 50: 'pointhigh2_john', 51: 'pointhigh2_kelvin', 52: 'pointhigh2_xiaoxue', 53: 'pointhigh2_yujie', 54: 'sidepump1_guiyong', 55: 'sidepump1_john', 56: 'sidepump1_kelvin', 57: 'sidepump1_xiaoxue', 58: 'sidepump2_guiyong', 59: 'sidepump2_john', 60: 'sidepump2_kelvin', 61: 'sidepump2_xiaoxue', 62: 'sidepump2_yujie', 63: 'wipetable1_guiyong', 64: 'wipetable1_john', 65: 'wipetable1_kelvin', 66: 'wipetable1_xiaoxue', 67: 'wipetable2_guiyong', 68: 'wipetable2_john', 69: 'wipetable2_kelvin', 70: 'wipetable2_xiaoxue', 71: 'wipetable2_yujie'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, TimeSeriesSplit, cross_val_score\n",
    "\n",
    "import brevitas.nn as nn\n",
    "\n",
    "from config import *\n",
    "from classic_models import *\n",
    "from data_preprocessing import *\n",
    "from feature_extraction import *\n",
    "from helpers import *\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tslearn.preprocessing import TimeSeriesScalerMinMax\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_accel1</th>\n",
       "      <th>mean_accel2</th>\n",
       "      <th>mean_accel3</th>\n",
       "      <th>mean_gyro1</th>\n",
       "      <th>mean_gyro2</th>\n",
       "      <th>mean_gyro3</th>\n",
       "      <th>max_accel1</th>\n",
       "      <th>max_accel2</th>\n",
       "      <th>max_accel3</th>\n",
       "      <th>max_gyro1</th>\n",
       "      <th>...</th>\n",
       "      <th>var_coeff_gyro1</th>\n",
       "      <th>var_coeff_gyro2</th>\n",
       "      <th>var_coeff_gyro3</th>\n",
       "      <th>kurtosis_accel1</th>\n",
       "      <th>kurtosis_accel2</th>\n",
       "      <th>kurtosis_accel3</th>\n",
       "      <th>kurtosis_gyro1</th>\n",
       "      <th>kurtosis_gyro2</th>\n",
       "      <th>kurtosis_gyro3</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.595618</td>\n",
       "      <td>0.823941</td>\n",
       "      <td>0.415132</td>\n",
       "      <td>0.592886</td>\n",
       "      <td>-0.000262</td>\n",
       "      <td>0.126108</td>\n",
       "      <td>0.222181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555123</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>0.114960</td>\n",
       "      <td>0.129377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.205184</td>\n",
       "      <td>-0.346658</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.595657</td>\n",
       "      <td>0.825499</td>\n",
       "      <td>0.415132</td>\n",
       "      <td>0.592886</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.126178</td>\n",
       "      <td>0.222181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555123</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.114954</td>\n",
       "      <td>0.129377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.205113</td>\n",
       "      <td>-0.343758</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.595753</td>\n",
       "      <td>0.825499</td>\n",
       "      <td>0.415132</td>\n",
       "      <td>0.592886</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>0.126336</td>\n",
       "      <td>0.222181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556420</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.114928</td>\n",
       "      <td>0.129377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.204948</td>\n",
       "      <td>-0.336518</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.595612</td>\n",
       "      <td>0.825499</td>\n",
       "      <td>0.415132</td>\n",
       "      <td>0.592886</td>\n",
       "      <td>-0.000370</td>\n",
       "      <td>0.126122</td>\n",
       "      <td>0.222181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557717</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.114924</td>\n",
       "      <td>0.129377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.204882</td>\n",
       "      <td>-0.333833</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.593477</td>\n",
       "      <td>0.825499</td>\n",
       "      <td>0.415132</td>\n",
       "      <td>0.592886</td>\n",
       "      <td>-0.002925</td>\n",
       "      <td>0.123803</td>\n",
       "      <td>0.214461</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557717</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.114924</td>\n",
       "      <td>0.129377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.204882</td>\n",
       "      <td>-0.333833</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_accel1  mean_accel2  mean_accel3  mean_gyro1  mean_gyro2  mean_gyro3  \\\n",
       "0     0.595618     0.823941     0.415132    0.592886   -0.000262    0.126108   \n",
       "1     0.595657     0.825499     0.415132    0.592886    0.000656    0.126178   \n",
       "2     0.595753     0.825499     0.415132    0.592886   -0.000072    0.126336   \n",
       "3     0.595612     0.825499     0.415132    0.592886   -0.000370    0.126122   \n",
       "4     0.593477     0.825499     0.415132    0.592886   -0.002925    0.123803   \n",
       "\n",
       "   max_accel1  max_accel2  max_accel3  max_gyro1  ...  var_coeff_gyro1  \\\n",
       "0    0.222181         0.0         1.0        0.0  ...         0.555123   \n",
       "1    0.222181         0.0         1.0        0.0  ...         0.555123   \n",
       "2    0.222181         0.0         1.0        0.0  ...         0.556420   \n",
       "3    0.222181         0.0         1.0        0.0  ...         0.557717   \n",
       "4    0.214461         0.0         2.0        0.0  ...         0.557717   \n",
       "\n",
       "   var_coeff_gyro2  var_coeff_gyro3  kurtosis_accel1  kurtosis_accel2  \\\n",
       "0        -0.000178         0.114960         0.129377              0.0   \n",
       "1         0.000730         0.114954         0.129377              0.0   \n",
       "2         0.000049         0.114928         0.129377              0.0   \n",
       "3         0.000178         0.114924         0.129377              0.0   \n",
       "4         0.000049         0.114924         0.129377              0.0   \n",
       "\n",
       "   kurtosis_accel3  kurtosis_gyro1  kurtosis_gyro2  kurtosis_gyro3  tag  \n",
       "0              2.0           0.325        0.205184       -0.346658  0.0  \n",
       "1              2.0           0.275        0.205113       -0.343758  0.0  \n",
       "2              2.0           0.325        0.204948       -0.336518  0.0  \n",
       "3              2.0           0.350        0.204882       -0.333833  0.0  \n",
       "4              2.0           0.350        0.204882       -0.333833  0.0  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "df_train = pd.read_csv('out_5_train.csv')\n",
    "# df_train = df_train.iloc[:, list(range(21)) + [-1]]\n",
    "df_test = pd.read_csv('out_5_test.csv')\n",
    "# df_test = df_test.iloc[:, list(range(21)) + [-1]]\n",
    "df_train['tag'] = df_train['tag'].apply(lambda x: x-1)\n",
    "df_test['tag'] = df_test['tag'].apply(lambda x: x-1)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 39\n"
     ]
    }
   ],
   "source": [
    "print(window_size, overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            df_np = df.to_numpy()\n",
    "        self.X = df_np[:,:-1]\n",
    "        self.y = df_np[:,-1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get item by index\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        # returns length of data\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 8\n"
     ]
    }
   ],
   "source": [
    "dataset = FeatureDataset(df_train)\n",
    "D_in = 72 # df.shape[1]-1\n",
    "D_out = 8 # len(dances)\n",
    "print(D_in, D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_hidden, d_out):\n",
    "        super(MLP, self).__init__()\n",
    "        self.d_in = d_in\n",
    "\n",
    "        self.linear1 = nn.QuantLinear(d_in, d_hidden, bias=True)#, weight_bit_width=4)\n",
    "        self.linear2 = nn.QuantLinear(d_hidden, d_hidden, bias=True)#, weight_bit_width=4)\n",
    "        self.linear3 = nn.QuantLinear(d_hidden, d_out, bias=False)#, weight_bit_width=4)\n",
    "        \n",
    "        self.relu = torch.nn.ReL(p=0.1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X.view(-1, self.d_in)\n",
    "        X = self.linear1(X.float())\n",
    "        X = self.linear2(X)\n",
    "        X = self.linear3(X)\n",
    "        return torch.nn.functional.sigmoid(X)\n",
    "    \n",
    "    def load(self, model_path):\n",
    "        self.load_state_dict(torch.load(model_path))\n",
    "        self.eval()\n",
    "\n",
    "    def predict(self, X):\n",
    "        outputs = self(X.float())\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_hidden, d_out):\n",
    "        super(MLP, self).__init__()\n",
    "        self.d_in = d_in\n",
    "\n",
    "        self.linear1 = nn.QuantLinear(d_in, d_hidden, bias=True)\n",
    "        self.linear2 = nn.QuantLinear(d_hidden, d_hidden//4, bias=True)\n",
    "        self.linear3 = nn.QuantLinear(d_hidden//4, d_hidden//4, bias=True)\n",
    "        self.linear4 = nn.QuantLinear(d_hidden//4, d_hidden//8, bias=True)\n",
    "        self.linear5 = nn.QuantLinear(d_hidden//8, d_out, bias=False)\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(p=0.65)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = X.view(-1, self.d_in)\n",
    "        X = self.relu(self.linear1(X.float()))\n",
    "        X = self.dropout(X)\n",
    "        X = self.relu(self.linear2(X))\n",
    "        X = self.dropout(X)\n",
    "        X = self.relu(self.linear3(X))\n",
    "        X = self.dropout(X)\n",
    "        X = self.relu(self.linear4(X))\n",
    "        X = self.dropout(X)\n",
    "        X = self.linear5(X)\n",
    "        return torch.nn.functional.log_softmax(X, dim=1)\n",
    "    \n",
    "    def load(self, model_path):\n",
    "        self.load_state_dict(torch.load(model_path))\n",
    "        self.eval()\n",
    "\n",
    "    def predict(self, X):\n",
    "        outputs = self(X.float())\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_model(model, criterion, optimizer, X, y, num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # Store losses and accuracies accross epochs\n",
    "    losses, accuracies = dict(train=[], val=[]), dict(train=[], val=[])\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=15, max_train_size=1000)\n",
    "    kf = KFold(n_splits=50)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    confusion_matrix = torch.zeros(8, 8)\n",
    "\n",
    "    for i in range(1,num_epochs+1):\n",
    "        print('Epoch {}/{}'.format(i, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "        \n",
    "        # for fold, (train_index, test_index) in enumerate(tscv.split(X_train, y_train)):\n",
    "        for fold, (train_index, test_index) in enumerate(kf.split(X_train)):\n",
    "#             if len(train_index) > 500:\n",
    "#                 train_index = train_index[len(train_index)-500:]\n",
    "            ### Dividing data into folds\n",
    "            # print(train_index, test_index, len(X_train))\n",
    "            x_train_fold = X_train[train_index]\n",
    "            x_test_fold = X_train[test_index]\n",
    "            y_train_fold = y_train[train_index]\n",
    "            y_test_fold = y_train[test_index]\n",
    "\n",
    "            print('Train Index Length:', len(train_index), end='\\t\\t')\n",
    "            print('Test Index Length:', len(test_index), end='\\n\\n')\n",
    "\n",
    "            train = torch.utils.data.TensorDataset(torch.tensor(x_train_fold), torch.tensor(y_train_fold))\n",
    "            test = torch.utils.data.TensorDataset(torch.tensor(x_test_fold), torch.tensor(y_test_fold))\n",
    "            train_loader = torch.utils.data.DataLoader(train, batch_size = 50, shuffle = False)\n",
    "            test_loader = torch.utils.data.DataLoader(test, batch_size = 50, shuffle = False)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            for batch_index, (x_batch, y_batch) in enumerate(train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                y_pred = model(x_batch)\n",
    "                _, preds = torch.max(y_pred, 1)\n",
    "                for t, p in zip(y_batch.view(-1), preds.view(-1)):\n",
    "                        confusion_matrix[t.long(), p.long()] += 1\n",
    "                # print(y_pred.shape, y_batch.view(-1, 1).shape)\n",
    "                single_loss = criterion(y_pred, y_batch.long())\n",
    "                single_loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += single_loss.item() * x_batch.size(0)\n",
    "                running_corrects += torch.sum(preds == y_batch.data)\n",
    "            print('Fold No. {}/{}\\tEpoch {}/{}\\t'.format(fold + 1 , kf.get_n_splits(X_train), i, num_epochs), end='')\n",
    "            print(f'loss: {single_loss.item():10.8f}')\n",
    "            \n",
    "            nsamples = len(train_index)\n",
    "            epoch_loss = running_loss / nsamples\n",
    "            epoch_acc = running_corrects.double() / nsamples\n",
    "\n",
    "            losses[phase].append(epoch_loss)\n",
    "            accuracies[phase].append(epoch_acc)\n",
    "            print('{} Loss: {:.4f} Acc: {:.2f}%'.format(\n",
    "                    phase, epoch_loss, 100 * epoch_acc)\n",
    "            )\n",
    "            print()\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.2f}%'.format(100 * best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    print(confusion_matrix.diag()/confusion_matrix.sum(1))\n",
    "    return model, losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([70, 72])\n",
      "torch.Size([70])\n",
      "torch.Size([17, 70])\n",
      "torch.Size([17])\n",
      "torch.Size([17, 17])\n",
      "torch.Size([17])\n",
      "torch.Size([8, 17])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 8])\n",
      "Total number of parameters = 6831\n"
     ]
    }
   ],
   "source": [
    "model = MLP(D_in, 70, D_out)\n",
    "# model = MultiHead4MLP(D_in, D_out)\n",
    "# Explore the model\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "\n",
    "print(\"Total number of parameters =\", np.sum([np.prod(parameter.shape) for parameter in model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 1/50\tEpoch 1/10\tloss: 1.81977499\n",
      "val Loss: 1.9331 Acc: 26.97%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 2/50\tEpoch 1/10\tloss: 1.81197011\n",
      "val Loss: 1.9283 Acc: 27.48%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 3/50\tEpoch 1/10\tloss: 1.80621815\n",
      "val Loss: 1.9258 Acc: 27.35%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 4/50\tEpoch 1/10\tloss: 1.80384159\n",
      "val Loss: 1.9266 Acc: 27.35%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 5/50\tEpoch 1/10\tloss: 1.79919541\n",
      "val Loss: 1.9208 Acc: 27.74%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 6/50\tEpoch 1/10\tloss: 1.79428172\n",
      "val Loss: 1.9202 Acc: 27.48%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 7/50\tEpoch 1/10\tloss: 1.79001880\n",
      "val Loss: 1.9181 Acc: 27.87%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 8/50\tEpoch 1/10\tloss: 1.78638744\n",
      "val Loss: 1.9133 Acc: 28.13%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 9/50\tEpoch 1/10\tloss: 1.78173244\n",
      "val Loss: 1.9108 Acc: 28.52%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 10/50\tEpoch 1/10\tloss: 1.77737057\n",
      "val Loss: 1.9087 Acc: 28.52%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 11/50\tEpoch 1/10\tloss: 1.77330291\n",
      "val Loss: 1.9073 Acc: 28.52%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 12/50\tEpoch 1/10\tloss: 1.76722682\n",
      "val Loss: 1.9038 Acc: 28.52%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 13/50\tEpoch 1/10\tloss: 1.76409626\n",
      "val Loss: 1.9030 Acc: 28.13%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 14/50\tEpoch 1/10\tloss: 1.75904250\n",
      "val Loss: 1.8994 Acc: 29.29%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 15/50\tEpoch 1/10\tloss: 1.75646174\n",
      "val Loss: 1.9004 Acc: 29.03%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 16/50\tEpoch 1/10\tloss: 1.75022447\n",
      "val Loss: 1.8952 Acc: 29.94%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 17/50\tEpoch 1/10\tloss: 1.74551320\n",
      "val Loss: 1.8916 Acc: 29.94%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 18/50\tEpoch 1/10\tloss: 1.74227047\n",
      "val Loss: 1.8893 Acc: 29.81%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 19/50\tEpoch 1/10\tloss: 1.73658717\n",
      "val Loss: 1.8881 Acc: 29.03%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 20/50\tEpoch 1/10\tloss: 1.73202527\n",
      "val Loss: 1.8813 Acc: 29.94%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 21/50\tEpoch 1/10\tloss: 1.72722578\n",
      "val Loss: 1.8824 Acc: 30.58%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 22/50\tEpoch 1/10\tloss: 1.72425115\n",
      "val Loss: 1.8819 Acc: 30.45%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 23/50\tEpoch 1/10\tloss: 1.71905255\n",
      "val Loss: 1.8737 Acc: 30.58%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 24/50\tEpoch 1/10\tloss: 1.71520126\n",
      "val Loss: 1.8675 Acc: 30.84%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 25/50\tEpoch 1/10\tloss: 1.71001112\n",
      "val Loss: 1.8676 Acc: 30.84%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 26/50\tEpoch 1/10\tloss: 1.70460367\n",
      "val Loss: 1.8658 Acc: 30.71%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 27/50\tEpoch 1/10\tloss: 1.70148253\n",
      "val Loss: 1.8637 Acc: 31.23%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 28/50\tEpoch 1/10\tloss: 1.69627380\n",
      "val Loss: 1.8578 Acc: 31.35%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 29/50\tEpoch 1/10\tloss: 1.69209504\n",
      "val Loss: 1.8575 Acc: 30.97%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 30/50\tEpoch 1/10\tloss: 1.68707919\n",
      "val Loss: 1.8544 Acc: 31.48%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 31/50\tEpoch 1/10\tloss: 1.68285131\n",
      "val Loss: 1.8495 Acc: 31.48%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 32/50\tEpoch 1/10\tloss: 1.67776978\n",
      "val Loss: 1.8471 Acc: 31.10%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 33/50\tEpoch 1/10\tloss: 1.67541134\n",
      "val Loss: 1.8469 Acc: 31.48%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 34/50\tEpoch 1/10\tloss: 1.67056274\n",
      "val Loss: 1.8407 Acc: 31.87%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 35/50\tEpoch 1/10\tloss: 1.66764390\n",
      "val Loss: 1.8359 Acc: 31.61%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 36/50\tEpoch 1/10\tloss: 1.66447210\n",
      "val Loss: 1.8341 Acc: 32.00%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 37/50\tEpoch 1/10\tloss: 1.65800190\n",
      "val Loss: 1.8292 Acc: 31.74%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 38/50\tEpoch 1/10\tloss: 1.65302598\n",
      "val Loss: 1.8225 Acc: 32.00%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 39/50\tEpoch 1/10\tloss: 1.65024531\n",
      "val Loss: 1.8234 Acc: 31.87%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 40/50\tEpoch 1/10\tloss: 1.64448166\n",
      "val Loss: 1.8194 Acc: 31.74%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 41/50\tEpoch 1/10\tloss: 1.63930714\n",
      "val Loss: 1.8208 Acc: 32.00%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 42/50\tEpoch 1/10\tloss: 1.62702918\n",
      "val Loss: 1.8134 Acc: 32.47%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 43/50\tEpoch 1/10\tloss: 1.62173712\n",
      "val Loss: 1.8122 Acc: 32.86%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 44/50\tEpoch 1/10\tloss: 1.61775506\n",
      "val Loss: 1.8105 Acc: 32.22%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 45/50\tEpoch 1/10\tloss: 1.61438048\n",
      "val Loss: 1.8033 Acc: 32.86%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 46/50\tEpoch 1/10\tloss: 1.60982049\n",
      "val Loss: 1.7990 Acc: 32.73%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 47/50\tEpoch 1/10\tloss: 1.60584855\n",
      "val Loss: 1.8027 Acc: 32.35%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 48/50\tEpoch 1/10\tloss: 1.60257912\n",
      "val Loss: 1.7975 Acc: 32.73%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 49/50\tEpoch 1/10\tloss: 1.69070172\n",
      "val Loss: 1.7953 Acc: 32.09%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 50/50\tEpoch 1/10\tloss: 1.62045836\n",
      "val Loss: 1.7900 Acc: 32.86%\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 1/50\tEpoch 2/10\tloss: 1.60950315\n",
      "val Loss: 1.7837 Acc: 33.29%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 2/50\tEpoch 2/10\tloss: 1.60265076\n",
      "val Loss: 1.7789 Acc: 33.29%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 3/50\tEpoch 2/10\tloss: 1.59927464\n",
      "val Loss: 1.7754 Acc: 33.29%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 4/50\tEpoch 2/10\tloss: 1.59889257\n",
      "val Loss: 1.7781 Acc: 33.68%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 5/50\tEpoch 2/10\tloss: 1.59181106\n",
      "val Loss: 1.7677 Acc: 33.94%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 6/50\tEpoch 2/10\tloss: 1.58775115\n",
      "val Loss: 1.7682 Acc: 33.81%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 7/50\tEpoch 2/10\tloss: 1.58648968\n",
      "val Loss: 1.7659 Acc: 34.19%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 8/50\tEpoch 2/10\tloss: 1.58310795\n",
      "val Loss: 1.7601 Acc: 34.19%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 9/50\tEpoch 2/10\tloss: 1.58046889\n",
      "val Loss: 1.7578 Acc: 34.19%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 10/50\tEpoch 2/10\tloss: 1.57638824\n",
      "val Loss: 1.7557 Acc: 34.06%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 11/50\tEpoch 2/10\tloss: 1.57461071\n",
      "val Loss: 1.7542 Acc: 34.19%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 12/50\tEpoch 2/10\tloss: 1.57175004\n",
      "val Loss: 1.7474 Acc: 34.32%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 13/50\tEpoch 2/10\tloss: 1.56986237\n",
      "val Loss: 1.7448 Acc: 34.06%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 14/50\tEpoch 2/10\tloss: 1.56864536\n",
      "val Loss: 1.7444 Acc: 34.32%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 15/50\tEpoch 2/10\tloss: 1.56763995\n",
      "val Loss: 1.7493 Acc: 33.94%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 16/50\tEpoch 2/10\tloss: 1.56044650\n",
      "val Loss: 1.7407 Acc: 34.45%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 17/50\tEpoch 2/10\tloss: 1.56102300\n",
      "val Loss: 1.7347 Acc: 35.23%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 18/50\tEpoch 2/10\tloss: 1.56151974\n",
      "val Loss: 1.7337 Acc: 34.97%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold No. 19/50\tEpoch 2/10\tloss: 1.56127012\n",
      "val Loss: 1.7344 Acc: 35.10%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 20/50\tEpoch 2/10\tloss: 1.55729032\n",
      "val Loss: 1.7225 Acc: 35.35%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 21/50\tEpoch 2/10\tloss: 1.55306745\n",
      "val Loss: 1.7250 Acc: 35.35%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 22/50\tEpoch 2/10\tloss: 1.55465865\n",
      "val Loss: 1.7267 Acc: 34.97%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 23/50\tEpoch 2/10\tloss: 1.55036747\n",
      "val Loss: 1.7166 Acc: 34.84%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 24/50\tEpoch 2/10\tloss: 1.54867733\n",
      "val Loss: 1.7087 Acc: 35.48%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 25/50\tEpoch 2/10\tloss: 1.54667866\n",
      "val Loss: 1.7111 Acc: 35.35%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 26/50\tEpoch 2/10\tloss: 1.54330325\n",
      "val Loss: 1.7090 Acc: 35.10%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 27/50\tEpoch 2/10\tloss: 1.54340029\n",
      "val Loss: 1.7033 Acc: 35.61%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 28/50\tEpoch 2/10\tloss: 1.54179335\n",
      "val Loss: 1.7008 Acc: 35.35%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 29/50\tEpoch 2/10\tloss: 1.53956723\n",
      "val Loss: 1.7023 Acc: 35.35%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 30/50\tEpoch 2/10\tloss: 1.53883541\n",
      "val Loss: 1.6971 Acc: 36.00%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 31/50\tEpoch 2/10\tloss: 1.53425825\n",
      "val Loss: 1.6932 Acc: 36.13%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 32/50\tEpoch 2/10\tloss: 1.53188670\n",
      "val Loss: 1.6920 Acc: 35.74%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 33/50\tEpoch 2/10\tloss: 1.53134978\n",
      "val Loss: 1.6923 Acc: 36.39%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 34/50\tEpoch 2/10\tloss: 1.52896810\n",
      "val Loss: 1.6827 Acc: 35.74%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 35/50\tEpoch 2/10\tloss: 1.52862787\n",
      "val Loss: 1.6805 Acc: 36.77%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 36/50\tEpoch 2/10\tloss: 1.52526033\n",
      "val Loss: 1.6775 Acc: 37.03%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 37/50\tEpoch 2/10\tloss: 1.52303743\n",
      "val Loss: 1.6748 Acc: 36.77%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 38/50\tEpoch 2/10\tloss: 1.52159727\n",
      "val Loss: 1.6713 Acc: 36.65%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 39/50\tEpoch 2/10\tloss: 1.52111542\n",
      "val Loss: 1.6686 Acc: 37.03%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 40/50\tEpoch 2/10\tloss: 1.51866627\n",
      "val Loss: 1.6639 Acc: 36.39%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 41/50\tEpoch 2/10\tloss: 1.51546812\n",
      "val Loss: 1.6678 Acc: 36.26%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 42/50\tEpoch 2/10\tloss: 1.49391317\n",
      "val Loss: 1.6585 Acc: 37.37%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 43/50\tEpoch 2/10\tloss: 1.49222255\n",
      "val Loss: 1.6547 Acc: 37.50%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 44/50\tEpoch 2/10\tloss: 1.48991251\n",
      "val Loss: 1.6551 Acc: 36.98%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 45/50\tEpoch 2/10\tloss: 1.49034929\n",
      "val Loss: 1.6485 Acc: 37.37%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 46/50\tEpoch 2/10\tloss: 1.48910570\n",
      "val Loss: 1.6457 Acc: 37.24%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 47/50\tEpoch 2/10\tloss: 1.48451221\n",
      "val Loss: 1.6517 Acc: 36.73%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 48/50\tEpoch 2/10\tloss: 1.48655558\n",
      "val Loss: 1.6448 Acc: 37.76%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 49/50\tEpoch 2/10\tloss: 1.63042057\n",
      "val Loss: 1.6436 Acc: 36.98%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 50/50\tEpoch 2/10\tloss: 1.47868919\n",
      "val Loss: 1.6355 Acc: 38.02%\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 1/50\tEpoch 3/10\tloss: 1.50899029\n",
      "val Loss: 1.6311 Acc: 38.06%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 2/50\tEpoch 3/10\tloss: 1.49959123\n",
      "val Loss: 1.6263 Acc: 38.32%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 3/50\tEpoch 3/10\tloss: 1.50275815\n",
      "val Loss: 1.6232 Acc: 38.32%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 4/50\tEpoch 3/10\tloss: 1.50317478\n",
      "val Loss: 1.6288 Acc: 38.45%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 5/50\tEpoch 3/10\tloss: 1.49813080\n",
      "val Loss: 1.6140 Acc: 38.71%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 6/50\tEpoch 3/10\tloss: 1.49872553\n",
      "val Loss: 1.6178 Acc: 38.97%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 7/50\tEpoch 3/10\tloss: 1.49767148\n",
      "val Loss: 1.6171 Acc: 38.58%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 8/50\tEpoch 3/10\tloss: 1.49682546\n",
      "val Loss: 1.6111 Acc: 38.97%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 9/50\tEpoch 3/10\tloss: 1.49491107\n",
      "val Loss: 1.6098 Acc: 38.58%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 10/50\tEpoch 3/10\tloss: 1.49207532\n",
      "val Loss: 1.6076 Acc: 38.84%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 11/50\tEpoch 3/10\tloss: 1.49146378\n",
      "val Loss: 1.6068 Acc: 38.58%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 12/50\tEpoch 3/10\tloss: 1.48848462\n",
      "val Loss: 1.5991 Acc: 38.97%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 13/50\tEpoch 3/10\tloss: 1.48904955\n",
      "val Loss: 1.5957 Acc: 38.84%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 14/50\tEpoch 3/10\tloss: 1.48685694\n",
      "val Loss: 1.5974 Acc: 38.58%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 15/50\tEpoch 3/10\tloss: 1.48731625\n",
      "val Loss: 1.6033 Acc: 38.32%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 16/50\tEpoch 3/10\tloss: 1.48190033\n",
      "val Loss: 1.5938 Acc: 39.23%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 17/50\tEpoch 3/10\tloss: 1.48423398\n",
      "val Loss: 1.5892 Acc: 39.35%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 18/50\tEpoch 3/10\tloss: 1.48203897\n",
      "val Loss: 1.5883 Acc: 39.48%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 19/50\tEpoch 3/10\tloss: 1.48247480\n",
      "val Loss: 1.5904 Acc: 39.35%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 20/50\tEpoch 3/10\tloss: 1.48191571\n",
      "val Loss: 1.5785 Acc: 39.87%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 21/50\tEpoch 3/10\tloss: 1.47559619\n",
      "val Loss: 1.5800 Acc: 39.87%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 22/50\tEpoch 3/10\tloss: 1.47740054\n",
      "val Loss: 1.5834 Acc: 39.10%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 23/50\tEpoch 3/10\tloss: 1.47183454\n",
      "val Loss: 1.5740 Acc: 39.87%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 24/50\tEpoch 3/10\tloss: 1.47152638\n",
      "val Loss: 1.5664 Acc: 40.00%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 25/50\tEpoch 3/10\tloss: 1.47025037\n",
      "val Loss: 1.5678 Acc: 39.87%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 26/50\tEpoch 3/10\tloss: 1.46793211\n",
      "val Loss: 1.5690 Acc: 40.39%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 27/50\tEpoch 3/10\tloss: 1.46953917\n",
      "val Loss: 1.5601 Acc: 40.52%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 28/50\tEpoch 3/10\tloss: 1.46796894\n",
      "val Loss: 1.5605 Acc: 41.16%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 29/50\tEpoch 3/10\tloss: 1.46808529\n",
      "val Loss: 1.5646 Acc: 40.65%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 30/50\tEpoch 3/10\tloss: 1.46370518\n",
      "val Loss: 1.5546 Acc: 41.29%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 31/50\tEpoch 3/10\tloss: 1.45948780\n",
      "val Loss: 1.5533 Acc: 40.77%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 32/50\tEpoch 3/10\tloss: 1.45949900\n",
      "val Loss: 1.5545 Acc: 40.90%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 33/50\tEpoch 3/10\tloss: 1.45819366\n",
      "val Loss: 1.5539 Acc: 41.16%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 34/50\tEpoch 3/10\tloss: 1.45858276\n",
      "val Loss: 1.5458 Acc: 41.94%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 35/50\tEpoch 3/10\tloss: 1.45757985\n",
      "val Loss: 1.5450 Acc: 41.42%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 36/50\tEpoch 3/10\tloss: 1.45642543\n",
      "val Loss: 1.5405 Acc: 41.81%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold No. 37/50\tEpoch 3/10\tloss: 1.45483947\n",
      "val Loss: 1.5378 Acc: 41.42%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 38/50\tEpoch 3/10\tloss: 1.45239747\n",
      "val Loss: 1.5381 Acc: 41.29%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 39/50\tEpoch 3/10\tloss: 1.45131528\n",
      "val Loss: 1.5335 Acc: 41.55%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 40/50\tEpoch 3/10\tloss: 1.45062041\n",
      "val Loss: 1.5276 Acc: 41.81%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 41/50\tEpoch 3/10\tloss: 1.44588852\n",
      "val Loss: 1.5328 Acc: 41.42%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 42/50\tEpoch 3/10\tloss: 1.41781425\n",
      "val Loss: 1.5243 Acc: 42.40%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 43/50\tEpoch 3/10\tloss: 1.41677642\n",
      "val Loss: 1.5189 Acc: 43.17%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 44/50\tEpoch 3/10\tloss: 1.41339004\n",
      "val Loss: 1.5199 Acc: 42.40%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 45/50\tEpoch 3/10\tloss: 1.41331565\n",
      "val Loss: 1.5154 Acc: 42.40%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 46/50\tEpoch 3/10\tloss: 1.41027367\n",
      "val Loss: 1.5129 Acc: 43.04%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 47/50\tEpoch 3/10\tloss: 1.41013694\n",
      "val Loss: 1.5200 Acc: 42.40%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 48/50\tEpoch 3/10\tloss: 1.40891445\n",
      "val Loss: 1.5125 Acc: 42.53%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 49/50\tEpoch 3/10\tloss: 1.55676401\n",
      "val Loss: 1.5123 Acc: 42.14%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 50/50\tEpoch 3/10\tloss: 1.36538708\n",
      "val Loss: 1.5037 Acc: 43.17%\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 1/50\tEpoch 4/10\tloss: 1.44056606\n",
      "val Loss: 1.5009 Acc: 42.97%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 2/50\tEpoch 4/10\tloss: 1.43427074\n",
      "val Loss: 1.4961 Acc: 43.23%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 3/50\tEpoch 4/10\tloss: 1.43157434\n",
      "val Loss: 1.4952 Acc: 42.84%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 4/50\tEpoch 4/10\tloss: 1.42811918\n",
      "val Loss: 1.5001 Acc: 42.58%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 5/50\tEpoch 4/10\tloss: 1.42220044\n",
      "val Loss: 1.4828 Acc: 42.71%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 6/50\tEpoch 4/10\tloss: 1.42436373\n",
      "val Loss: 1.4904 Acc: 42.58%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 7/50\tEpoch 4/10\tloss: 1.42398083\n",
      "val Loss: 1.4910 Acc: 42.58%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 8/50\tEpoch 4/10\tloss: 1.42380571\n",
      "val Loss: 1.4845 Acc: 43.35%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 9/50\tEpoch 4/10\tloss: 1.41983318\n",
      "val Loss: 1.4848 Acc: 42.84%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 10/50\tEpoch 4/10\tloss: 1.41798413\n",
      "val Loss: 1.4815 Acc: 43.23%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 11/50\tEpoch 4/10\tloss: 1.41298890\n",
      "val Loss: 1.4803 Acc: 42.71%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 12/50\tEpoch 4/10\tloss: 1.41034079\n",
      "val Loss: 1.4743 Acc: 43.10%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 13/50\tEpoch 4/10\tloss: 1.41314840\n",
      "val Loss: 1.4732 Acc: 43.23%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 14/50\tEpoch 4/10\tloss: 1.41031599\n",
      "val Loss: 1.4742 Acc: 43.61%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 15/50\tEpoch 4/10\tloss: 1.41167688\n",
      "val Loss: 1.4804 Acc: 42.45%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 16/50\tEpoch 4/10\tloss: 1.40665805\n",
      "val Loss: 1.4701 Acc: 43.35%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 17/50\tEpoch 4/10\tloss: 1.40541875\n",
      "val Loss: 1.4667 Acc: 42.58%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 18/50\tEpoch 4/10\tloss: 1.40427256\n",
      "val Loss: 1.4677 Acc: 43.23%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 19/50\tEpoch 4/10\tloss: 1.40285265\n",
      "val Loss: 1.4684 Acc: 43.10%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 20/50\tEpoch 4/10\tloss: 1.40200078\n",
      "val Loss: 1.4592 Acc: 43.61%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 21/50\tEpoch 4/10\tloss: 1.39590609\n",
      "val Loss: 1.4587 Acc: 44.13%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 22/50\tEpoch 4/10\tloss: 1.39748859\n",
      "val Loss: 1.4641 Acc: 43.10%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 23/50\tEpoch 4/10\tloss: 1.39380920\n",
      "val Loss: 1.4568 Acc: 43.61%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 24/50\tEpoch 4/10\tloss: 1.39422238\n",
      "val Loss: 1.4488 Acc: 44.00%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 25/50\tEpoch 4/10\tloss: 1.39072359\n",
      "val Loss: 1.4491 Acc: 43.61%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 26/50\tEpoch 4/10\tloss: 1.39259982\n",
      "val Loss: 1.4528 Acc: 44.13%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 27/50\tEpoch 4/10\tloss: 1.38917315\n",
      "val Loss: 1.4405 Acc: 43.74%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 28/50\tEpoch 4/10\tloss: 1.38789988\n",
      "val Loss: 1.4434 Acc: 44.00%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 29/50\tEpoch 4/10\tloss: 1.38512182\n",
      "val Loss: 1.4502 Acc: 43.48%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 30/50\tEpoch 4/10\tloss: 1.38489640\n",
      "val Loss: 1.4382 Acc: 44.39%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 31/50\tEpoch 4/10\tloss: 1.38018751\n",
      "val Loss: 1.4399 Acc: 43.87%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 32/50\tEpoch 4/10\tloss: 1.38125551\n",
      "val Loss: 1.4426 Acc: 44.39%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 33/50\tEpoch 4/10\tloss: 1.38026822\n",
      "val Loss: 1.4403 Acc: 43.35%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 34/50\tEpoch 4/10\tloss: 1.37452638\n",
      "val Loss: 1.4334 Acc: 44.52%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 35/50\tEpoch 4/10\tloss: 1.37420201\n",
      "val Loss: 1.4338 Acc: 43.74%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 36/50\tEpoch 4/10\tloss: 1.36846781\n",
      "val Loss: 1.4296 Acc: 43.87%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 37/50\tEpoch 4/10\tloss: 1.36827290\n",
      "val Loss: 1.4266 Acc: 43.87%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 38/50\tEpoch 4/10\tloss: 1.36938787\n",
      "val Loss: 1.4274 Acc: 44.77%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 39/50\tEpoch 4/10\tloss: 1.36811757\n",
      "val Loss: 1.4249 Acc: 44.90%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 40/50\tEpoch 4/10\tloss: 1.36539614\n",
      "val Loss: 1.4197 Acc: 44.52%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 41/50\tEpoch 4/10\tloss: 1.36344516\n",
      "val Loss: 1.4247 Acc: 44.39%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 42/50\tEpoch 4/10\tloss: 1.33326519\n",
      "val Loss: 1.4180 Acc: 44.33%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 43/50\tEpoch 4/10\tloss: 1.32876635\n",
      "val Loss: 1.4109 Acc: 44.97%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 44/50\tEpoch 4/10\tloss: 1.32796848\n",
      "val Loss: 1.4130 Acc: 44.59%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 45/50\tEpoch 4/10\tloss: 1.32817829\n",
      "val Loss: 1.4108 Acc: 44.33%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 46/50\tEpoch 4/10\tloss: 1.32421505\n",
      "val Loss: 1.4081 Acc: 44.46%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 47/50\tEpoch 4/10\tloss: 1.32396901\n",
      "val Loss: 1.4159 Acc: 44.07%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 48/50\tEpoch 4/10\tloss: 1.32488310\n",
      "val Loss: 1.4087 Acc: 44.33%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 49/50\tEpoch 4/10\tloss: 1.46227825\n",
      "val Loss: 1.4091 Acc: 43.56%\n",
      "\n",
      "Train Index Length: 776\t\tTest Index Length: 15\n",
      "\n",
      "Fold No. 50/50\tEpoch 4/10\tloss: 1.28598666\n",
      "val Loss: 1.4020 Acc: 44.33%\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 1/50\tEpoch 5/10\tloss: 1.35493898\n",
      "val Loss: 1.4010 Acc: 44.77%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 2/50\tEpoch 5/10\tloss: 1.35008097\n",
      "val Loss: 1.3942 Acc: 45.29%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 3/50\tEpoch 5/10\tloss: 1.35133219\n",
      "val Loss: 1.3960 Acc: 44.77%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 4/50\tEpoch 5/10\tloss: 1.34803820\n",
      "val Loss: 1.3992 Acc: 44.77%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold No. 5/50\tEpoch 5/10\tloss: 1.34301174\n",
      "val Loss: 1.3829 Acc: 44.65%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 6/50\tEpoch 5/10\tloss: 1.34194398\n",
      "val Loss: 1.3922 Acc: 44.52%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 7/50\tEpoch 5/10\tloss: 1.33975458\n",
      "val Loss: 1.3930 Acc: 44.52%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 8/50\tEpoch 5/10\tloss: 1.33817637\n",
      "val Loss: 1.3877 Acc: 44.65%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 9/50\tEpoch 5/10\tloss: 1.33686972\n",
      "val Loss: 1.3898 Acc: 44.90%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 10/50\tEpoch 5/10\tloss: 1.32974243\n",
      "val Loss: 1.3853 Acc: 45.29%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 11/50\tEpoch 5/10\tloss: 1.32841945\n",
      "val Loss: 1.3842 Acc: 45.03%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 12/50\tEpoch 5/10\tloss: 1.32464278\n",
      "val Loss: 1.3784 Acc: 45.03%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 13/50\tEpoch 5/10\tloss: 1.32525396\n",
      "val Loss: 1.3802 Acc: 44.65%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 14/50\tEpoch 5/10\tloss: 1.32276869\n",
      "val Loss: 1.3811 Acc: 44.65%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 15/50\tEpoch 5/10\tloss: 1.32165205\n",
      "val Loss: 1.3876 Acc: 44.26%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 16/50\tEpoch 5/10\tloss: 1.31899226\n",
      "val Loss: 1.3772 Acc: 44.90%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 17/50\tEpoch 5/10\tloss: 1.31949961\n",
      "val Loss: 1.3742 Acc: 44.90%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 18/50\tEpoch 5/10\tloss: 1.31329131\n",
      "val Loss: 1.3767 Acc: 44.90%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 19/50\tEpoch 5/10\tloss: 1.31323230\n",
      "val Loss: 1.3783 Acc: 44.65%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n",
      "Fold No. 20/50\tEpoch 5/10\tloss: 1.31211293\n",
      "val Loss: 1.3698 Acc: 45.16%\n",
      "\n",
      "Train Index Length: 775\t\tTest Index Length: 16\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-747-5fcf7ccb8964>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_val_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-743-0a6d0c2dd2e3>\u001b[0m in \u001b[0;36mtrain_val_model\u001b[1;34m(model, criterion, optimizer, X, y, num_epochs)\u001b[0m\n\u001b[0;32m     51\u001b[0m                 \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m                         \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m                 \u001b[1;31m# print(y_pred.shape, y_batch.view(-1, 1).shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m                 \u001b[0msingle_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.4)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "model, losses, accuracies = train_val_model(model, criterion, optimizer, dataset.X, dataset.y, num_epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1\n",
    "overlap = 48\n",
    "window_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.plot(losses['train'], '-b', losses['val'], '--r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'MLP_Model_moves_{D_out}_windowsize{window_size}_overlap{overlap}_epoch{NUM_EPOCHS}'\n",
    "torch.save(model.state_dict(), name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "linear1.weight \t\t torch.Size([70, 72])\n",
      "linear1.bias \t\t torch.Size([70])\n",
      "linear2.weight \t\t torch.Size([17, 70])\n",
      "linear2.bias \t\t torch.Size([17])\n",
      "linear3.weight \t\t torch.Size([17, 17])\n",
      "linear3.bias \t\t torch.Size([17])\n",
      "linear4.weight \t\t torch.Size([8, 17])\n",
      "linear4.bias \t\t torch.Size([8])\n",
      "linear5.weight \t\t torch.Size([8, 8])\n",
      "Optimizer's state_dict:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'momentum_buffer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-731-6b663fd4d333>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvar_name\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'state'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlp_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'momentum_buffer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;31m# print(var_name, \"\\t\", np.array(optimizer.state_dict()[var_name][i]['momentum_buffer']))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'momentum_buffer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'momentum_buffer'"
     ]
    }
   ],
   "source": [
    "mlp_model = MLP(D_in, 70, D_out)\n",
    "mlp_model.load(name)\n",
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in mlp_model.state_dict():\n",
    "    print(param_tensor, \"\\t\\t\", mlp_model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "\n",
    "with open('weights.txt', 'w') as outfile:\n",
    "    for var_name in optimizer.state_dict():\n",
    "        if var_name == 'state':\n",
    "            for i in range(len(mlp_model.state_dict())):\n",
    "                print(var_name, \"\\t\", optimizer.state_dict()[var_name][i]['momentum_buffer'].shape)\n",
    "                # print(var_name, \"\\t\", np.array(optimizer.state_dict()[var_name][i]['momentum_buffer']))\n",
    "                y = np.array(optimizer.state_dict()[var_name][i]['momentum_buffer'])\n",
    "                for x in y:\n",
    "                    x = str(x)\n",
    "                    x = x.replace('[','{').replace(']','}').replace(' ', ', ').replace('{,', '{').replace(', ,', ',').replace('\\n,', ',\\n')\n",
    "                    outfile.write(x)\n",
    "                # np.savetxt(outfile, np.array(optimizer.state_dict()[var_name][i]['momentum_buffer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f5c2602d6379>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmlp_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmlp_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmlp_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mto_predict\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'name' is not defined"
     ]
    }
   ],
   "source": [
    "mlp_model = MLP(D_in, 70, D_out)\n",
    "mlp_model.load(name)\n",
    "mlp_model.eval()\n",
    "\n",
    "for to_predict in range(D_out):\n",
    "    df_target = df_test[df_test['tag'] == to_predict]\n",
    "    df_target = torch.from_numpy(np.array(df_target)[:,:-1])\n",
    "\n",
    "#     df_random = df_test\n",
    "\n",
    "#     df_filtered = torch.from_numpy(np.array(pd.merge(df_target, df_random))[:,:-1])\n",
    "    output = mlp_model.predict(df_target)\n",
    "    proba_dict = {}\n",
    "\n",
    "    for x in output:\n",
    "        x = int(x)\n",
    "        if x not in proba_dict:\n",
    "            proba_dict[x] = 1\n",
    "        else:\n",
    "            proba_dict[x] += 1\n",
    "    for k in proba_dict.keys():\n",
    "        proba_dict[k] /= len(output)\n",
    "\n",
    "    print(dict(sorted(proba_dict.items(), key=lambda item: -item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dances = ['dab', 'elbowkick', 'gun', 'hair', 'listen', 'pointhigh', 'sidepump', 'wipetable']\n",
    "# dances = ['gun', 'hair', 'sidepump']\n",
    "# dances = ['elbowkick', 'pointhigh', 'wipetable']\n",
    "persons = ['kelvin', 'guiyong', 'xiaoxue', 'john']\n",
    "beetles = ['1', '2']\n",
    "\n",
    "test_range = 12\n",
    "leap = 100\n",
    "truth, total, skipped = 0,0,0\n",
    "for i in range(18,18+test_range):\n",
    "    print(\"Phase:\", i)\n",
    "    start, end = i * leap, i * leap + leap\n",
    "    for d in dances:\n",
    "        print(d)\n",
    "        df_full = pd.DataFrame()\n",
    "        collection = [np.array([]) for x in range(16)]\n",
    "        j = 0\n",
    "        for p in persons:\n",
    "            for b in beetles:\n",
    "                if b == '1':\n",
    "                    continue\n",
    "                move_json = 'collected_data/' + d + b + '_' + p + '.json'\n",
    "                with open(move_json) as f:\n",
    "                    x = json.load(f)\n",
    "                x = pd.DataFrame.from_dict(x)[100:400]\n",
    "                df_target = torch.from_numpy(np.array(feature_extraction(x)))\n",
    "                output = mlp_model.predict(df_target)\n",
    "                proba_dict = {}\n",
    "\n",
    "                for x in output:\n",
    "                    x = int(x)\n",
    "                    if x not in proba_dict:\n",
    "                        proba_dict[x] = 1\n",
    "                    else:\n",
    "                        proba_dict[x] += 1\n",
    "                for k in proba_dict.keys():\n",
    "                    proba_dict[k] /= len(output)\n",
    "\n",
    "                print(dict(sorted(proba_dict.items(), key=lambda item: -item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(df, window_size):\n",
    "    full_features = np.array([])\n",
    "    axis = ['accel1', 'accel2', 'accel3', 'gyro1', 'gyro2', 'gyro3']\n",
    "    titles = np.ravel(np.array([i+'_'+j for i in feature_list for j in axis]))\n",
    "\n",
    "    # print(\"Begin Feature Extraction\")\n",
    "    windows = set_sliding_windows(df, 48, window_size)\n",
    "    # windows = set_windows(df, window_size)\n",
    "\n",
    "    for window in windows:\n",
    "        for _,ax in enumerate(window.T):\n",
    "                full_features = np.append(full_features, add_mean(ax))\n",
    "                full_features = np.append(full_features, add_max(ax))\n",
    "                full_features = np.append(full_features, add_min(ax))\n",
    "                full_features = np.append(full_features, add_median(ax))\n",
    "                full_features = np.append(full_features, add_gradient(ax))\n",
    "                full_features = np.append(full_features, add_std(ax))\n",
    "                full_features = np.append(full_features, add_iqr(ax))\n",
    "                # full_features = np.append(full_features, add_skew(ax))\n",
    "                full_features = np.append(full_features, add_zero_crossing_count(ax))\n",
    "                # full_features = np.append(full_features, add_cwt(ax))\n",
    "                full_features = np.append(full_features, add_no_peaks(ax))\n",
    "                full_features = np.append(full_features, add_recurring_dp(ax))\n",
    "                # full_features = np.append(full_features, add_ratio_v_tsl(ax))\n",
    "                # full_features = np.append(full_features, add_sum_recurring_dp(ax))\n",
    "                full_features = np.append(full_features, add_var_coeff(ax))\n",
    "                full_features = np.append(full_features, add_kurtosis(ax)) \n",
    "\n",
    "    full_features = full_features.reshape(\n",
    "        -1,\n",
    "        len(feature_list) * 6,\n",
    "    )   \n",
    "    full_features_df = pd.DataFrame(full_features)\n",
    "    full_features_df.columns = titles\n",
    "    return full_features_df\n",
    "\n",
    "def feature_extraction(data):\n",
    "    data = pd.DataFrame.from_dict(data)\n",
    "    if 'dance' in data:\n",
    "        del data['dance']\n",
    "\n",
    "    df = data.apply(pd.to_numeric).interpolate(method='polynomial', order=2)\n",
    "    col = df.columns\n",
    "    # X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0)\n",
    "    df_scaled = df.apply(lambda x: (x - mean(x)) / std(x))\n",
    "    # df_scaled = df.apply(lambda x: (x - min(x)) / (max(x) - min(x)))\n",
    "    # min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    # df_scaled = min_max_scaler.fit_transform(df)\n",
    "    df = pd.DataFrame(df_scaled, columns=col)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(df.shape)\n",
    "    features = feature_extract(df, window_size=50).reset_index(drop=True)\n",
    "    # print(features.shape)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"collected_data/dab2_guiyong.json\") as f:\n",
    "    x = json.load(f)\n",
    "x = pd.DataFrame.from_dict(x)[120:240]\n",
    "feature_extraction(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_accel1</th>\n",
       "      <th>mean_accel2</th>\n",
       "      <th>mean_accel3</th>\n",
       "      <th>mean_gyro1</th>\n",
       "      <th>mean_gyro2</th>\n",
       "      <th>mean_gyro3</th>\n",
       "      <th>max_accel1</th>\n",
       "      <th>max_accel2</th>\n",
       "      <th>max_accel3</th>\n",
       "      <th>max_gyro1</th>\n",
       "      <th>...</th>\n",
       "      <th>var_coeff_gyro1</th>\n",
       "      <th>var_coeff_gyro2</th>\n",
       "      <th>var_coeff_gyro3</th>\n",
       "      <th>kurtosis_accel1</th>\n",
       "      <th>kurtosis_accel2</th>\n",
       "      <th>kurtosis_accel3</th>\n",
       "      <th>kurtosis_gyro1</th>\n",
       "      <th>kurtosis_gyro2</th>\n",
       "      <th>kurtosis_gyro3</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.619921</td>\n",
       "      <td>0.852686</td>\n",
       "      <td>0.415965</td>\n",
       "      <td>0.644185</td>\n",
       "      <td>0.004212</td>\n",
       "      <td>0.120937</td>\n",
       "      <td>0.139660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513191</td>\n",
       "      <td>0.009334</td>\n",
       "      <td>0.136847</td>\n",
       "      <td>0.188756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.275968</td>\n",
       "      <td>-0.960621</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.624279</td>\n",
       "      <td>0.852686</td>\n",
       "      <td>0.416880</td>\n",
       "      <td>0.644185</td>\n",
       "      <td>-0.001367</td>\n",
       "      <td>0.116153</td>\n",
       "      <td>0.135386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516332</td>\n",
       "      <td>0.009095</td>\n",
       "      <td>0.137426</td>\n",
       "      <td>0.223304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.267198</td>\n",
       "      <td>-1.087590</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.628567</td>\n",
       "      <td>0.852686</td>\n",
       "      <td>0.416880</td>\n",
       "      <td>0.647176</td>\n",
       "      <td>0.004263</td>\n",
       "      <td>0.117444</td>\n",
       "      <td>0.141651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.531407</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>0.131167</td>\n",
       "      <td>0.201319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.250598</td>\n",
       "      <td>-0.998598</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.635413</td>\n",
       "      <td>0.852686</td>\n",
       "      <td>0.416880</td>\n",
       "      <td>0.654197</td>\n",
       "      <td>0.003841</td>\n",
       "      <td>0.122414</td>\n",
       "      <td>0.153426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534548</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>0.127450</td>\n",
       "      <td>0.185302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.240380</td>\n",
       "      <td>-0.874532</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.642668</td>\n",
       "      <td>0.852686</td>\n",
       "      <td>0.416880</td>\n",
       "      <td>0.666117</td>\n",
       "      <td>0.003439</td>\n",
       "      <td>0.128431</td>\n",
       "      <td>0.157654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534548</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.126936</td>\n",
       "      <td>0.185302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.238541</td>\n",
       "      <td>-0.847370</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.638731</td>\n",
       "      <td>0.855403</td>\n",
       "      <td>0.433303</td>\n",
       "      <td>0.633242</td>\n",
       "      <td>-0.001171</td>\n",
       "      <td>0.120727</td>\n",
       "      <td>0.165690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562814</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.107036</td>\n",
       "      <td>0.145729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.188983</td>\n",
       "      <td>-0.345404</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.634350</td>\n",
       "      <td>0.855403</td>\n",
       "      <td>0.433303</td>\n",
       "      <td>0.633242</td>\n",
       "      <td>-0.003033</td>\n",
       "      <td>0.125137</td>\n",
       "      <td>0.181677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562814</td>\n",
       "      <td>0.002387</td>\n",
       "      <td>0.096728</td>\n",
       "      <td>0.145729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.168880</td>\n",
       "      <td>-0.719264</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.626859</td>\n",
       "      <td>0.855403</td>\n",
       "      <td>0.417308</td>\n",
       "      <td>0.632799</td>\n",
       "      <td>-0.004421</td>\n",
       "      <td>0.131631</td>\n",
       "      <td>0.203022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562814</td>\n",
       "      <td>-0.000402</td>\n",
       "      <td>0.093748</td>\n",
       "      <td>0.145729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.163197</td>\n",
       "      <td>-0.898353</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.617916</td>\n",
       "      <td>0.855403</td>\n",
       "      <td>0.417308</td>\n",
       "      <td>0.614850</td>\n",
       "      <td>-0.004626</td>\n",
       "      <td>0.136993</td>\n",
       "      <td>0.216331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562814</td>\n",
       "      <td>-0.003920</td>\n",
       "      <td>0.100980</td>\n",
       "      <td>0.145729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.177072</td>\n",
       "      <td>-0.475365</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.610069</td>\n",
       "      <td>0.855403</td>\n",
       "      <td>0.417308</td>\n",
       "      <td>0.586920</td>\n",
       "      <td>-0.003406</td>\n",
       "      <td>0.138429</td>\n",
       "      <td>0.222711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559045</td>\n",
       "      <td>-0.005942</td>\n",
       "      <td>0.112796</td>\n",
       "      <td>0.158291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.201060</td>\n",
       "      <td>-0.351155</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_accel1  mean_accel2  mean_accel3  mean_gyro1  mean_gyro2  mean_gyro3  \\\n",
       "0      0.619921     0.852686     0.415965    0.644185    0.004212    0.120937   \n",
       "1      0.624279     0.852686     0.416880    0.644185   -0.001367    0.116153   \n",
       "2      0.628567     0.852686     0.416880    0.647176    0.004263    0.117444   \n",
       "3      0.635413     0.852686     0.416880    0.654197    0.003841    0.122414   \n",
       "4      0.642668     0.852686     0.416880    0.666117    0.003439    0.128431   \n",
       "..          ...          ...          ...         ...         ...         ...   \n",
       "67     0.638731     0.855403     0.433303    0.633242   -0.001171    0.120727   \n",
       "68     0.634350     0.855403     0.433303    0.633242   -0.003033    0.125137   \n",
       "69     0.626859     0.855403     0.417308    0.632799   -0.004421    0.131631   \n",
       "70     0.617916     0.855403     0.417308    0.614850   -0.004626    0.136993   \n",
       "71     0.610069     0.855403     0.417308    0.586920   -0.003406    0.138429   \n",
       "\n",
       "    max_accel1  max_accel2  max_accel3  max_gyro1  ...  var_coeff_gyro1  \\\n",
       "0     0.139660         0.0         3.0       0.00  ...         0.513191   \n",
       "1     0.135386         0.0         3.0       0.00  ...         0.516332   \n",
       "2     0.141651         0.0         3.0       0.00  ...         0.531407   \n",
       "3     0.153426         0.0         3.0       0.00  ...         0.534548   \n",
       "4     0.157654         0.0         2.0       0.00  ...         0.534548   \n",
       "..         ...         ...         ...        ...  ...              ...   \n",
       "67    0.165690         0.0         2.0       0.00  ...         0.562814   \n",
       "68    0.181677         0.0         2.0       0.00  ...         0.562814   \n",
       "69    0.203022         0.0         2.0       0.00  ...         0.562814   \n",
       "70    0.216331         0.0         2.0       0.00  ...         0.562814   \n",
       "71    0.222711         0.0         1.0       0.04  ...         0.559045   \n",
       "\n",
       "    var_coeff_gyro2  var_coeff_gyro3  kurtosis_accel1  kurtosis_accel2  \\\n",
       "0          0.009334         0.136847         0.188756              0.0   \n",
       "1          0.009095         0.137426         0.223304              0.0   \n",
       "2          0.003719         0.131167         0.201319              0.0   \n",
       "3          0.002198         0.127450         0.185302              0.0   \n",
       "4          0.000113         0.126936         0.185302              0.0   \n",
       "..              ...              ...              ...              ...   \n",
       "67         0.004372         0.107036         0.145729              0.0   \n",
       "68         0.002387         0.096728         0.145729              0.0   \n",
       "69        -0.000402         0.093748         0.145729              0.0   \n",
       "70        -0.003920         0.100980         0.145729              0.0   \n",
       "71        -0.005942         0.112796         0.158291              0.0   \n",
       "\n",
       "    kurtosis_accel3  kurtosis_gyro1  kurtosis_gyro2  kurtosis_gyro3  tag  \n",
       "0               1.0            0.14        0.275968       -0.960621  0.0  \n",
       "1               1.0            0.14        0.267198       -1.087590  0.0  \n",
       "2               2.0            0.18        0.250598       -0.998598  0.0  \n",
       "3               2.0            0.18        0.240380       -0.874532  0.0  \n",
       "4               2.0            0.18        0.238541       -0.847370  0.0  \n",
       "..              ...             ...             ...             ...  ...  \n",
       "67              2.0            0.08        0.188983       -0.345404  0.0  \n",
       "68              2.0            0.12        0.168880       -0.719264  0.0  \n",
       "69              2.0            0.12        0.163197       -0.898353  0.0  \n",
       "70              2.0            0.12        0.177072       -0.475365  0.0  \n",
       "71              2.0            0.12        0.201060       -0.351155  0.0  \n",
       "\n",
       "[72 rows x 73 columns]"
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.df.head(72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hierarchical = df.copy()\n",
    "df_hierarchical['tag'] = df_hierarchical['tag'].apply(lambda x: 0 if x <= 7 else 1)\n",
    "\n",
    "msk = np.random.rand(len(df_hierarchical)) < 0.8\n",
    "df_train = df_hierarchical[msk]\n",
    "df_test = df_hierarchical[~msk]\n",
    "\n",
    "dataset = FeatureDataset(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hierarchical = MLP(D_in, 50, 2)\n",
    "optimizer = torch.optim.SGD(model_hierarchical.parameters(), lr=0.01, momentum=0.5)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "model, losses, accuracies = train_val_model(model_hierarchical, criterion, optimizer, dataset.X, dataset.y, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'MLP_Model_Hierarchical_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(losses['train'], '-b', losses['val'], '--r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = MLP(D_in, 50, 2)\n",
    "mlp_model.load('MLP_Model_Hierarchical_1')\n",
    "mlp_model.eval()\n",
    "\n",
    "for to_predict in range(2):\n",
    "    df_target = df_test[df_test['tag'] == to_predict]\n",
    "\n",
    "    df_random = df_test\n",
    "\n",
    "    df_filtered = torch.from_numpy(np.array(pd.merge(df_target, df_random))[:,:-1])\n",
    "    output = mlp_model.predict(df_filtered)\n",
    "    # print(output)\n",
    "    proba_dict = {}\n",
    "\n",
    "    for x in output:\n",
    "        x = int(x)\n",
    "        if x not in proba_dict:\n",
    "            proba_dict[x] = 1\n",
    "        else:\n",
    "            proba_dict[x] += 1\n",
    "    for k in proba_dict.keys():\n",
    "        proba_dict[k] /= len(output)\n",
    "    print(dict(sorted(proba_dict.items(), key=lambda item: -item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hierarchical_2 = df.copy()\n",
    "df_hierarchical_2 = df_hierarchical_2[df_hierarchical_2['tag'] >= 8]\n",
    "df_hierarchical_2 = df_hierarchical_2.apply(lambda x: x-8)\n",
    "msk = np.random.rand(len(df_hierarchical_2)) < 0.8\n",
    "df_train = df_hierarchical_2[msk]\n",
    "df_test = df_hierarchical_2[~msk]\n",
    "\n",
    "dataset = FeatureDataset(df_train)\n",
    "\n",
    "model_hierarchical_2 = MLP(D_in, 50, 2)\n",
    "# optimizer = torch.optim.Adam(model_hierarchical_2.parameters(), lr=1e-4)\n",
    "optimizer = torch.optim.SGD(model_hierarchical_2.parameters(), lr=0.01, momentum=0.5)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model, losses, accuracies = train_val_model(model_hierarchical_2, criterion, optimizer, dataset.X, dataset.y, num_epochs=20)\n",
    "\n",
    "torch.save(model.state_dict(), 'MLP_Model_Hierarchical_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(losses['train'], '-b', losses['val'], '--r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = MLP(D_in, 50, 2)\n",
    "mlp_model.load('MLP_Model_Hierarchical_2')\n",
    "mlp_model.eval()\n",
    "\n",
    "for to_predict in range(2):\n",
    "    df_target = df_test[df_test['tag'] == to_predict]\n",
    "\n",
    "    df_random = df_test\n",
    "\n",
    "    df_filtered = torch.from_numpy(np.array(pd.merge(df_target, df_random))[:,:-1])\n",
    "    output = mlp_model.predict(df_filtered)\n",
    "    # print(output)\n",
    "    proba_dict = {}\n",
    "\n",
    "    for x in output:\n",
    "        x = int(x) + 8\n",
    "        if x not in proba_dict:\n",
    "            proba_dict[x] = 1\n",
    "        else:\n",
    "            proba_dict[x] += 1\n",
    "    for k in proba_dict.keys():\n",
    "        proba_dict[k] /= len(output)\n",
    "\n",
    "    print(dict(sorted(proba_dict.items(), key=lambda item: -item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hierarchical_3 = df.copy()\n",
    "df_hierarchical_3 = df_hierarchical_3[df_hierarchical_3['tag'] < 8]\n",
    "msk = np.random.rand(len(df_hierarchical_3)) < 0.8\n",
    "df_train = df_hierarchical_3[msk]\n",
    "df_test = df_hierarchical_3[~msk]\n",
    "\n",
    "dataset = FeatureDataset(df_train)\n",
    "\n",
    "model_hierarchical_3 = MLP(D_in, 50, 8)\n",
    "# optimizer = torch.optim.Adam(model_hierarchical_2.parameters(), lr=1e-4)\n",
    "optimizer = torch.optim.SGD(model_hierarchical_3.parameters(), lr=0.01, momentum=0.5)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "model, losses, accuracies = train_val_model(model_hierarchical_3, criterion, optimizer, dataset.X, dataset.y, num_epochs=30)\n",
    "\n",
    "torch.save(model.state_dict(), 'MLP_Model_Hierarchical_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(losses['train'], '-b', losses['val'], '--r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = MLP(D_in, 50, 8)\n",
    "mlp_model.load('MLP_Model_Hierarchical_3')\n",
    "mlp_model.eval()\n",
    "\n",
    "for to_predict in range(8):\n",
    "    df_target = df_test[df_test['tag'] == to_predict]\n",
    "\n",
    "    df_random = df_test\n",
    "\n",
    "    df_filtered = torch.from_numpy(np.array(pd.merge(df_target, df_random))[:,:-1])\n",
    "    output = mlp_model.predict(df_filtered)\n",
    "    # print(output)\n",
    "    proba_dict = {}\n",
    "\n",
    "    for x in output:\n",
    "        x = int(x)\n",
    "        if x not in proba_dict:\n",
    "            proba_dict[x] = 1\n",
    "        else:\n",
    "            proba_dict[x] += 1\n",
    "    for k in proba_dict.keys():\n",
    "        proba_dict[k] /= len(output)\n",
    "\n",
    "    print(dict(sorted(proba_dict.items(), key=lambda item: -item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 4)]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "lst = [1,1,1,1,2,3]\n",
    "print(statistics._counts(lst))\n",
    "print(max([p[0] for p in statistics._counts(lst)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
